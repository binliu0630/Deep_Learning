{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_tensorflow2.0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smitaforward/Data_Science/blob/master/Amazon_tensorflow2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "iLgXXoFuxayL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "9b99479f-4b40-4926-d92e-f2ed5ff501a7"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "# !pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 332.1MB 57kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Collecting google-pasta>=0.1.2 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/96/adbd4eafe72ce9b5ca6f168fbf109386e1b601f7c59926a11e9d7b7a5b44/google_pasta-0.1.4-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.6.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.11.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K    100% |████████████████████████████████| 419kB 12.0MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (40.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.0.1)\n",
            "Installing collected packages: google-pasta, tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed google-pasta-0.1.4 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UQ631rmxxbuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68ef238d-3485-486b-cc19-e04789301720"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MDsu4hZOyn1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CbJLB6frypxQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Amazon comments"
      ]
    },
    {
      "metadata": {
        "id": "KJ3ER5Qzyov3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " data_path = \"https://s3.amazonaws.com/tomk/h2o-world/megan/AmazonReviews.csv\"\n",
        "data = pd.read_csv(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efVH6iaCynyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0fe2f3ed-944c-4ae8-8a66-23daeca8034a"
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Score</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>Time</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B00141QYSQ</td>\n",
              "      <td>A1YS02UZZGRDCT</td>\n",
              "      <td>Do Not Buy</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>41471</td>\n",
              "      <td>Evan Eberhardt</td>\n",
              "      <td>2</td>\n",
              "      <td>1348358400</td>\n",
              "      <td>These are made in China (do not buy ANY pet fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B0089SPEO2</td>\n",
              "      <td>A3JOYNYL458QHP</td>\n",
              "      <td>Less lemon and less zing</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>28582</td>\n",
              "      <td>coleridge</td>\n",
              "      <td>0</td>\n",
              "      <td>1323907200</td>\n",
              "      <td>Everything is ok, except it just isn't as good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B001PMCDK2</td>\n",
              "      <td>A14TTMM0Z03Y2W</td>\n",
              "      <td>my cat goes crazy for these!</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>389965</td>\n",
              "      <td>Lindsay S. Bradford</td>\n",
              "      <td>0</td>\n",
              "      <td>1310601600</td>\n",
              "      <td>Best cat treat ever. There isn't anything comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B002Q8JOSI</td>\n",
              "      <td>A17UQD2RSSQH5X</td>\n",
              "      <td>My dogs tell me these treats are YUMMY</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>212536</td>\n",
              "      <td>in the dark</td>\n",
              "      <td>1</td>\n",
              "      <td>1316131200</td>\n",
              "      <td>My two Corgis were thoroughly spoiled by my la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00176G870</td>\n",
              "      <td>A2F2MZW8EOGH5J</td>\n",
              "      <td>Yummy to the tummy</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>115971</td>\n",
              "      <td>daemoncycler \"When you arrive at a fork in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>1334793600</td>\n",
              "      <td>We used to have drive down to the specialty pe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ProductId          UserId                                 Summary  Score  \\\n",
              "0  B00141QYSQ  A1YS02UZZGRDCT                              Do Not Buy      1   \n",
              "1  B0089SPEO2  A3JOYNYL458QHP                Less lemon and less zing      3   \n",
              "2  B001PMCDK2  A14TTMM0Z03Y2W            my cat goes crazy for these!      5   \n",
              "3  B002Q8JOSI  A17UQD2RSSQH5X  My dogs tell me these treats are YUMMY      5   \n",
              "4  B00176G870  A2F2MZW8EOGH5J                      Yummy to the tummy      5   \n",
              "\n",
              "   HelpfulnessDenominator      Id  \\\n",
              "0                       2   41471   \n",
              "1                       0   28582   \n",
              "2                       0  389965   \n",
              "3                       1  212536   \n",
              "4                       0  115971   \n",
              "\n",
              "                                        ProfileName  HelpfulnessNumerator  \\\n",
              "0                                    Evan Eberhardt                     2   \n",
              "1                                         coleridge                     0   \n",
              "2                               Lindsay S. Bradford                     0   \n",
              "3                                       in the dark                     1   \n",
              "4  daemoncycler \"When you arrive at a fork in th...                     0   \n",
              "\n",
              "         Time                                               Text  \n",
              "0  1348358400  These are made in China (do not buy ANY pet fo...  \n",
              "1  1323907200  Everything is ok, except it just isn't as good...  \n",
              "2  1310601600  Best cat treat ever. There isn't anything comp...  \n",
              "3  1316131200  My two Corgis were thoroughly spoiled by my la...  \n",
              "4  1334793600  We used to have drive down to the specialty pe...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "vM5U8puGyniK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g2gdfKT_ynfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jy6qy71GyncX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xqDJfVYCyiTJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Quick Example About IMDB"
      ]
    },
    {
      "metadata": {
        "id": "HWX5uzcCyTXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c35fcfd1-b507-41c5-9c86-0ab63572b2ae"
      },
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Duc5MickzjXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Explore the data"
      ]
    },
    {
      "metadata": {
        "id": "XV-SjmOuzLGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22916fd1-34b7-4e62-c9ef-6edb0c634c13"
      },
      "cell_type": "code",
      "source": [
        "print(f'Training entries:{len(train_data)}, labels: {len(train_labels)}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries:25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1fcz7xFazgE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "579a5112-f457-45f2-f731-117709e21e70"
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Qt5Jt2ZznY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae37578b-48bc-49b1-9252-90ac552b528b"
      },
      "cell_type": "code",
      "source": [
        "print(len(train_data[0]), len(train_data[1]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "218 189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ctaxbgj2HzwU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6305Hw2zwhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cb3c23fa-e83d-498b-dfd5-be567d41bad4"
      },
      "cell_type": "code",
      "source": [
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "  \n",
        "decode_review(train_data[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> in with i like horrible business chinese charm would killer waited which explosion ? going at fun ? film make like lame character has novel <UNK> a all final sense ? real ? find character nothing <UNK> second perhaps they ? find valuable cover this city an br overall ? horror has i ? should shop was in with ? delightful 00 despite ? with their people is i like horrible an well it br garbage ? with this genre this is i taken that <UNK> ? she sex is and house and after ? ? product bud i final which returned be ? does is i an annoying ? film where if at man it's film sent be ? with is comedy you than some ? in perfect i get <UNK> and ? think plot windows it fun ? <UNK> the lou ? sequence at their like horrible wanted on getting night just the ? <UNK> rich br any other ? couple it someone then he decade more on why ? can't ajay that ? family with for still wanted on final ? such his lindsay that if at you interesting how film any ? family would i an g other is i once ? i boot seen could he it i pitiful was every he\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Bo8kdqoy0jyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prep the data"
      ]
    },
    {
      "metadata": {
        "id": "VHi72dxwz-X6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IjtaescM0lNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbc35852-686c-4bc9-87d5-8f07adceb880"
      },
      "cell_type": "code",
      "source": [
        "print(len(train_data[0]), len(train_data[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "02kpZ1_Y0p2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "5123254e-eb74-4b5e-943e-a87820ce8db8"
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5ss9w5G9571U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Toy Model"
      ]
    },
    {
      "metadata": {
        "id": "92CVNRYu1BWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ]
    },
    {
      "metadata": {
        "id": "7JGW7Hs80vKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1c343274-78d6-4552-ca40-d4a193b78dc1"
      },
      "cell_type": "code",
      "source": [
        "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6oQvq6sv1ikf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MOD2HXKd21XB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ]
    },
    {
      "metadata": {
        "id": "yymGCn-t2EeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create validation set\n",
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "or8eFQSy2S0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        },
        "outputId": "06e27d11-5781-4954-8aef-194a584f520d"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1) # means print out the training info"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 93us/sample - loss: 0.6914 - accuracy: 0.6069 - val_loss: 0.6884 - val_accuracy: 0.7118\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 1s 70us/sample - loss: 0.6832 - accuracy: 0.7348 - val_loss: 0.6774 - val_accuracy: 0.7399\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.6658 - accuracy: 0.7581 - val_loss: 0.6558 - val_accuracy: 0.7565\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.6366 - accuracy: 0.7686 - val_loss: 0.6231 - val_accuracy: 0.7608\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 1s 81us/sample - loss: 0.5956 - accuracy: 0.7976 - val_loss: 0.5816 - val_accuracy: 0.7912\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.5468 - accuracy: 0.8218 - val_loss: 0.5364 - val_accuracy: 0.8110\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.4955 - accuracy: 0.8379 - val_loss: 0.4897 - val_accuracy: 0.8287\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.4470 - accuracy: 0.8558 - val_loss: 0.4493 - val_accuracy: 0.8403\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.4043 - accuracy: 0.8698 - val_loss: 0.4149 - val_accuracy: 0.8508\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.3679 - accuracy: 0.8805 - val_loss: 0.3878 - val_accuracy: 0.8562\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3378 - accuracy: 0.8891 - val_loss: 0.3659 - val_accuracy: 0.8631\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3127 - accuracy: 0.8947 - val_loss: 0.3492 - val_accuracy: 0.8673\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.2921 - accuracy: 0.9009 - val_loss: 0.3348 - val_accuracy: 0.8730\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.2735 - accuracy: 0.9073 - val_loss: 0.3242 - val_accuracy: 0.8753\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.2578 - accuracy: 0.9119 - val_loss: 0.3157 - val_accuracy: 0.8781\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.2436 - accuracy: 0.9169 - val_loss: 0.3085 - val_accuracy: 0.8771\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.2303 - accuracy: 0.9211 - val_loss: 0.3026 - val_accuracy: 0.8798\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.2186 - accuracy: 0.9249 - val_loss: 0.2982 - val_accuracy: 0.8827\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.2079 - accuracy: 0.9279 - val_loss: 0.2938 - val_accuracy: 0.8841\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.1983 - accuracy: 0.9321 - val_loss: 0.2911 - val_accuracy: 0.8832\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.1883 - accuracy: 0.9376 - val_loss: 0.2888 - val_accuracy: 0.8837\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.1801 - accuracy: 0.9411 - val_loss: 0.2873 - val_accuracy: 0.8849\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.1718 - accuracy: 0.9451 - val_loss: 0.2871 - val_accuracy: 0.8840\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.1646 - accuracy: 0.9481 - val_loss: 0.2860 - val_accuracy: 0.8842\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.1571 - accuracy: 0.9509 - val_loss: 0.2854 - val_accuracy: 0.8854\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.1505 - accuracy: 0.9537 - val_loss: 0.2867 - val_accuracy: 0.8840\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.1443 - accuracy: 0.9561 - val_loss: 0.2867 - val_accuracy: 0.8847\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.1383 - accuracy: 0.9581 - val_loss: 0.2879 - val_accuracy: 0.8846\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.1330 - accuracy: 0.9613 - val_loss: 0.2902 - val_accuracy: 0.8841\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.1275 - accuracy: 0.9627 - val_loss: 0.2901 - val_accuracy: 0.8855\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.1219 - accuracy: 0.9656 - val_loss: 0.2919 - val_accuracy: 0.8861\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.1169 - accuracy: 0.9679 - val_loss: 0.2939 - val_accuracy: 0.8859\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.1122 - accuracy: 0.9691 - val_loss: 0.2968 - val_accuracy: 0.8840\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.1079 - accuracy: 0.9701 - val_loss: 0.2995 - val_accuracy: 0.8842\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.1037 - accuracy: 0.9723 - val_loss: 0.3030 - val_accuracy: 0.8830\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.0996 - accuracy: 0.9738 - val_loss: 0.3050 - val_accuracy: 0.8832\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.0954 - accuracy: 0.9750 - val_loss: 0.3081 - val_accuracy: 0.8821\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.0917 - accuracy: 0.9770 - val_loss: 0.3123 - val_accuracy: 0.8821\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.0885 - accuracy: 0.9777 - val_loss: 0.3168 - val_accuracy: 0.8808\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.0846 - accuracy: 0.9793 - val_loss: 0.3195 - val_accuracy: 0.8812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WHeCiV4M29rt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "yMYbBcsC2WT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "36ee4fb8-03ea-4632-f996-06352029954a"
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 40us/sample - loss: 0.3416 - accuracy: 0.8694\n",
            "[0.3415939032173157, 0.86944]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "guXwfhj33Deq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Graph of accuracy and loss overtime"
      ]
    },
    {
      "metadata": {
        "id": "zsJC1_Ch2bUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "058f13be-e52e-4e1d-a4d6-b0c95dfef5ea"
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "2u2Aj8-33NOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "97a0067d-953a-43e4-9201-327d9ad0c8f1"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngTG8JUkKjOEtSVJgDG9JkgLzCbH+x7laB5mZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1rzQ7kvo3XYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "acfbef40-aeee-460f-a874-77d22def3fe1"
      },
      "cell_type": "code",
      "source": [
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiJvEFgsHweTFnRuoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "y-FEefjF6Gvy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## seqCNN"
      ]
    },
    {
      "metadata": {
        "id": "sV9L5SfZ6LFY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ]
    },
    {
      "metadata": {
        "id": "WWDp2vCF6BHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _get_last_layer_units_and_activation(num_classes):\n",
        "    \"\"\"Gets the # units and activation function for the last network layer.\n",
        "\n",
        "    # Arguments\n",
        "        num_classes: int, number of classes.\n",
        "\n",
        "    # Returns\n",
        "        units, activation values.\n",
        "    \"\"\"\n",
        "    if num_classes == 2:\n",
        "        activation = 'sigmoid'\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = 'softmax'\n",
        "        units = num_classes\n",
        "    return units, activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9vHHbSk6CK0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import SeparableConv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "\n",
        "def sepcnn_model(blocks,\n",
        "                 filters,\n",
        "                 kernel_size,\n",
        "                 embedding_dim,\n",
        "                 dropout_rate,\n",
        "                 pool_size,\n",
        "                 input_shape,\n",
        "                 num_classes,\n",
        "                 num_features,\n",
        "                 use_pretrained_embedding=False,\n",
        "                 is_embedding_trainable=False,\n",
        "                 embedding_matrix=None):\n",
        "    \"\"\"Creates an instance of a separable CNN model.\n",
        "\n",
        "    # Arguments\n",
        "        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
        "        filters: int, output dimension of the layers.\n",
        "        kernel_size: int, length of the convolution window.\n",
        "        embedding_dim: int, dimension of the embedding vectors.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "        num_features: int, number of words (embedding input dimension).\n",
        "        use_pretrained_embedding: bool, true if pre-trained embedding is on.\n",
        "        is_embedding_trainable: bool, true if embedding layer is trainable.\n",
        "        embedding_matrix: dict, dictionary with embedding coefficients.\n",
        "\n",
        "    # Returns\n",
        "        A sepCNN model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Add embedding layer. If pre-trained embedding is used add weights to the\n",
        "    # embeddings layer and set trainable to input is_embedding_trainable flag.\n",
        "    if use_pretrained_embedding:\n",
        "        model.add(Embedding(input_dim=num_features,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=input_shape[0],\n",
        "                            weights=[embedding_matrix],\n",
        "                            trainable=is_embedding_trainable))\n",
        "    else:\n",
        "      model.add(Embedding(input_dim=num_features, \n",
        "                          output_dim=embedding_dim))\n",
        "      \n",
        "#         model.add(Embedding(input_dim=num_features,\n",
        "#                             output_dim=embedding_dim,\n",
        "#                             input_length=input_shape[0]))\n",
        "\n",
        "\n",
        "\n",
        "    for _ in range(blocks-1):\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(MaxPooling1D(pool_size=pool_size))\n",
        "#       model.add(Dropout(rate=dropout_rate))\n",
        "      \n",
        "\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "    model.add(Dense(op_units, activation=op_activation))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upjfXKm7indD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "blocks=1\n",
        "filters=64\n",
        "kernel_size=3\n",
        "embedding_dim=200\n",
        "dropout_rate=0.2\n",
        "pool_size=3\n",
        "\n",
        "input_shape=partial_x_train.shape[1:]\n",
        "num_classes=2\n",
        "num_features = min(len(word_index) + 1, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IZ0Tke6Gg-nE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = sepcnn_model(blocks=blocks,\n",
        "                                     filters=filters,\n",
        "                                     kernel_size=kernel_size,\n",
        "                                     embedding_dim=embedding_dim,\n",
        "                                     dropout_rate=dropout_rate,\n",
        "                                     pool_size=pool_size,\n",
        "                                     input_shape=input_shape,\n",
        "                                     num_classes=num_classes,\n",
        "                                     num_features=num_features,\n",
        "                        is_embedding_trainable = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iwxJa0GdhFNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "658f2639-1ece-432d-ee3b-8dc2c99fd867"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 200)         2000000   \n",
            "_________________________________________________________________\n",
            "separable_conv1d_18 (Separab (None, None, 128)         26328     \n",
            "_________________________________________________________________\n",
            "separable_conv1d_19 (Separab (None, None, 128)         16896     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_8 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,043,353\n",
            "Trainable params: 2,043,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6zoFyWq-65JA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ]
    },
    {
      "metadata": {
        "id": "EfWyOyJBlt8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile model with learning parameters.\n",
        "learning_rate=1e-3\n",
        "epochs=100\n",
        "batch_size=128\n",
        "loss = 'binary_crossentropy'\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMlBgnMZmj4h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bBIBSSybmS4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f4bb800d-7ee5-40a8-e87b-3f5959311004"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "            partial_x_train,\n",
        "            partial_y_train,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=(x_val, y_val),\n",
        "            verbose=1,  # Logs once per epoch.\n",
        "            batch_size=batch_size)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "15000/15000 [==============================] - 45s 3ms/sample - loss: 0.6933 - acc: 0.5007 - val_loss: 0.6933 - val_acc: 0.4947\n",
            "Epoch 2/100\n",
            "15000/15000 [==============================] - 45s 3ms/sample - loss: 0.6730 - acc: 0.5595 - val_loss: 0.5338 - val_acc: 0.7498\n",
            "Epoch 3/100\n",
            "15000/15000 [==============================] - 45s 3ms/sample - loss: 0.3540 - acc: 0.8497 - val_loss: 0.3019 - val_acc: 0.8777\n",
            "Epoch 4/100\n",
            "15000/15000 [==============================] - 45s 3ms/sample - loss: 0.2185 - acc: 0.9175 - val_loss: 0.2878 - val_acc: 0.8856\n",
            "Epoch 5/100\n",
            "15000/15000 [==============================] - 45s 3ms/sample - loss: 0.1573 - acc: 0.9432 - val_loss: 0.3040 - val_acc: 0.8863\n",
            "Epoch 6/100\n",
            "15000/15000 [==============================] - 45s 3ms/sample - loss: 0.1141 - acc: 0.9584 - val_loss: 0.3377 - val_acc: 0.8840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mZRF_wO9Q-VS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "L6z5AaUsDxpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b6e4fd8-7df6-4efa-d4a9-7bf119858d28"
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 22s 870us/sample - loss: 0.3644 - acc: 0.8692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DFnffRXDmi2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2785faf-86a1-4011-970e-75728337b059"
      },
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.364426405954361, 0.86924]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gx0JlQUCmizA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMjm69Cemilw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "otF9Kefs6cxZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Module to train sequence model.\n",
        "Vectorizes training and validation texts into sequences and uses that for\n",
        "training a sequence model - a sepCNN model. We use sequence model for text\n",
        "classification when the ratio of number of samples to number of words per\n",
        "sample for the given dataset is very large (>~15K).\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "\n",
        "FLAGS = None\n",
        "\n",
        "# Limit on the number of features. We use the top 10K features.\n",
        "TOP_K = 10000\n",
        "\n",
        "def get_num_classes(labels):\n",
        "    \"\"\"Gets the total number of classes.\n",
        "    # Arguments\n",
        "        labels: list, label values.\n",
        "            There should be at lease one sample for values in the\n",
        "            range (0, num_classes -1)\n",
        "    # Returns\n",
        "        int, total number of classes.\n",
        "    # Raises\n",
        "        ValueError: if any label value in the range(0, num_classes - 1)\n",
        "            is missing or if number of classes is <= 1.\n",
        "    \"\"\"\n",
        "    num_classes = max(labels) + 1\n",
        "    missing_classes = [i for i in range(num_classes) if i not in labels]\n",
        "    if len(missing_classes):\n",
        "        raise ValueError('Missing samples with label value(s) '\n",
        "                         '{missing_classes}. Please make sure you have '\n",
        "                         'at least one sample for every label value '\n",
        "                         'in the range(0, {max_class})'.format(\n",
        "                            missing_classes=missing_classes,\n",
        "                            max_class=num_classes - 1))\n",
        "\n",
        "    if num_classes <= 1:\n",
        "        raise ValueError('Invalid number of labels: {num_classes}.'\n",
        "                         'Please make sure there are at least two classes '\n",
        "                         'of samples'.format(num_classes=num_classes))\n",
        "    return num_classes\n",
        "\n",
        "\n",
        "\n",
        "def train_sequence_model(data,word_index,\n",
        "                         learning_rate=1e-3,\n",
        "                         epochs=100,\n",
        "                         batch_size=128,\n",
        "                         blocks=2,\n",
        "                         filters=64,\n",
        "                         dropout_rate=0.2,\n",
        "                         embedding_dim=200,\n",
        "                         kernel_size=3,\n",
        "                         pool_size=3):\n",
        "    \"\"\"Trains sequence model on the given dataset.\n",
        "    # Arguments\n",
        "        data: tuples of training and test data(not text) and labels.\n",
        "        word_index:\n",
        "        learning_rate: float, learning rate for training model.\n",
        "        epochs: int, number of epochs.\n",
        "        batch_size: int, number of samples per batch.\n",
        "        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
        "        filters: int, output dimension of sepCNN layers in the model.\n",
        "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
        "        embedding_dim: int, dimension of the embedding vectors.\n",
        "        kernel_size: int, length of the convolution window.\n",
        "        pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
        "    # Raises\n",
        "        ValueError: If validation data has label values which were not seen\n",
        "            in the training data.\n",
        "    \"\"\"\n",
        "    # Get the data.\n",
        "    # (train_texts, train_labels), (val_texts, val_labels) = data\n",
        "    \n",
        "    (train_data, train_labels), (test_data, test_labels) = data\n",
        "    \n",
        "    train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        #value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "    test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       #value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)\n",
        "    x_train = train_data[:15000]\n",
        "    y_train = train_labels[:15000]\n",
        "    \n",
        "    x_val = train_data[15000:]\n",
        "    y_val = train_labels[15000:]\n",
        "\n",
        "    # Verify that validation labels are in the same range as training labels.\n",
        "    num_classes = get_num_classes(train_labels)\n",
        "    unexpected_labels = [v for v in test_labels if v not in range(num_classes)]\n",
        "    if len(unexpected_labels):\n",
        "        raise ValueError('Unexpected label values found in the validation set:'\n",
        "                         ' {unexpected_labels}. Please make sure that the '\n",
        "                         'labels in the validation set are in the same range '\n",
        "                         'as training labels.'.format(\n",
        "                             unexpected_labels=unexpected_labels))\n",
        "\n",
        "    # Vectorize texts.\n",
        "#     x_train, x_val, word_index = vectorize_data.sequence_vectorize(\n",
        "#             train_texts, val_texts)\n",
        "    word_index = word_index\n",
        "\n",
        "    # Number of features will be the embedding input dimension. Add 1 for the\n",
        "    # reserved index 0.\n",
        "    num_features = min(len(word_index) + 1, TOP_K)\n",
        "\n",
        "    # Create model instance.\n",
        "    model = sepcnn_model(blocks=blocks,\n",
        "                                     filters=filters,\n",
        "                                     kernel_size=kernel_size,\n",
        "                                     embedding_dim=embedding_dim,\n",
        "                                     dropout_rate=dropout_rate,\n",
        "                                     pool_size=pool_size,\n",
        "                                     input_shape=x_train.shape[1:],\n",
        "                                     num_classes=num_classes,\n",
        "                                     num_features=num_features,\n",
        "                        is_embedding_trainable = True)\n",
        "\n",
        "    # Compile model with learning parameters.\n",
        "    if num_classes == 2:\n",
        "        loss = 'binary_crossentropy'\n",
        "    else:\n",
        "        loss = 'sparse_categorical_crossentropy'\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
        "\n",
        "    # Create callback for early stopping on validation loss. If the loss does\n",
        "    # not decrease in two consecutive tries, stop training.\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=2)]\n",
        "\n",
        "    # Train and validate model.\n",
        "    history = model.fit(\n",
        "            x_train,\n",
        "            y_train,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=(x_val, y_val),\n",
        "            verbose=2,  # Logs once per epoch.\n",
        "            batch_size=batch_size)\n",
        "\n",
        "    # Print results.\n",
        "    history = history.history\n",
        "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
        "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
        "\n",
        "    # Save model.\n",
        "    model.save('imdb_sepcnn_model.h5')\n",
        "    return history['val_acc'][-1], history['val_loss'][-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_LIwfOr-hfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "outputId": "5b340fe1-faea-4864-8c9e-295b8c160aac"
      },
      "cell_type": "code",
      "source": [
        " # Using the IMDB movie reviews dataset to demonstrate\n",
        "    # training sequence model.\n",
        "    imdb = tf.keras.datasets.imdb\n",
        "    data = imdb.load_data(num_words = 10000)\n",
        "    word_index = imdb.get_word_index()\n",
        "    train_sequence_model(data, word_index)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            " - 53s - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4967\n",
            "Epoch 2/100\n",
            " - 52s - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6932 - val_acc: 0.4967\n",
            "Epoch 3/100\n",
            " - 52s - loss: 0.6933 - acc: 0.4983 - val_loss: 0.6932 - val_acc: 0.4967\n",
            "Epoch 4/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d19016fada41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<PAD>\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_sequence_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-8e364ff8aa1a>\u001b[0m in \u001b[0;36mtrain_sequence_model\u001b[0;34m(data, word_index, learning_rate, epochs, batch_size, blocks, filters, dropout_rate, embedding_dim, kernel_size, pool_size)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Logs once per epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# Print results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "H70RqNJa67GI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}