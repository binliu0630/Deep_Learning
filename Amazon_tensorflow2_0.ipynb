{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_tensorflow2.0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smitaforward/Data_Science/blob/master/Amazon_tensorflow2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "iLgXXoFuxayL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "9f2dbd30-8519-49f6-9a58-101c130088da"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "# !pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 332.1MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.11.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.6.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (40.8.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.0.0a0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UQ631rmxxbuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31e63ad3-b3d9-42ea-9135-863599f20b3e"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MDsu4hZOyn1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CbJLB6frypxQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Amazon comments"
      ]
    },
    {
      "metadata": {
        "id": "KJ3ER5Qzyov3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " data_path = \"https://s3.amazonaws.com/tomk/h2o-world/megan/AmazonReviews.csv\"\n",
        "data = pd.read_csv(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efVH6iaCynyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "0fe2f3ed-944c-4ae8-8a66-23daeca8034a"
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Score</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>Time</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B00141QYSQ</td>\n",
              "      <td>A1YS02UZZGRDCT</td>\n",
              "      <td>Do Not Buy</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>41471</td>\n",
              "      <td>Evan Eberhardt</td>\n",
              "      <td>2</td>\n",
              "      <td>1348358400</td>\n",
              "      <td>These are made in China (do not buy ANY pet fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B0089SPEO2</td>\n",
              "      <td>A3JOYNYL458QHP</td>\n",
              "      <td>Less lemon and less zing</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>28582</td>\n",
              "      <td>coleridge</td>\n",
              "      <td>0</td>\n",
              "      <td>1323907200</td>\n",
              "      <td>Everything is ok, except it just isn't as good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B001PMCDK2</td>\n",
              "      <td>A14TTMM0Z03Y2W</td>\n",
              "      <td>my cat goes crazy for these!</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>389965</td>\n",
              "      <td>Lindsay S. Bradford</td>\n",
              "      <td>0</td>\n",
              "      <td>1310601600</td>\n",
              "      <td>Best cat treat ever. There isn't anything comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B002Q8JOSI</td>\n",
              "      <td>A17UQD2RSSQH5X</td>\n",
              "      <td>My dogs tell me these treats are YUMMY</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>212536</td>\n",
              "      <td>in the dark</td>\n",
              "      <td>1</td>\n",
              "      <td>1316131200</td>\n",
              "      <td>My two Corgis were thoroughly spoiled by my la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00176G870</td>\n",
              "      <td>A2F2MZW8EOGH5J</td>\n",
              "      <td>Yummy to the tummy</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>115971</td>\n",
              "      <td>daemoncycler \"When you arrive at a fork in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>1334793600</td>\n",
              "      <td>We used to have drive down to the specialty pe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ProductId          UserId                                 Summary  Score  \\\n",
              "0  B00141QYSQ  A1YS02UZZGRDCT                              Do Not Buy      1   \n",
              "1  B0089SPEO2  A3JOYNYL458QHP                Less lemon and less zing      3   \n",
              "2  B001PMCDK2  A14TTMM0Z03Y2W            my cat goes crazy for these!      5   \n",
              "3  B002Q8JOSI  A17UQD2RSSQH5X  My dogs tell me these treats are YUMMY      5   \n",
              "4  B00176G870  A2F2MZW8EOGH5J                      Yummy to the tummy      5   \n",
              "\n",
              "   HelpfulnessDenominator      Id  \\\n",
              "0                       2   41471   \n",
              "1                       0   28582   \n",
              "2                       0  389965   \n",
              "3                       1  212536   \n",
              "4                       0  115971   \n",
              "\n",
              "                                        ProfileName  HelpfulnessNumerator  \\\n",
              "0                                    Evan Eberhardt                     2   \n",
              "1                                         coleridge                     0   \n",
              "2                               Lindsay S. Bradford                     0   \n",
              "3                                       in the dark                     1   \n",
              "4  daemoncycler \"When you arrive at a fork in th...                     0   \n",
              "\n",
              "         Time                                               Text  \n",
              "0  1348358400  These are made in China (do not buy ANY pet fo...  \n",
              "1  1323907200  Everything is ok, except it just isn't as good...  \n",
              "2  1310601600  Best cat treat ever. There isn't anything comp...  \n",
              "3  1316131200  My two Corgis were thoroughly spoiled by my la...  \n",
              "4  1334793600  We used to have drive down to the specialty pe...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "APpvus3lynwW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qq-0iyeFynuA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LWrXC2Ooynrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JW1BPdoNynpU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0eks7KBynm-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GncVAdWHynko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vM5U8puGyniK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g2gdfKT_ynfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jy6qy71GyncX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xqDJfVYCyiTJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Quick Example About IMDB"
      ]
    },
    {
      "metadata": {
        "id": "HWX5uzcCyTXh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Duc5MickzjXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Explore the data"
      ]
    },
    {
      "metadata": {
        "id": "XV-SjmOuzLGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3e00b13-3c62-4389-9e50-89cd3911b8f4"
      },
      "cell_type": "code",
      "source": [
        "print(f'Training entries:{len(train_data)}, labels: {len(train_labels)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries:25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1fcz7xFazgE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5161ede2-424f-470e-95db-3e948b970096"
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Qt5Jt2ZznY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2529106f-bb34-4272-ce90-35b5b88b784e"
      },
      "cell_type": "code",
      "source": [
        "print(len(train_data[0]), len(train_data[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "218 189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a6305Hw2zwhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dc8762aa-a26e-41ca-d1e1-5a8c64033769"
      },
      "cell_type": "code",
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "  \n",
        "decode_review(train_data[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "Bo8kdqoy0jyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prep the data"
      ]
    },
    {
      "metadata": {
        "id": "VHi72dxwz-X6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IjtaescM0lNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a573b808-4cbc-4acd-a897-24317aee775c"
      },
      "cell_type": "code",
      "source": [
        "print(len(train_data[0]), len(train_data[1]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "02kpZ1_Y0p2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "064eea79-ad69-441a-9ee6-fb2f5df2f450"
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5ss9w5G9571U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Toy Model"
      ]
    },
    {
      "metadata": {
        "id": "92CVNRYu1BWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ]
    },
    {
      "metadata": {
        "id": "7JGW7Hs80vKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "9ac55aae-7468-43f0-8030-0d5038f7bb8c"
      },
      "cell_type": "code",
      "source": [
        "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6oQvq6sv1ikf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MOD2HXKd21XB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ]
    },
    {
      "metadata": {
        "id": "yymGCn-t2EeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "or8eFQSy2S0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        },
        "outputId": "35132817-3558-44e3-a0c0-c0730cc65e7b"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1) # means print out the training info"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 76us/sample - loss: 0.6922 - accuracy: 0.5755 - val_loss: 0.6907 - val_accuracy: 0.6998\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.6878 - accuracy: 0.7297 - val_loss: 0.6845 - val_accuracy: 0.7324\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 1s 58us/sample - loss: 0.6776 - accuracy: 0.7498 - val_loss: 0.6706 - val_accuracy: 0.7487\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.6574 - accuracy: 0.7661 - val_loss: 0.6467 - val_accuracy: 0.7653\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 1s 58us/sample - loss: 0.6263 - accuracy: 0.7841 - val_loss: 0.6137 - val_accuracy: 0.7818\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.5856 - accuracy: 0.8046 - val_loss: 0.5729 - val_accuracy: 0.7990\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.5391 - accuracy: 0.8267 - val_loss: 0.5290 - val_accuracy: 0.8110\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.4902 - accuracy: 0.8433 - val_loss: 0.4858 - val_accuracy: 0.8268\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.4444 - accuracy: 0.8597 - val_loss: 0.4480 - val_accuracy: 0.8361\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.4039 - accuracy: 0.8720 - val_loss: 0.4151 - val_accuracy: 0.8519\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.3698 - accuracy: 0.8809 - val_loss: 0.3893 - val_accuracy: 0.8567\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.3412 - accuracy: 0.8887 - val_loss: 0.3684 - val_accuracy: 0.8612\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.3167 - accuracy: 0.8946 - val_loss: 0.3521 - val_accuracy: 0.8659\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.2963 - accuracy: 0.8996 - val_loss: 0.3378 - val_accuracy: 0.8712\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.2780 - accuracy: 0.9052 - val_loss: 0.3266 - val_accuracy: 0.8731\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.2621 - accuracy: 0.9104 - val_loss: 0.3176 - val_accuracy: 0.8768\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.2479 - accuracy: 0.9154 - val_loss: 0.3105 - val_accuracy: 0.8787\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.2353 - accuracy: 0.9195 - val_loss: 0.3053 - val_accuracy: 0.8772\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 1s 58us/sample - loss: 0.2236 - accuracy: 0.9229 - val_loss: 0.2995 - val_accuracy: 0.8808\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.2128 - accuracy: 0.9262 - val_loss: 0.2954 - val_accuracy: 0.8816\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.2031 - accuracy: 0.9301 - val_loss: 0.2918 - val_accuracy: 0.8834\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.1936 - accuracy: 0.9347 - val_loss: 0.2893 - val_accuracy: 0.8831\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1851 - accuracy: 0.9379 - val_loss: 0.2873 - val_accuracy: 0.8839\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1771 - accuracy: 0.9417 - val_loss: 0.2884 - val_accuracy: 0.8824\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1701 - accuracy: 0.9453 - val_loss: 0.2852 - val_accuracy: 0.8844\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.1627 - accuracy: 0.9485 - val_loss: 0.2852 - val_accuracy: 0.8855\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1560 - accuracy: 0.9515 - val_loss: 0.2848 - val_accuracy: 0.8848\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1498 - accuracy: 0.9533 - val_loss: 0.2857 - val_accuracy: 0.8851\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.1436 - accuracy: 0.9567 - val_loss: 0.2858 - val_accuracy: 0.8848\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.1378 - accuracy: 0.9583 - val_loss: 0.2868 - val_accuracy: 0.8851\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.1325 - accuracy: 0.9613 - val_loss: 0.2882 - val_accuracy: 0.8858\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1274 - accuracy: 0.9634 - val_loss: 0.2902 - val_accuracy: 0.8838\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1227 - accuracy: 0.9649 - val_loss: 0.2913 - val_accuracy: 0.8858\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1182 - accuracy: 0.9669 - val_loss: 0.2934 - val_accuracy: 0.8856\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.1134 - accuracy: 0.9693 - val_loss: 0.2963 - val_accuracy: 0.8827\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1093 - accuracy: 0.9707 - val_loss: 0.2981 - val_accuracy: 0.8846\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.1054 - accuracy: 0.9714 - val_loss: 0.3008 - val_accuracy: 0.8852\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1018 - accuracy: 0.9729 - val_loss: 0.3039 - val_accuracy: 0.8842\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.0978 - accuracy: 0.9744 - val_loss: 0.3080 - val_accuracy: 0.8829\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 1s 59us/sample - loss: 0.0943 - accuracy: 0.9763 - val_loss: 0.3101 - val_accuracy: 0.8832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WHeCiV4M29rt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "yMYbBcsC2WT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fec26a40-761a-4827-c3f4-71eb2e921311"
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 38us/sample - loss: 0.3299 - accuracy: 0.8726\n",
            "[0.3298719537115097, 0.87264]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "guXwfhj33Deq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Graph of accuracy and loss overtime"
      ]
    },
    {
      "metadata": {
        "id": "zsJC1_Ch2bUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8521033-f0a6-4c15-c363-435c9ee79085"
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "2u2Aj8-33NOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "e21d34f0-edaf-4ea8-d17f-9a1ffa39b1a3"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8U/X+x/HXSdLdoi20LEEQKdAi\nevE6ELVMKQJqXdQBOOEKKCh4hV6xDpYoCogDXD8FlAq2jqvAFRUnigqXyygyFAQBadndzfj9EQlU\n0pKOtEn6fj4eeTTnJOec7zcnPZ98v+c7DIfD4UBERET8hqmuEyAiIiKVo+AtIiLiZxS8RURE/IyC\nt4iIiJ9R8BYREfEzCt4iIiJ+RsFb6rX09HSSk5NJTk4mMTGR7t27u5bz8vIqta/k5GRyc3MrfM/0\n6dN5++23q5PkGnfbbbeRmZlZI/tq164de/fu5ZNPPmH8+PHVOt4777zjeu7JZ+upcePG8cILL9TI\nvkTqiqWuEyBSlx577DHX8x49ejBt2jT+/ve/V2lfS5cuPeV7xowZU6V9+5vevXvTu3fvKm+fk5PD\nK6+8wo033gh49tmK1CcqeYtUYNCgQTz77LP07duX1atXk5uby5133klycjI9evTg9ddfd733WKnz\n+++/Z+DAgUyfPp2+ffvSo0cPVq1aBZQt9fXo0YOFCxdy/fXXc+mllzJ16lTXvl566SW6dOnCdddd\nx4IFC+jRo4fb9C1atIi+fftyxRVXcMstt/D7778DkJmZyX333UdaWhp9+vThyiuvZMuWLQDs3LmT\nG264gV69ejFmzBhsNttJ+/3iiy8YMGBAmXVXX301X375ZYWfwTGZmZncdtttpzzep59+yoABA+jT\npw/XXnst2dnZAKSmprJ7926Sk5MpKSlxfbYAb775JldeeSXJycncc889HDhwwPXZzpo1i9tvv53u\n3btz++23U1hYWN6pBWDTpk2kpqaSnJzM1VdfzVdffQVAfn4+I0aMoG/fvvTs2ZOHH36Y0tLScteL\n1DYFb5FTWL9+PR999BGdO3fmxRdf5IwzzmDp0qW88cYbTJ8+nT179py0zcaNGzn33HNZsmQJN998\nMy+++KLbff/www9kZGTw7rvvMn/+fPbu3cuWLVt45ZVXeP/993nrrbfKLXXu37+fxx9/nNdff53/\n/Oc/tGzZskx18JdffsnNN9/MsmXLuOiii3jjjTcAePrpp+nSpQvLly9nyJAhrF69+qR9d+nShb17\n97Jz507AGYD37t3LJZdc4vFncEx5x7NarYwbN44nnniCZcuW0aNHD5588kkAJk+eTNOmTVm6dCnB\nwcGuff33v//l1VdfZd68eSxdupRmzZoxffp01+tLly7l2Wef5ZNPPuHAgQN88skn5abLbrfzwAMP\ncOutt7J06VImTpzImDFjyMvL47333qNBgwYsWbKEZcuWYTab2bp1a7nrRWqbgrfIKSQlJWEyOf9V\nHn74YSZMmABAixYtiI2NZdeuXSdtExERQa9evQBITExk9+7dbvc9YMAAzGYzjRs3pmHDhuzZs4cf\nfviBCy+8kLi4OEJCQrjuuuvcbtuwYUN++uknmjRpAsDf//53V7AFaNOmDR07dgQgISHBFWB//PFH\nrrzySgA6derEWWedddK+g4OD6d69O5999hkAy5cvp1evXlgsFo8/g2PKO57FYuHbb7/lvPPOc5t+\nd1asWEGfPn1o2LAhADfccAPffPON6/WkpCROP/10LBYL8fHxFf6o2LVrF7m5ufTr1w+Ac845h2bN\nmrFu3TpiYmJYs2YNX3/9NXa7nccee4wOHTqUu16ktumet8gpnHbaaa7n69atc5U0TSYTOTk52O32\nk7aJiopyPTeZTG7fAxAZGel6bjabsdlsHDlypMwxGzdu7HZbm83GrFmz+Oyzz7DZbOTn59O6dWu3\naTi2b4DDhw+XOW6DBg3c7r9Pnz68+eabDBkyhOXLlzN8+PBKfQbHVHS8efPmkZWVRUlJCSUlJRiG\nUe5+AA4cOEBcXFyZfe3fv/+UeS5vX1FRUWWO2aBBAw4cOEC/fv04fPgwM2fO5JdffuGqq65i/Pjx\n9O3b1+36E2sHRGqDSt4ilfDggw/Sp08fli1bxtKlS4mOjq7xY0RGRlJQUOBa3rdvn9v3ffzxx3z2\n2WfMnz+fZcuWcd9993m0/wYNGpRpSX/snvFfXXbZZWzatInt27ezfft2Lr74YqDyn0F5x1u9ejUv\nv/wyL774IsuWLWPixImnTHujRo04dOiQa/nQoUM0atTolNu507BhQw4fPsyJczMdOnTIVapPTU1l\n0aJFfPzxx2zYsIH33nuvwvUitUnBW6QS9u/fT8eOHTEMg6ysLAoLC8sE2prQqVMnvv/+ew4cOEBJ\nSUm5wWH//v00b96cmJgYDh48yJIlS8jPzz/l/s877zzXveDVq1fz22+/uX1fcHAwl156KU899RQ9\ne/bEbDa7jluZz6C84x04cICGDRvSrFkzCgsLycrKoqCgAIfDgcVioaCgAKvVWmZf3bp145NPPuHg\nwYMALFy4kKSkpFPm2Z0zzjiDJk2a8PHHH7vSlpubS6dOnXj++edZvHgx4Kz5OOOMMzAMo9z1IrVN\nwVukEkaNGsWIESMYMGAABQUFDBw4kAkTJpQbAKuiU6dOpKSkkJKSwuDBg+nevbvb9/Xv359Dhw7R\nu3dvxowZw+jRo9m7d2+ZVuvuPPjgg3z++ef06tWLBQsWcMkll5T73j59+rB8+XL69u3rWlfZz6C8\n41122WXExcXRq1cv7rjjDoYMGUJUVBT33Xcf7dq147TTTqNr165l2gt06tSJoUOHcsstt5CcnMzR\no0e5//77K8xveQzD4JlnnmH+/Pn07duXiRMnMnPmTMLDw7n66qt5//336dOnD8nJyQQFBXH11VeX\nu16kthmaz1vE9zgcDleJbsWKFcyYMUPVsyLiopK3iI85cOAAF198Mb///jsOh4MlS5a4WmSLiIBK\n3iI+6e233+a1117DMAzOOussJk2a5GpIJSKi4C0iIuJnVG0uIiLiZxS8RURE/IzfjLCWk3PUo/dF\nR4dz8GDN9rutS8qPb1N+fJvy49uUn1OLjY1yuz7gSt4Wi7muk1CjlB/fpvz4NuXHtyk/VRdwwVtE\nRCTQKXiLiIj4GQVvERERP6PgLSIi4me82tp88uTJrF27FsMwSEtLo1OnTgD88ccfjB071vW+nTt3\nMmbMGAYMGODN5IiIiAQErwXvVatWsWPHDjIyMti2bRtpaWlkZGQAzqn05s2bB4DVamXQoEH06NHD\nW0kREREJKF6rNl+5ciW9evUCoE2bNhw+fJi8vLyT3peVlUWfPn2IiIjwVlJEREQCiteCd25uLtHR\n0a7lmJgYcnJyTnrfokWLuP76672VDBER8UHPPfcsgwYN4uabr+Paa/sxcuRQ0tIe9Gjbjz/+kC++\n+Lzc12fOnM7u3b9XOW0jRw7ll1+2Vnn72lBrI6y5m/9kzZo1nHXWWURGRp5y++jocI87wJc3Ig3A\nwoUweTJs3AgJCZCWBqmpHu22zlSUH3+k/Pg25ce31VV+avra+fjjjwCQmZnJli1beOihhzzedsiQ\nmyt8feLER6ueMCA42EJ0dESVPuvaOj9eC95xcXHk5ua6lvft20dsbGyZ96xYsYIuXbp4tD9Ph5yL\njY0qdyjVrCwLw4aFuZbXrYObboIjRwpJSbF6tP/aVlF+/JHy49uUH99WV/nx1rUzNjaKo0eLKCgo\nceVr9eofWbhwPgUFBYwceT9r1vzEihWfYrfb6dKlK3fcMZRXX53D6aefTuvWbcjMfAfDMLFjx690\n69aTO+4YysiRQ3nggX/y+eefkp+fx2+/7eD333dx331j6NKlK/Pn/x/Ll/+HZs2aY7VaSU29hc6d\n/+5KV0mJlYMH8/n11z1MmvQoeXlHsVqtjB79IO3atWfGjKfYtCkbm81GSsr1XHnlAGbMeIpt2zZT\nVFTiWlcTan141K5du7Js2TIANmzYQFxc3Ekl7HXr1tG+fXtvJeEkM2YEu10/c6b79VlZFpKSwmna\nNJKkpHCysvxmKHgRkRpT2WtndW3btpVnnplN+/YdAHjhhVeYO/f/WLLk3+Tnl207tXHjBv71r0d5\n6aXXeffdjJP2tW/fHzz99CxGjRrLBx9kcuTIYTIzFzFnzmuMHTuO//53dbnpWLTobRITO/Lcc3MY\nNWoMzz33DEeOHObbb7/mpZde48UXX8VqtbrWLVy40LXO27wWjTp37kxiYiKpqakYhkF6ejqZmZlE\nRUXRu3dvAHJycmjYsKG3knCSzZvd/1b5+eeT1//1l2Z2tvnPZd8tpYuIeEN5187y1lfX2We3JTjY\n+cMgNDSUkSOHYjabOXToEEeOHCnz3nbt2hMaGlruvjp1Og9w1gbn5eWxa9dOzjqrDSEhoYSEhNKh\nQ2K5227atJHBg+8EoH37BHbt2kmDBqfRosWZjBv3AN279yI5uR/BwcG0aHEm99xzD127diM5uV91\nP4JT8mpR8sS+3MBJpewPP/zQm4c/SXy8nezsk++b22xwzTVhJCXZuPxyK+edZ6/wl6aCt4jUJ+Vd\nO+Pj7V45XlBQEAB79+4hI2MBr722gPDwcAYNuvGk95rNFbeFOvF1h8OBwwEm0/EfHYZR/raGYZRp\nr2W3O/M7ffosfv55E598spSlSz/i2WefZ/r0Wezb9xvvvJPpWudN9WqEtdGjS9yuP/NMBytXmpky\nJYS+fSNo3z6S7Oza/aUpIuKryrt2jhrlfn1NOXToENHR0YSHh/Pzz5vYu3cvpaWl1dpn06ZN+eWX\nbVitVg4ePMimTdnlvrd9+wTWrPkRgPXr19G6dRv27NnNokULadeuPSNHjubw4cOudYmJia513lav\nbuI6S8yFzJwZzObNJuLj7YwaVUJKipUDB+Drry188YWZL76wcPiw+yDtrV+aIiK+qqJrpze1bRtP\nWFg499xzB+eccx5XX30t06c/SadO51Z5nzExDendO5m77x7MmWe2JiEhsdzS+4033sTkyY9x333/\nwG6388ADD9GoUSzr16/l00//Q1BQEP36XeVal5qaCpjo1++qKqfPU4bDXR8uH+RpC8uaaI3pcMDc\nuUFMmHDyfZQZMwq5+eayX9isLAszZhz/Uo8eXXNfarWW9W3Kj29TfnxbXeXn448/pHfvZMxmM4MH\np/LMM88RF9e42vv1Rn7Ka21er0renjIMGDaslLg4BzNnBrNpkwmLBUpKDKZMCSEsDK65xophqGGb\niIi/2b9/P0OHDiEoKJgrrkiukcBd21Ty9lBREcyeHczMmcEUFxtcdpmVJ58s4s47w9w25EhIsLFi\nhWd90yuiX9q+TfnxbcqPb1N+PNunO2p95aHQUBg7toQvv8ynZ08rX31lISkpgk2b1LBNRERqlyJM\nJbVu7eCttwp5/fVCYmMdOBzu+xmoYZuIiHiLgncVGAb062fl66/zueIK990WvN2FQkRE6i8F72qI\njIT584tITy8iPNzZdCA83MFzz6mxmoiIeI+Cdw0YMaKUrVvz6N+/lIICg8zMIIqL6zpVIiK+a9iw\n21m/fn2ZdS+9NJu3357v9v2rV//Iww//E4Bx4x446fV3383g1VfnlHu8rVu38NtvOwBITx9PcXFR\nVZPO9dcPoKCg+g2Sq0PBu4ZYLPDSS0X07m3l888tDB0aSjUHAhIRCVi9e/dhyZIlZdatWPEZvXpd\nccptp059ptLH++KLz9i58zcAHntsCiEh5Y+H7g/Uz7sGBQfDq68WcsstYSxZEsS998Lzzxdx4uA9\n3hzQRUTEX/TseQUjR97Nbbf9A4BNm7KJjY0lNjaOH374nldeeYmgoCCioqJ4/PGpZbbt168nH330\nKT/+uIpZs6YTE9OQhg0buab4nDTpUXJy9lFYWMgddwylSZOmvP9+Jl988RnR0dE88sh43nwzg7y8\no0yZ8jilpaWYTCbGjZuAYRhMmvQozZo1Z+vWLcTHt2PcuAlu87Bv3x9ltp82bSoWSySPPz6B/ftz\nKSkp4c47h/H3v1940rqLL76kWp+fgncNCw2FN94oZODAcDIzgwgLczB9ejEmkwZ0ERHf9OijIXz4\nYc2GgwEDrDz6aPn3D6OjY2jRogUbN64nIaEjn332Cb17JwNw9OhR0tMn0qxZc5544hG+/34l4eHh\nJ+1jzpzZTJjwBG3bxjN27H00a9aco0ePcOGFF9O3b39+/30XEyaM47XX5nPRRV3o1q0nCQkdXdu/\n8spL9O9/NT17XsHnny/ntdfmcuedw/j552wee2wy0dExpKRcydGjR4mKOrm/9V+3nz17NgMGXM/h\nw4d4/vmXOXr0KCtXfsO2bVtPWlddqjb3gshIePvtAs4918aCBcE8/HAIDkftz4krIuLL+vfvz6ef\nfgLAN998SbduPQE4/fTTefLJiYwcOZQ1a37iyBH3E33s2bOHtm3jATjvvM4AREU1IDt7A/fccweT\nJj1a7rYAP/+czd/+dj4AnTv/nS1bfgagefMWNGzYCJPJRKNGsSfNIV7e9hs3buTMM1tRUJDPE09M\nYPXqH+jV6wq366pLJW8vadAAMjIKSEkJ55VXggkLc7idNxw0oIuI1K1HHy2usJTsLb179+b551+g\nd+8+tGjRkgYNGgAwZcoTPPXUDFq1as0zzzxZ7vYnTu15bLDQTz5ZypEjR3j++Vc4cuQId901qIIU\nHJ/ys7TUimE49/fXiUrKH4i07PYmk4nQ0FDmzPk/1q37H0uWfMg333xFWlq623XVoajhRTExsGhR\nIW3a2HnuuRBiYtx/ATSgi4jUR5GRkbRp05Y333zdVWUOkJ+fR+PGTTh69CirV/9U7jSgjRrF8ttv\n23E4HKxZ8xPgnEa0adNmmEwmvvjiM9e2hmFgs9nKbN+hQwKrVzun/Pzvf3+iffsOlUr/X7fv2LGj\na57vc889j7Fjx7N9+69u11WXSt5eFhfn4N13C7jqqnB++839byUN6CIi9VXv3slMnJhOevoTrnXX\nXnsD99xzJy1atOSWWwbz2mtzGTp0+EnbDh06nIcffogmTZq6Jhfp1q0H48Y9wMaN6+nX7yri4uJ4\n/fWXOffcvzFjxlNl7p3fddc/mDLlCT788D0sliDGj5+A1ep5+6O/bv/000+Sl2dlzpznef/9TEwm\nEzffPIimTZudtK66NDFJLdm+3eDqq8PZs8dEkyZ2cnMNj+bE9dX8VJXy49uUH9+m/Pg2TQkagFq1\ncrB4cSFXXx3G3r0m5s4t5Jpr1MJcREQqT/e8a1HbtnYWLSokMtLBmDGh7NzpflITERGRiih417LE\nRDuTJxdx9KjBvfeGYldbNRERqSQF7zowcKCVvn1L+fZbCy+9FFTXyRERET+j4F0HDAOmTy+mUSM7\nkyeHkJ2t0yAiIp5T1KgjjRo5mDGjiJISg+HDQzULmYiIeEzBuw5dcYWNQYNK2LDBzLRpGiJVREQ8\no+Bdxx57rJhWrezMnh3Md98dH5IvK8tCUlI4FgskJYWTlaVefSIi4qTgXcciI2H27EIMA0aODOXo\n0eOzj2Vnm7HZjs8+pgAuIiKg4O0TLrzQOdLab7+ZmDAhRLOPiYhIhVSU8xFjxpSwfLmFt94KxmRy\nP2KtZh8TERFQydtnBAfDCy8UERLiwChn4DXNPiYiIqDg7VPatbMzYUIxNpv76K3Zx0REBBS8fc5d\nd5Vy2WXOCUuaNrVjsUBCgo05cwornH1MRETqD93z9jEmE8yaVURSUgSHDxts2gQNGhTUdbJERMSH\nqOTtg5o3d/Dkk0UUFBgMGYImLxERkTIUvH3Utdda6d+/lG++Qf27RUSkDAVvH2UY8OijxYSEwKRJ\nIRQW1nWKRETEVyh4+7CWLR2MGgW7dpmYO1cDtIiIiJNXg/fkyZMZOHAgqamp/O9//yvz2p49e7jp\nppu4/vrreeSRR7yZDL+WlgYNG9qZOTOYnJxyOoCLiEi94rXgvWrVKnbs2EFGRgaTJk1i0qRJZV6f\nOnUqd9xxB4sXL8ZsNrN7925vJcWvnXYaPPhgCXl5hmYeExERwIvBe+XKlfTq1QuANm3acPjwYfLy\n8gCw2+389NNP9OjRA4D09HSaNWvmraT4vcGDS2nb1sa8eUFs2qQ7HSIi9Z3XmjHn5uaSmJjoWo6J\niSEnJ4fIyEgOHDhAREQEU6ZMYcOGDfz9739nzJgxFe4vOjoci8Vc4XuOiY2NqlbafU3TplE8+yz0\n7w9TpkTw8cd1naLqCbTzo/z4NuXHtyk/VVNrfZAcDkeZ53/88QeDBw+mefPmDB06lBUrVtCtW7dy\ntz940LOBSmJjo8jJOVrd5PqMY/m54AK47LIwliyx8M47BXTvbqvrpFVJoJ6fQKH8+Dblx7d5Iz/l\n/RjwWh1sXFwcubm5ruV9+/YRGxsLQHR0NM2aNaNly5aYzWa6dOnCli1bvJWUgGAY8NhjxRiGg0cf\nDcHmn7FbRERqgNeCd9euXVm2bBkAGzZsIC4ujsjISAAsFgstWrRg+/btrtdbt27traQEjI4d7dx0\nUynZ2WbefjuorpMjIiJ1xGvBu3PnziQmJpKamsrEiRNJT08nMzOTTz75BIC0tDTGjx9PamoqUVFR\nrsZrUrFx40oID3cwZUowf7b/IyvLQlJSOE2bRpKUFK4R2UREApxXr/Jjx44ts9y+fXvX8zPPPJO3\n337bm4cPSE2aOBgxooSnngph9uxg2rWzM2xYmOv17Gzzn8uahUxEJFCp35EfGj68hCZN7Lz4YjBP\nPeW+7/fMmeoTLiISqBS8/VBEBKSlFVNYaLBtm/tTuHmzTq2ISKDSFd5P3XijlY4dbTgc7odMjY/X\nPKIiIoFKwdtPmUzOrmPlGTWqpBZTIyIitUnB249ddpmNPn2cjdLOOMOGxeIgIcHGnDlqrCYiEsjU\np8jPpacX8emnEQQHG2zfnkew2qmJiAQ8lbz93NlnOxgypJRffjHx5psauEVEpD5Q8A4AY8aUEBHh\n4Nlng8nPr+vUiIiItyl4B4BGjRwMG1ZCTo6JV19VvbmISKBT8A4Qw4eXcPrpDmbPDubw4bpOjYiI\neJOCd4Bo0ABGjizh0CGDF19U6VtEJJApeAeQO+8sIS7OzksvBZOT437wFhER8X8K3gEkIgLuv7+E\nggKDWbNU+hYRCVQK3gHm1ltLadHCzv/9XxC7d6v0LSISiBS8A0xICIwdW0xxscH06Sp9i4gEIgXv\nAHTDDVbOPtvGW28F8csvKn2LiAQaBe8AZLHAuHEl2GwG06aF1HVyRESkhil4B6j+/Z1ThmZlWdi4\nUadZRCSQ6KoeoEwmSEsrxuEwmDpV975FRAKJgncA69nTxgUX2Fi6NIjVq01kZVlISgqnadNIkpLC\nycrSpHIiIv5IV+8AZhjwr38Vc8014dx/fyjZ2WbXa9nZZoYNCwM097eIiL9RyTvAXXKJjW7drGUC\n94lmzlSVuoiIv1HwrgfGjy8u97XNm/UVEBHxN7py1wN/+5udqCiH29fi4+21nBoREakuBe964oEH\n3Je+R40qqeWUiIhIdSl41xMjRpRy0UXOhmkmk4OEBBtz5qixmoiIP1Jr83pk1qwiunaNoGVLB598\nUkBQUF2nSEREqkIl73qkdWsHt9xSyi+/mFi4UJFbRMRfKXjXM2PGlBAW5uCpp4IpLKzr1IiISFUo\neNczTZo4uOuuEvbuNfHaayp9i4j4IwXveujee0s47TQHs2aFcORIXadGREQqS8G7Hjr9dGcAP3jQ\n4IUXNMKaiIi/UfCup+66q4S4ODsvvRTMvn1GXSdHREQqQcG7ngoPdzZeKygwmDFDpW8REX+i4F2P\n3XprKa1a2XnjjSB27FDpW0TEXyh412NBQfDQQ8WUlho89VRIXSdHREQ85NUR1iZPnszatWsxDIO0\ntDQ6derkeq1Hjx40adIEs9k5VeXTTz9N48aNvZkccSMlxcpzz9lYtMjCiBEmOnTQRCUiIr7Oa8F7\n1apV7Nixg4yMDLZt20ZaWhoZGRll3vPyyy8TERHhrSSIB0wm+Ne/irnllnCmTAnmzTeL6jpJIiJy\nCl6rNl+5ciW9evUCoE2bNhw+fJi8vDxvHU6qoVcvGxddZGXp0iB++EF3UkREfJ3XrtS5ublER0e7\nlmNiYsjJySnznvT0dG666SaefvppHA73802L9xkG/OtfzqlBJ00KQadCRMS31dqsYn8Nzvfddx+X\nXXYZp512GiNGjGDZsmUkJyeXu310dDgWi9mjY8XGRlUrrb6mNvIzYAD06wcffWRhzZoo+vTx3rF0\nfnyb8uPblB/fVlv58VrwjouLIzc317W8b98+YmNjXcvXXHON6/nll1/O5s2bKwzeBw8WeHTc2Ngo\ncnKOViHFvqk28zN2rImPPw7n7rsdREQ42LLFRHy8ndGjS2ps3m+dH9+m/Pg25ce3eSM/5f0Y8Fq1\nedeuXVm2bBkAGzZsIC4ujsjISACOHj3KnXfeSUmJs6r2hx9+oG3btt5KingoMdHOBRfY2LnTxKZN\nZmw2g+xsM8OGhZGVpanfRUR8hdeuyJ07dyYxMZHU1FQMwyA9PZ3MzEyioqLo3bs3l19+OQMHDiQk\nJISEhIQKS91Se/bvdz9Yy8yZwTVW+hYRkerxanFq7NixZZbbt2/vej5kyBCGDBnizcNLFWzf7r4y\nZvNmtUIXEfEVuiJLGfHx7gdpKW+9iIjUPgVvKWP06BK360eNcr9eRERqn4K3lJGSYmXOnELat7cB\nDgzDweOPF+l+t4iID1HwlpOkpFj58ssCXn21CIfD4PPPLRq4RUTEhyh4S7n697fSrZuVzz+38O9/\nq6uYiIivUPCWchkGTJ1aRHCwgwkTQtDQ9CIivkHBWyp01lkORo4sYfduE888E1zXyRERERS8xQP3\n3VdCy5Z2XnopmJ9/1ldGRKSu6UospxQeDpMmFWG1Gjz0kGYdExGpawre4pE+fWz06WPl228tvPuu\nGq+JiNQlBW/x2MSJRYSGOkhPD+HIkbpOjYhI/aXgLR4780wHo0eXkJNj4sknQ+o6OSIi9ZaCt1TK\niBElnHWWnVdfDWLdOn19RETgYcqMAAAgAElEQVTqgq6+UikhITBlShF2u8FDD4Vi13wlIiK1TsFb\nKq17dxsDBpTy449mFi5U4zURkdqm4C1V8sQTxYSHO3jiiRAOHqzr1IiI1C8K3lIlzZo5GDu2mP37\nTUyapMZrIiK1ScFbqmzYsFKaNrXz5ptBNGkSSVJSOFlZqkYXEfE2BW+psn//28KePSbAwG43yM42\nM2xYmAK4iIiXKXhLlc2Y4X6ikpkzNYGJiIg3KXhLlW3e7P7rU956ERGpGbrKSpXFx7vv5N2mjTp/\ni4h4k4K3VNno0SVu10dHa9oxERFvUvCWKktJsTJnTiEJCTYsFgcdOtho1crOd99Z+OADNVoTEfEW\nXWGlWlJSrKSkWF3L27YZ9OgRwYMPhnLhhfk0aaJSuIhITVPJW2pUmzYOHn20mIMHDUaNCsWh2C0i\nUuMUvKXG3XZbKT16WPn8cwuvvx5U18kREQk4Ct5S4wwDZs4sIjrawWOPhbB1q1HXSRIRCSgK3uIV\njRs7ePrpIgoLDUaMCKO0tK5TJCISOBS8xWsGDLBy442lrFlj5tlnNeqaiEhNUfAWr5o8uYgzzrDz\n7LPB/PSTvm4iIjVBV1PxqgYNYPbsIux2GDEijPz8uk6RiIj/U/AWr7vkEhv33FPKL7+YGDOmrlMj\nIuL/FLylVowfX0yHDjbmzEHdx0REqsmj4L1+/Xo+//xzAJ599lmGDBnCjz/+6NWESWAJCYE33igk\nLg7Gjw/h4481uJ+ISFV5FLwnTpxI69at+fHHH1m3bh0TJkxg1qxZ3k6bBJCsLAtDhoSRmwsOB9x9\ndyirVqniR0SkKjy6eoaEhNCqVSs+/fRTbrzxRs4++2xMJl14xTNZWRaGDQsjO9uM3Q4Oh0FpqcHA\ngeEawEVEpAo8isCFhYUsWbKE5cuXc+mll3Lo0CGOHDlyyu0mT57MwIEDSU1N5X//+5/b90yfPp1B\ngwZVLtXiV2bMcN/HOz/fIDU1nD/+UAAXEakMj4L3Aw88wIcffsj9999PZGQk8+bN47bbbqtwm1Wr\nVrFjxw4yMjKYNGkSkyZNOuk9W7du5YcffqhSwsV/bN7s/mtmMjn47TcTN98cRl5eLSdKRMSPeRS8\nL774YqZNm8aVV15Jbm4uXbp0oX///hVus3LlSnr16gVAmzZtOHz4MHl/uUJPnTqV+++/v4pJF38R\nH293u75dOzuDBpWwbp2ZO+/UEKoiIp7yqMnvE088Qfv27enduzepqal07NiRDz74gMcff7zcbXJz\nc0lMTHQtx8TEkJOTQ2RkJACZmZlceOGFNG/e3KOERkeHY7GYPXpvbGyUR+/zF/6en0cegZtucrfe\nzPXXmzlwAD76yEJaWhSvv+6c2MSf+Pv5+Svlx7cpP76ttvLjUfDeuHEjEyZM4O233yYlJYURI0Yw\nZMiQSh3IccLEzocOHSIzM5PXX3+dP/74w6PtDx4s8Oh9sbFR5OQcrVTafFkg5KdnT5gzx8LMmcFs\n3mwmPt7GqFEl9Oxp5eBBmD0b9uwJ5403zMTEFDN+fEldJ9ljgXB+TqT8+Dblx7d5Iz/l/RjwqNr8\nWOBdsWIFPXr0AKCkpOILbFxcHLm5ua7lffv2ERsbC8B3333HgQMHuOWWWxg5ciQbNmxg8uTJniRF\n/FRKipUVKwooLYUVKwpISbG6XouIgHnzCmnVys6zz4bwxhsaxEVEpCIeBe/WrVtz5ZVXkp+fT4cO\nHXjvvfc47bTTKtyma9euLFu2DIANGzYQFxfnqjJPTk7m448/5p133mH27NkkJiaSlpZWzayIP4uN\ndbBwYQGNGtl56KEQli717BaJiEh95FG1+cSJE9m8eTNt2rQB4Oyzz2batGkVbtO5c2cSExNJTU3F\nMAzS09PJzMwkKiqK3r17Vz/lEnDOOsvB/PmFXHttOMOGhfH224VccomtrpMlIuJzPAreRUVFfPbZ\nZ8ycORPDMDjvvPM4++yzT7nd2LFjyyy3b9/+pPecccYZzJs3z8PkSqDr3NnOyy8XMmRIGAMHhjF3\nbhF9+1pPvaGISD3iUbX5hAkTyMvLIzU1lRtvvJHc3Fwefvhhb6dN6qnevW3Mn1+I2Qy33x7KW29p\nHHQRkRN5dFXMzc3lmWeecS13795do6KJV/XoYePddwu45ZYwRo8OIze3mHvvLfG7bmQiIt7g8fCo\nhYWFruWCggKKi4u9ligRgPPPt/PBB4U0b25n4sQQHnkkBLv78V5EROoVj0reAwcOpG/fvnTs2BFw\nth4fNWqUVxMmAs7R2f797wIGDgxjzpxg9u83mDmziCD1JhOResyj4H399dfTtWtXNmzYgGEYTJgw\nQY3MpNY0b+7ggw8KuOWWcBYvDuLgQYNXXikkIqKuUyYiUjc8ntezadOm9OrVi549e9K4ceNyZwkT\nqa6sLAtJSeE0bRpJUlI4WVkWYmJg8eICevSw8umnFq6/PpyDB+s6pSIidaPKk3KfONypSE05ce5v\nm80gO9vMsGFhZGVZXCOxXXddKT/9ZOaqq8LZvVst2ESk/qly8DbU7Fe8oLy5v2fOdK4PCoLnny9i\n2LASfv7ZTL9+4WzZUuWvsYiIX6rwnndSUpLbIO1wODioOkvxgvLm/j5xvckEjz9eTGysg4kTQ+jT\nJ5ypU4u44QarupKJSL1QYfB+6623aisdIoCzdXl29snjmv91TnDDgPvuK6F5czsPPhjKyJFhfPpp\nKdOmFXGKYfdFRPxehcHb07m2RWrK6NElDBsWdtL6UaPcz2J33XVWzj8/n+HDw8jKCuKHH8w8/3wR\nXbpoTHQRCVy6WSg+JSXFypw5hSQk2LBYHCQk2Jgzp7DMFKJ/1aqVsyvZgw8Ws3u3wTXXhDF5cjCl\npbWYcBGRWqRBo8XnpKRYKwzW7lgs8OCDJSQlWRk+PIwZM0L44gsLL75YyFlnqWeEiAQWlbwloFx4\noZ3PP8/nxhtLWbPGTI8eESxYEIR6NopIIFHwloATFQWzZxcxZ04hFgvcf38od9wRyoEDdZ0yEZGa\noeAtASslxcqKFfl06WLlo4+C6NYtgiVLdKdIRPyfgrcEtDPOcJCZWUhaWjH79xsMGRLGkCGh/P67\nOoSLiP9S8JaAZzY7u6B9/nkBXbpYWbIkiEsvjWDu3CBs6lEmIn5IwVv8lrsJTCoSH28nK6uQGTMK\nCQqChx8OJTk5nP/9T/8GIuJfdNUSv1TRBCYVMZng5putfPNNPjfcUMratWauuCKcCRNCyMurpcSL\niFSTgrf4pVNNYHIqsbEOnn++iMWLCzjzTAdz5gRz2WURLF168tCsIiK+RsFb/JInE5h44vLLbXzx\nRT4PPFDMvn0GgweHc/vtoezcqQZtIuK7FLzFL/11opJTra9IaCiMG1fCZ58VcNFFzm5lF10Uwf33\nh/DrrwriIuJ7FLzFL40e7X6ikvImMPFEu3Z23n+/kBdeKKRVKzsLFgRzySURjBgRqjnDRcSn6Iok\nfqkqE5h4wmSC66+38tVXBcydW0h8vJ1Fi4K49NJwhg4NZeNG/cuISN3TcFPit6oygYmnzGa45hor\nV11lZckSC888E8x77wXx3ntBXHllKQ88UEKnTpWvohcRqQkqRohUwGSCfv2sLF9ewIIFBZx/vo2P\nPw6iV68IbrkljG+/RZOeiEitU/AW8YBhQO/eNj7+uIB33ing4outfPKJha5doVu3cF55JYhDh+o6\nlSJSXyh4i1SCYUC3bjY++KCQ994r4PrrYcsWE2lpoXTqFMnw4aF8951ZpXER8SoFbwl4lR1G1VOX\nXGJj0SL473/zmTChmGbNHCxeHMRVV4Vz6aXhvPBCELm56momIjVPwVsCWlWHUa2MuDgH995bwsqV\n+WRlFXDttaX89puJRx8N5dxzI7j77lC++MKsSVBEpMYoeEtAq+4wqpVhGNC1q42XXipi7do8Jk4s\nok0bO++/H8QNN4RzzjnOgV+WLTNTWFjjhxeRekTBWwJaTQ2jWlkxMTB0aClffFHAv/+dz6BBJRgG\nLFgQzKBB4XToEMntt4eSkWHhwAGvJkVEApD6eUtAi4+3k5198mQjVRlGtSoMAy680M6FFxbz1FPF\n/PSTiSVLLCxZEsRHHzkfZrODLl1sJCdbSU620rKlWruJSMUUvCWgjR5dwrBhYSetr84wqlVlMsEF\nF9i54IISHnmkhC1bjgVyC19/7Xw8/DDEx9u44IJjDztt2tgxqY5MpM4VFMC+fQb79hnk5Jhcz53L\nBtHRMG0ahIR4Py0K3hLQnCOwFTJzZjCbN5uIj7czalSJ10Zmq4y2be20bVvCffeVsHevwbJlzkD+\n/fdmNm82s2CB833R0Q7OP/94QD/vPBuRkXWbdpFAVVAAP/9sYuNGM9nZJrKzTezaZSInxyAvr+Le\nI82aQXFxAATvyZMns3btWgzDIC0tjU6dOrlee+edd1i8eDEmk4n27duTnp6OYahbjdQ8bw6jWlOa\nNHEwZEgpQ4aUYrVCdraJH38088MPzsfy5RaWL3f+u5rNDhIS7Fx4oY1LLrHRpYuNRo1U1S5SGTYb\nbN9usHGjmY0bTX8GajPbtxs4HGVjUWysnTPPtBMX5/jzYSc21nHCsoPYWDtt20aRm1s76fda8F61\nahU7duwgIyODbdu2kZaWRkZGBgCFhYV89NFHLFiwgKCgIAYPHsyaNWvo3Lmzt5Ij4jcsFjjnHDvn\nnGPn9ttLAfjjD8MVzH/80cTatWbWrTPz6qvObTp0sNG1q/PRpYuVmJg6zICIjyguhp07DbZvN7F9\nu4kdO0x/PjfYscNEUVHZIB0d7eCSS2x06GD/82GjfXu7xzVdtVn+9FrwXrlyJb169QKgTZs2HD58\nmLy8PCIjIwkLC+ONN94AnIE8Ly+P2NhYbyVFxGNZWRZmzDhexT56tG9UsTdu7KBfPyv9+jnTUlwM\n//2vmW+/NfPNN86gnp1t5pVXwDCcJfMTg/npp9dxBkS8wGqFPXsMdu0ysWuX8+9vvx0P1rt3n1yK\nBmjQwEF8vJ127ewkJDiDdUKCncaNHbUagKvDa8E7NzeXxMRE13JMTAw5OTlEnvATZu7cubz55psM\nHjyYFi1aeCspIh45NqDLMccGdIHqTzVa00JC4KKLbFx0kY3773cG8zVrnIH8WDDfsMHM3LnOYH72\n2c6LU2Ki82KVmGinWTP/uVBJ/eJwQF4e7N9vcPCgwf79Br//buL33w127jweqPfsMbDb3X+JmzWz\n06WLjTPPdNCqlZ1WrZxV361a2YmOrt1SsjcYDod3RmGeMGECSUlJrtL3TTfdxOTJk2ndunWZ9xUV\nFXH33XczevRozj///HL3Z7XasFhO7vIjUlM6dYJ169yvX7u29tNTHUVF8P33sGKF87FmDRw+XPY9\n0dHOvJ177vG/iYkQdnLjfJEaUVgIO3bAr7/C9u2waxfk5jof+/cf/7t/P5SWlr8fkwmaN4eWLeHM\nM48/WraEVq2gdWsIDa2tXNUNr5W84+LiyD3hzv2+fftcVeOHDh1iy5YtXHDBBYSGhnL55ZezevXq\nCoP3wYMFHh03NjaKnJyj1Uu8D1F+as/GjZHAyT/HN250kJOT53YbX85PQoLzMXy4sySza5fBhg0m\nNmxwNtDZsMHMl18afPHF8TwbBrRoYadtWztnn23/s0W883mjRv5XUvfl81MVvpwfhwPy851dqZzV\n184qbOdf5/N9+yru83j66Q6iox106uQgJsb5iI52/m3a1E6LFg7OOMNO06YOgoLK38/Ro85HbfPG\n+YmNjXK73mvBu2vXrjz33HOkpqayYcMG4uLiXFXmVquVcePG8cEHHxAREcG6deu46qqrvJUUEY/U\n9YAu3uQMyg5atLCRnHx8kPX8fNi06XhA37YtmI0b4dNPLXz6adl9REc7/gzoNtq0OX4RbdrUTpMm\njlrpHiO1x2p1fj/y851dpI4ehZwcZwA+1q/Z2cf5+HJBgftfd2azg+bNHVx2mZWWLZ1BuGVLO4mJ\nYZjN+cTEODj9dAcWdV72mNc+qs6dO5OYmEhqaiqGYZCenk5mZiZRUVH07t2bESNGMHjwYCwWC+3a\ntaNnz57eSoqIR3xpQJfaEhEB559v5/zznT9QYmODycnJ59Ah2LrVxNatJrZscT62bjWxerWJH35w\nf/uqYUNnED8W0J1/HTRu7OxWExvroFEjB8E1P6y8VCAvD3JzncE1N9d0wnPn4+BBg/x8wxWoj/39\na0vs8pjNznN79tn2P7tMOWjWzHl/uWVLBy1aOL8L7gJzbCzk5Pj/j+O64LV73jXN06oIX65Wqgrl\np3ZlZVkqNaCLr+ensk6Vn5IS2LHDGch37zbYs8dgzx4Te/c6n+/ebSq39HXMaac5+8SeGNBjY50l\nr8LC4yW9goLjz/Pzcf3NzzeIjnbQurX9z4eDs85yPm/SxFFmNDp/Pz82G67PJD8fQkIi2b69gCNH\nDI4c4c+/zsfRo3D48PHl/fudwflU5wPAYnEQGQkREY4/HxAZ6XweHu58Hhnp7O98Yt/muDhntXZV\nRwD09/PzVwFRbS7ij/xhQJe6FByM6z64Ow6H817jnj2mPwO7s1o1J+d4ae/Y823bTG678ZQnPNzx\n58P5A2LjxpNrAEJDnS2LjwX1tm0hP7/szdHyiitms/MRFOQMZseem83OvvdBQc51DgcUFBgUFkJh\nYdm/J64vKgK73fn+Yw/n8Y0y6xwO54+i/PzjP1gKCo7ty93nE37KzyokxPmjqG1bu+vHUaNGJz4v\n+6MpJMT/W1/XNwreIlJjDAMaNIAGDey0a1fxe61WZ1egY8H8yBGDsLCyJcBjz8PDnUH0GIfDef/1\nl1+cA278+quJX34xuf5u2nRiYPePZschIc58RkQ4aNjQQYsWx0u+zr8OGjUKJiiomAYNHH9+zg7X\n47TTHERFOdep/UHgU/AWqYLjg7lAfHy4zwzm4k8sFufgM40bV/7OnWHwZ7WtjYsvLvuaw+G8x/vr\nrwbFxREcOXLy5Ol/LWU6HM5SstXqfNhsUFpqnPAcrFYDm825bXi4g7AwCAsr+/fE9SEhzi5NhuFs\npe/ucSwtISF41FjL2SYhcNtgiOcUvEUqyZ8Gc6mPDAPX/XRngyidEwk8mmhQpJJmzHDfXHrmTDWj\nFpHaoeAtUkmbN7v/tylvvYhITdPVRqSSyhu0JRAGcxER/6DgLVJJo0e7bzAUyIO5iIhvUfAWqaSU\nFCtz5hSSkGDDYoGEBBtz5qixmojUHgVvkSpISbGyYkUBpaWwYkVBhYE7K8tCUlI4TZtGkpQUTlaW\nOnmISPXoKiLiRepWJiLeoJK3iBepW5mIeIOCt4gXqVuZiHiDriAiXqRuZSLiDQreIl6kbmUi4g0K\n3iJeVLZbmaPCbmVqlS4intLVQcTLPJkjXK3SRaQyVPIW8QFqlS4ilaHgLeID1CpdRCpDVwYRH6BW\n6SJSGQreIj5ArdJFpDIUvEV8gFqli0hl6L9exEeoVbqIeEolbxE/olbpIgIK3iJ+Ra3SRQQUvEX8\nilqliwgoeIv4lcq2SlfjNpHApP9kET/ibJRWyMyZwWzebCI+3s6oUSXltkpX4zaRwKTgLeJnPGmV\nDhU3blPwFvFvqjYXCVBq3CYSuPRfLBKg1LhNJHApeIsEqMo0bjvWsM1iQQ3bRPyA/kNFApSnjdvU\nsE3E/yh4iwQwTxq3qWGbiP9RtblIPaeGbSL+R/+dIvWcGraJ+B8Fb5F6TqO2ifgfr/7XTZ48mbVr\n12IYBmlpaXTq1Mn12nfffcczzzyDyWSidevWTJo0CZNJvyVEalvZhm1m4uNtGrVNxMd5LVquWrWK\nHTt2kJGRwaRJk5g0aVKZ1x955BFmzZrFwoULyc/P56uvvvJWUkTkFFJSrKxYUUBpKaxYUVBuINaU\npCK+wWvBe+XKlfTq1QuANm3acPjwYfLy8lyvZ2Zm0qRJEwBiYmI4ePCgt5IiIjVEjdtEfIPXqs1z\nc3NJTEx0LcfExJCTk0NkZCSA6+++ffv45ptvGDVqVIX7i44Ox2Ixe3Ts2NioKqbaNyk/vq0+5Sch\nAdatc7feOGm7hQth8mTYuNG5XVoapKbWdGpPrT6dH3+k/FRNrbU0cTgcJ63bv38///jHP0hPTyc6\nOrrC7Q8eLPDoOLGxUeTkHK1SGn2R8uPb6lt+Ro4se8/7mBEjCsnJOV7V/td74+vWwU03wZEjtXtv\nvL6dH3+j/Hi2T3e8VtcVFxdHbm6ua3nfvn3Exsa6lvPy8rj77rsZPXo0l156qbeSISI1KCXFypw5\nhSQk2LBYHCQk2Jgz5+SArHvjIt7lteDdtWtXli1bBsCGDRuIi4tzVZUDTJ06lSFDhnD55Zd7Kwki\n4gXHGrft3p1XbuM23RsX8S6vVZt37tyZxMREUlNTMQyD9PR0MjMziYqK4tJLL+W9995jx44dLF68\nGID+/fszcOBAbyVHRGpRfLyd7OyT26i4G/glK8vCjBnHx18fPdp9NzUROc6r97zHjh1bZrl9+/au\n5+vXr/fmoUWkDo0eXeL23vhfB35Rv3GRqlEdlojUON0bF/EujWsoIl7hyYxmujcuUjX6DxGROlPZ\nSVE0rrqIk4K3iNSZykyKcuz+eHa2GZvNcN0fVwCX+kjBW0TqjKf3xkH3x0VOpOAtInXKk37jULn7\n48eq1y0WVL0uAUnBW0T8gqf3x8tWr6PqdQlICt4i4hc8vT+u6nWpDxS8RcQveHp/vLLdz9SCXfyR\nvqUi4jc86Tte2aFZNcKb+COVvEUkoFSm+5mq2MVfKXiLSEApW71Ohd3PqtKCXdXr4gv07RORgHOs\nej02NoqcnIJy3+dpFbuq18XXqOQtIvWWWrCLv1LwFpF6yxst2FW9LrVB3yoRqddqsgW7qteltqjk\nLSJyCqpeF1+j4C0icgoaIEZ8jb4pIiIe0AAx4ktU8hYRqSHeGiBGs6TJX+kbICJSQ5wl5kJmzgxm\n82YT8fF2Ro0qqdYAMSqhizsK3iIiNciT6nXwvIq9ohK6gnf9pWpzEZE64GkVuxrBiTsK3iIidcDT\nFuzuGruVt/5YFXt2thmbzXBVsSuABx4FbxGROpKSYmXFigJ2785jxYoCt9Xg3m4EpxK6f9LZEhHx\nYWUbwZmJj7epEZyo5C0i4uuOldBLSym3hA6eV7GrhO7/FLxFRAJETTeC0z1036XgLSISIGq6EVxl\nx2pXKb326JMVEQkgnvQzHz26pMw972Oq001N99Frl0reIiL1jDe6qWlGtdql4C0iUg/VdDe1ypbS\nNVZ79Sh4i4iIW56W0MHzUnrZRnCcshGc7qO7p09BRETK5elY7Z7eR6/MWO26j14+lbxFRKTaPC2l\nV6Z6Xf3RyxfYuRMRkVrjSSnd09nUQCPGVcSrJe/JkyczcOBAUlNT+d///lfmteLiYh566CGuvfZa\nbyZBRER8SGUawWnEuPJ5LXivWrWKHTt2kJGRwaRJk5g0aVKZ16dNm0aHDh28dXgREfFBZavXqbAR\nnEaMK5/XgvfKlSvp1asXAG3atOHw4cPk5eW5Xr///vtdr4uISP3h6VjtGjGufF4L3rm5uURHR7uW\nY2JiyMnJcS1HRkZ669AiIhIgarI/elVGjPOklF4X/dZr7WeEw+Go1vbR0eFYLCc3cnAnNjaqWsfy\nNcqPb1N+fJvy49tqIj9Dh0KDBjBlCmzcCAkJMH48pKaW7bqWkADr1p28fUKCcVI6Zs92f6znnw9j\n6NDjywsXwrBhx5ePBfkGDSA1tao5OjWvBe+4uDhyc3Ndy/v27SM2NrbK+zt4sMCj98XGRpGTc7TK\nx/E1yo9vU358m/Lj22oyPz17Oh8nOqGyF4CRIy1u+6KPGFFITk7ZEv3GjZGAcdJ7N250kJNz/Bbw\n44+HAycXLJ94wkbPnp7FrYqU9+PGa9XmXbt2ZdmyZQBs2LCBuLg4VZWLiEid8caIcZWpiq9JXit5\nd+7cmcTERFJTUzEMg/T0dDIzM4mKiqJ3797cd9997N27l19//ZVBgwZx4403MmDAAG8lR0REpMZH\njKtMv/Wa5NV73mPHji2z3L59e9fzWbNmefPQIiIiVeYM8IXMnBnM5s0m4uPtjBpVclLg9zTI1zTf\nafcuIiLiQzwppZcN8mbi421ug3xNU/AWERGphmNB3tkAr/qN1DyhiUlERET8jIK3iIiIn1HwFhER\n8TMK3iIiIn5GwVtERMTPKHiLiIj4GQVvERERP6PgLSIi4mcUvEVERPyM4ajuRNsiIiJSq1TyFhER\n8TMK3iIiIn5GwVtERMTPKHiLiIj4GQVvERERP6PgLSIi4mcsdZ2AmjR58mTWrl2LYRikpaXRqVOn\nuk5SlX3//feMGjWKtm3bAhAfH8+ECRPqOFWVt3nzZoYPH85tt93Grbfeyp49e/jnP/+JzWYjNjaW\np556iuDg4LpOpsf+mp9x48axYcMGTj/9dADuvPNOunXrVreJrIRp06bx008/YbVaGTZsGOecc45f\nn5+/5uezzz7z2/NTWFjIuHHj2L9/P8XFxQwfPpz27dv77flxl59ly5b57fk5pqioiP79+zN8+HC6\ndOlSa+cnYIL3qlWr2LFjBxkZGWzbto20tDQyMjLqOlnVcuGFFzJr1qy6TkaVFRQU8MQTT9ClSxfX\nulmzZnHzzTfTt29fnnnmGRYvXszNN99ch6n0nLv8ADzwwAN07969jlJVdd999x1btmwhIyODgwcP\nkpKSQpcuXfz2/LjLz8UXX+y35+fzzz+nY8eO3H333fz+++/ccccddO7c2W/Pj7v8/O1vf/Pb83PM\niy++yGmnnQbU7vUtYKrNV65cSa9evQBo06YNhw8fJi8vr45TVb8FBwfz8ssvExcX51r3/fff07Nn\nTwC6d+/OypUr6yp5leYuP/7sggsuYObMmQA0aNCAwsJCvz4/7vJjs9nqOFVVd+WVV3L33XcDsGfP\nHho3buzX58ddfvzdtlKUjs8AAAYiSURBVG3b2Lp1q6u2oDbPT8AE79zcXKKjo13LMTEx5OTk1GGK\nqm/r1q384x//4KabbuKbb76p6+RUmsViITQ0tMy6wsJCVzVSw4YN/eocucsPwPz58xk8eDD3338/\nBw4cqIOUVY3ZbCY8PByAxYsXc/nll/v1+XGXH7PZ7Lfn55jU1FTGjh1LWlqaX5+fY07MD/jv/w/A\nk08+ybhx41zLtXl+Aqba/K/8fdTXVq1aMXLkSPr27cvOnTsZPHgw//nPf/zm/pYn/P0cAVx99dWc\nfvrpdOjQgblz5zJ79mweeeSRuk5WpSxfvpzFixfz2muvccUVV7jW++v5OTE/69ev9/vzs3DhQrKz\ns3nwwQfLnBN/PT8n5ictLc1vz897773HeeedR4sWLdy+7u3zEzAl77i4OHJzc13L+/btIzY2tg5T\nVD2NGzfmyiuvxDAMWrZsSaNGjfjjjz/qOlnVFh4eTlFREQB//PGH31dBd+nShQ4dOgDQo0cPNm/e\nXMcpqpyvvvqKl156iZdffpmoqCi/Pz9/zY8/n5/169ezZ88eADp06IDNZiMiIsJvz4+7/MTHx/vt\n+VmxYgWffvopN954I4sWLeKFF16o1f+fgAneXbt2ZdmyZQBs2LCBuLg4IiMj6zhVVffBBx/w6quv\nApCTk8P+/fsD4h7RJZdc4jpP//nPf7jsssvqOEXVc++997Jz507Aeb/rWO8Af3D06FGmTZvGnDlz\nXK19/fn8uMuPP5+fH3/8kddeew1w3hYsKCjw6/PjLj+PPPKI356fGTNm8O677/LOO+9www03MHz4\n8Fo9PwE1q9jTTz/Njz/+iGEYpKen0759+7pOUpXl5eUxduxYjhw5QmlpKSNHjiQpKamuk1Up69ev\n58knn+T333/HYrHQuHFjnn76acaNG0dxcTHNmjVjypQpBAUF1XVSPeIuP7feeitz584lLCyM8PBw\npkyZQsOGDes6qR7JyMjgueeeo3Xr1q51U6dO5eGHH/bL8+MuP9deey3z58/3y/NTVFTEv/71L/bs\n2UNRUREjR46kY8eOPPTQQ355ftzlJzw8nKeeesovz8+JnnvuOZo3b86ll15aa+cnoIK3iIhIfRAw\n1eYiIiL1hYK3iIiIn1HwFhER8TMK3iIiIn5GwVtERMTPBOwIayICu3btIjk5mb/97W9l1iclJXHX\nXXdVe//ff/89M2bM4O233672vkTEcwreIgEuJiaGefPm1XUyRKQGKXiL1FMJCQkMHz6c77//nvz8\nfKZOnUp8fDxr165l6tSpWCwWDMPgkUce4eyzz2b79u1MmDABu91OSEgIU6ZMAcBut5Oenk52djbB\nwcHMmTMHgDFjxnDkyBGsVivdu3fnnnvuqcvsigQU3fMWqadsNhtt27Zl3rx53HTTTa654//5z38y\nfvx45s2bx+23385jjz0GQHp6OnfeeScLFizguuuuY8mSJYBzWsR7772Xd955B4vFwtdff823336L\n1WrlrbfeYuHChYSHh2O32+ssr/L/7d2xquJAAIXhP8ZKuJUKgjbapBNRSBUQbC3F0mcQBMUmYCWm\nsbDWVkuxsRMEBW1EFPQB7COYJ7jFbXZZ78LC3iJ6vnICCVOdOTOQkVej5i3y4u73O41G47exdrsN\ngOM4ABSLRSaTCUEQ4Ps++XweANu2abVaAJzPZ2zbBqBarQJfZ965XI5EIgFAKpUiCAIqlQqj0Yhm\ns0m5XKZerxOJqCuI/C8Kb5EX97cz71//jmwYBoZhfPsceNqeTdP8Yywej7NYLDgej6xWK2q1GvP5\n/Ol96CLy77QUFnlj+/0egMPhgGVZfHx8kEwmOZ1OAOx2OwqFAvDVzjebDQDL5ZLhcPjte7fbLev1\nmlKpRKfTIRaL4fv+D89G5H2oeYu8uGfb5plMBoDr9cpsNuPxeOB5HgCe5zEYDDBNk0gkQq/XA8B1\nXVzXZTqdEo1G6ff73G63p9/MZrN0u13G4zGmaeI4Dul0+ucmKfJmdKuYyJuyLIvL5UI0qjW8SNho\n21xERCRk1LxFRERCRs1bREQkZBTeIiIiIaPwFhERCRmFt4iISMgovEVEREJG4S0iIhIynyYYbG0S\nf3P2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1rzQ7kvo3XYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "784d775a-bb11-4c43-da4b-95dea46e3a5e"
      },
      "cell_type": "code",
      "source": [
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "y-FEefjF6Gvy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## seqCNN"
      ]
    },
    {
      "metadata": {
        "id": "sV9L5SfZ6LFY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ]
    },
    {
      "metadata": {
        "id": "WWDp2vCF6BHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _get_last_layer_units_and_activation(num_classes):\n",
        "    \"\"\"Gets the # units and activation function for the last network layer.\n",
        "\n",
        "    # Arguments\n",
        "        num_classes: int, number of classes.\n",
        "\n",
        "    # Returns\n",
        "        units, activation values.\n",
        "    \"\"\"\n",
        "    if num_classes == 2:\n",
        "        activation = 'sigmoid'\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = 'softmax'\n",
        "        units = num_classes\n",
        "    return units, activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9vHHbSk6CK0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import SeparableConv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "\n",
        "def sepcnn_model(blocks,\n",
        "                 filters,\n",
        "                 kernel_size,\n",
        "                 embedding_dim,\n",
        "                 dropout_rate,\n",
        "                 pool_size,\n",
        "                 input_shape,\n",
        "                 num_classes,\n",
        "                 num_features,\n",
        "                 use_pretrained_embedding=False,\n",
        "                 is_embedding_trainable=False,\n",
        "                 embedding_matrix=None):\n",
        "    \"\"\"Creates an instance of a separable CNN model.\n",
        "\n",
        "    # Arguments\n",
        "        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
        "        filters: int, output dimension of the layers.\n",
        "        kernel_size: int, length of the convolution window.\n",
        "        embedding_dim: int, dimension of the embedding vectors.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "        num_features: int, number of words (embedding input dimension).\n",
        "        use_pretrained_embedding: bool, true if pre-trained embedding is on.\n",
        "        is_embedding_trainable: bool, true if embedding layer is trainable.\n",
        "        embedding_matrix: dict, dictionary with embedding coefficients.\n",
        "\n",
        "    # Returns\n",
        "        A sepCNN model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Add embedding layer. If pre-trained embedding is used add weights to the\n",
        "    # embeddings layer and set trainable to input is_embedding_trainable flag.\n",
        "    if use_pretrained_embedding:\n",
        "        model.add(Embedding(input_dim=num_features,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=input_shape[0],\n",
        "                            weights=[embedding_matrix],\n",
        "                            trainable=is_embedding_trainable))\n",
        "    else:\n",
        "      model.add(Embedding(input_dim=num_features, \n",
        "                          output_dim=embedding_dim))\n",
        "      \n",
        "#         model.add(Embedding(input_dim=num_features,\n",
        "#                             output_dim=embedding_dim,\n",
        "#                             input_length=input_shape[0]))\n",
        "\n",
        "\n",
        "\n",
        "    for _ in range(blocks-1):\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(MaxPooling1D(pool_size=pool_size))\n",
        "\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "    model.add(Dense(op_units, activation=op_activation))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3NgP7HT-552A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7cbd379-4169-4188-8c0d-e45c4adb76c5"
      },
      "cell_type": "code",
      "source": [
        "input_shape=partial_x_train.shape[1:]\n",
        "input_shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "upjfXKm7indD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "blocks=1\n",
        "filters=64\n",
        "kernel_size=3\n",
        "embedding_dim=200\n",
        "dropout_rate=0.2\n",
        "pool_size=3\n",
        "\n",
        "input_shape=partial_x_train.shape[1:]\n",
        "num_classes=2\n",
        "num_features = min(len(word_index) + 1, TOP_K)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IZ0Tke6Gg-nE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = sepcnn_model(blocks=blocks,\n",
        "                                     filters=filters,\n",
        "                                     kernel_size=kernel_size,\n",
        "                                     embedding_dim=embedding_dim,\n",
        "                                     dropout_rate=dropout_rate,\n",
        "                                     pool_size=pool_size,\n",
        "                                     input_shape=input_shape,\n",
        "                                     num_classes=num_classes,\n",
        "                                     num_features=num_features,\n",
        "                        is_embedding_trainable = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iwxJa0GdhFNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "fea53569-2190-4d77-a5a4-a04709182b54"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 200)         2000000   \n",
            "_________________________________________________________________\n",
            "separable_conv1d_18 (Separab (None, None, 128)         26328     \n",
            "_________________________________________________________________\n",
            "separable_conv1d_19 (Separab (None, None, 128)         16896     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_5 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,043,353\n",
            "Trainable params: 2,043,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6zoFyWq-65JA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ]
    },
    {
      "metadata": {
        "id": "M5OHkX4LyvOs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "EfWyOyJBlt8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile model with learning parameters.\n",
        "learning_rate=1e-3\n",
        "epochs=100\n",
        "batch_size=64\n",
        "loss = 'binary_crossentropy'\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMlBgnMZmj4h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bBIBSSybmS4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1459
        },
        "outputId": "e272d7ee-23f7-4848-d439-67248eac552c"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "            partial_x_train,\n",
        "            partial_y_train,\n",
        "            epochs=epochs,\n",
        "            #callbacks=callbacks,\n",
        "            validation_data=(x_val, y_val),\n",
        "            verbose=1,  # Logs once per epoch.\n",
        "            batch_size=batch_size)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "15000/15000 [==============================] - 57s 4ms/sample - loss: 0.6930 - acc: 0.5023 - val_loss: 0.6832 - val_acc: 0.6416\n",
            "Epoch 2/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.3957 - acc: 0.8262 - val_loss: 0.2943 - val_acc: 0.8828\n",
            "Epoch 3/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.2082 - acc: 0.9199 - val_loss: 0.2814 - val_acc: 0.8890\n",
            "Epoch 4/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.1381 - acc: 0.9496 - val_loss: 0.3142 - val_acc: 0.8870\n",
            "Epoch 5/100\n",
            "15000/15000 [==============================] - 57s 4ms/sample - loss: 0.0902 - acc: 0.9676 - val_loss: 0.3707 - val_acc: 0.8846\n",
            "Epoch 6/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0591 - acc: 0.9797 - val_loss: 0.4566 - val_acc: 0.8798\n",
            "Epoch 7/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0368 - acc: 0.9885 - val_loss: 0.5653 - val_acc: 0.8761\n",
            "Epoch 8/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0304 - acc: 0.9907 - val_loss: 0.6526 - val_acc: 0.8701\n",
            "Epoch 9/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0242 - acc: 0.9921 - val_loss: 0.6880 - val_acc: 0.8728\n",
            "Epoch 10/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0141 - acc: 0.9964 - val_loss: 0.7359 - val_acc: 0.8736\n",
            "Epoch 11/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0119 - acc: 0.9969 - val_loss: 0.7789 - val_acc: 0.8723\n",
            "Epoch 12/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0128 - acc: 0.9960 - val_loss: 0.8360 - val_acc: 0.8667\n",
            "Epoch 13/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0114 - acc: 0.9964 - val_loss: 0.8711 - val_acc: 0.8693\n",
            "Epoch 14/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0114 - acc: 0.9966 - val_loss: 0.8903 - val_acc: 0.8698\n",
            "Epoch 15/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0098 - acc: 0.9972 - val_loss: 0.9232 - val_acc: 0.8699\n",
            "Epoch 16/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0093 - acc: 0.9973 - val_loss: 0.9298 - val_acc: 0.8691\n",
            "Epoch 17/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0110 - acc: 0.9964 - val_loss: 0.9562 - val_acc: 0.8648\n",
            "Epoch 18/100\n",
            "15000/15000 [==============================] - 55s 4ms/sample - loss: 0.0109 - acc: 0.9969 - val_loss: 0.9611 - val_acc: 0.8658\n",
            "Epoch 19/100\n",
            "15000/15000 [==============================] - 55s 4ms/sample - loss: 0.0075 - acc: 0.9982 - val_loss: 0.9987 - val_acc: 0.8659\n",
            "Epoch 20/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0070 - acc: 0.9981 - val_loss: 0.9836 - val_acc: 0.8673\n",
            "Epoch 21/100\n",
            "15000/15000 [==============================] - 56s 4ms/sample - loss: 0.0065 - acc: 0.9982 - val_loss: 1.0064 - val_acc: 0.8722\n",
            "Epoch 22/100\n",
            " 2432/15000 [===>..........................] - ETA: 41s - loss: 0.0036 - acc: 0.9984"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-71630ce64b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Logs once per epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             batch_size=batch_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "L6z5AaUsDxpT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFnffRXDmi2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gx0JlQUCmizA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMjm69Cemilw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "otF9Kefs6cxZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Module to train sequence model.\n",
        "Vectorizes training and validation texts into sequences and uses that for\n",
        "training a sequence model - a sepCNN model. We use sequence model for text\n",
        "classification when the ratio of number of samples to number of words per\n",
        "sample for the given dataset is very large (>~15K).\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "\n",
        "FLAGS = None\n",
        "\n",
        "# Limit on the number of features. We use the top 10K features.\n",
        "TOP_K = 10000\n",
        "\n",
        "def get_num_classes(labels):\n",
        "    \"\"\"Gets the total number of classes.\n",
        "    # Arguments\n",
        "        labels: list, label values.\n",
        "            There should be at lease one sample for values in the\n",
        "            range (0, num_classes -1)\n",
        "    # Returns\n",
        "        int, total number of classes.\n",
        "    # Raises\n",
        "        ValueError: if any label value in the range(0, num_classes - 1)\n",
        "            is missing or if number of classes is <= 1.\n",
        "    \"\"\"\n",
        "    num_classes = max(labels) + 1\n",
        "    missing_classes = [i for i in range(num_classes) if i not in labels]\n",
        "    if len(missing_classes):\n",
        "        raise ValueError('Missing samples with label value(s) '\n",
        "                         '{missing_classes}. Please make sure you have '\n",
        "                         'at least one sample for every label value '\n",
        "                         'in the range(0, {max_class})'.format(\n",
        "                            missing_classes=missing_classes,\n",
        "                            max_class=num_classes - 1))\n",
        "\n",
        "    if num_classes <= 1:\n",
        "        raise ValueError('Invalid number of labels: {num_classes}.'\n",
        "                         'Please make sure there are at least two classes '\n",
        "                         'of samples'.format(num_classes=num_classes))\n",
        "    return num_classes\n",
        "\n",
        "\n",
        "\n",
        "def train_sequence_model(data,word_index,\n",
        "                         learning_rate=1e-3,\n",
        "                         epochs=100,\n",
        "                         batch_size=128,\n",
        "                         blocks=2,\n",
        "                         filters=64,\n",
        "                         dropout_rate=0.2,\n",
        "                         embedding_dim=200,\n",
        "                         kernel_size=3,\n",
        "                         pool_size=3):\n",
        "    \"\"\"Trains sequence model on the given dataset.\n",
        "    # Arguments\n",
        "        data: tuples of training and test data(not text) and labels.\n",
        "        word_index:\n",
        "        learning_rate: float, learning rate for training model.\n",
        "        epochs: int, number of epochs.\n",
        "        batch_size: int, number of samples per batch.\n",
        "        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
        "        filters: int, output dimension of sepCNN layers in the model.\n",
        "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
        "        embedding_dim: int, dimension of the embedding vectors.\n",
        "        kernel_size: int, length of the convolution window.\n",
        "        pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
        "    # Raises\n",
        "        ValueError: If validation data has label values which were not seen\n",
        "            in the training data.\n",
        "    \"\"\"\n",
        "    # Get the data.\n",
        "    # (train_texts, train_labels), (val_texts, val_labels) = data\n",
        "    \n",
        "    (train_data, train_labels), (test_data, test_labels) = data\n",
        "    \n",
        "    train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        #value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "    test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       #value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)\n",
        "    x_train = train_data[:15000]\n",
        "    y_train = train_labels[:15000]\n",
        "    \n",
        "    x_val = train_data[15000:]\n",
        "    y_val = train_labels[15000:]\n",
        "\n",
        "    # Verify that validation labels are in the same range as training labels.\n",
        "    num_classes = get_num_classes(train_labels)\n",
        "    unexpected_labels = [v for v in test_labels if v not in range(num_classes)]\n",
        "    if len(unexpected_labels):\n",
        "        raise ValueError('Unexpected label values found in the validation set:'\n",
        "                         ' {unexpected_labels}. Please make sure that the '\n",
        "                         'labels in the validation set are in the same range '\n",
        "                         'as training labels.'.format(\n",
        "                             unexpected_labels=unexpected_labels))\n",
        "\n",
        "    # Vectorize texts.\n",
        "#     x_train, x_val, word_index = vectorize_data.sequence_vectorize(\n",
        "#             train_texts, val_texts)\n",
        "    word_index = word_index\n",
        "\n",
        "    # Number of features will be the embedding input dimension. Add 1 for the\n",
        "    # reserved index 0.\n",
        "    num_features = min(len(word_index) + 1, TOP_K)\n",
        "\n",
        "    # Create model instance.\n",
        "    model = sepcnn_model(blocks=blocks,\n",
        "                                     filters=filters,\n",
        "                                     kernel_size=kernel_size,\n",
        "                                     embedding_dim=embedding_dim,\n",
        "                                     dropout_rate=dropout_rate,\n",
        "                                     pool_size=pool_size,\n",
        "                                     input_shape=x_train.shape[1:],\n",
        "                                     num_classes=num_classes,\n",
        "                                     num_features=num_features,\n",
        "                        is_embedding_trainable = True)\n",
        "\n",
        "    # Compile model with learning parameters.\n",
        "    if num_classes == 2:\n",
        "        loss = 'binary_crossentropy'\n",
        "    else:\n",
        "        loss = 'sparse_categorical_crossentropy'\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
        "\n",
        "    # Create callback for early stopping on validation loss. If the loss does\n",
        "    # not decrease in two consecutive tries, stop training.\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=2)]\n",
        "\n",
        "    # Train and validate model.\n",
        "    history = model.fit(\n",
        "            x_train,\n",
        "            y_train,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=(x_val, y_val),\n",
        "            verbose=2,  # Logs once per epoch.\n",
        "            batch_size=batch_size)\n",
        "\n",
        "    # Print results.\n",
        "    history = history.history\n",
        "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
        "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
        "\n",
        "    # Save model.\n",
        "    model.save('imdb_sepcnn_model.h5')\n",
        "    return history['val_acc'][-1], history['val_loss'][-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_LIwfOr-hfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "outputId": "5b340fe1-faea-4864-8c9e-295b8c160aac"
      },
      "cell_type": "code",
      "source": [
        " # Using the IMDB movie reviews dataset to demonstrate\n",
        "    # training sequence model.\n",
        "    imdb = tf.keras.datasets.imdb\n",
        "    data = imdb.load_data(num_words = 10000)\n",
        "    word_index = imdb.get_word_index()\n",
        "    train_sequence_model(data, word_index)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            " - 53s - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4967\n",
            "Epoch 2/100\n",
            " - 52s - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6932 - val_acc: 0.4967\n",
            "Epoch 3/100\n",
            " - 52s - loss: 0.6933 - acc: 0.4983 - val_loss: 0.6932 - val_acc: 0.4967\n",
            "Epoch 4/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d19016fada41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<PAD>\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_sequence_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-8e364ff8aa1a>\u001b[0m in \u001b[0;36mtrain_sequence_model\u001b[0;34m(data, word_index, learning_rate, epochs, batch_size, blocks, filters, dropout_rate, embedding_dim, kernel_size, pool_size)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Logs once per epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# Print results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "H70RqNJa67GI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ]
    }
  ]
}