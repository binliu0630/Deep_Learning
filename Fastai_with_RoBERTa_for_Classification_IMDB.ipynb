{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fastai with RoBERTa for Classification IMDB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binliu0630/Deep_Learning/blob/master/Fastai_with_RoBERTa_for_Classification_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhUUxLacnqKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "b40b46ae-4c66-4949-95b9-1313e51ede6c"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 23.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 31.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 36.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 39.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 43.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 46.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 42.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 43.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 44.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 46.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 46.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 46.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 46.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 46.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 46.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 46.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 46.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Collecting sacremoses (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/24/0b86f494d3a5c7531f6d0c77d39fd8f9d42e651244505d3d737e31db9a4d/sacremoses-0.0.33.tar.gz (802kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.220)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 47.1MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 52.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.13.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.220 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.220)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.220->boto3->pytorch-transformers) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.220->boto3->pytorch-transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses, regex\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.33-cp36-none-any.whl size=833106 sha256=fbb4b96ffd96fde69c088064811ac97335ed754ad26ec7bf374c1fb028a6922c\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/87/56/e40575cca30d12fee8875d523b8878b7aba866a9f03b2fd983\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609222 sha256=8e04071b9ad36cdd3afcc1858b8a9be96db79e95c0a7ef900da0f870b651861c\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "Successfully built sacremoses regex\n",
            "Installing collected packages: sacremoses, sentencepiece, regex, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.33 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXVDhkq6wCc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "ac43e6c2-fa5f-46f2-9c03-0e42d89cfef1"
      },
      "source": [
        "pip install fastai"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.57)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.21.0)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.3.0)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.8)\n",
            "Requirement already satisfied: typing; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (3.7.4.1)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.1.21)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.3.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.16.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.24.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (19.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.0)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.1.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (7.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (19.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (41.2.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.0.18->fastai) (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WABWZdidvaAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRFg3nyrqK1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/devkosal/fastai_roberta/master/fastai_roberta_imdb/imdb_dataset.csv'\n",
        "data = pd.read_csv(url)\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JiG1YcgvYQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "84280562-a924-43ff-da01-a57c244ee98f"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            "review       50000 non-null object\n",
            "sentiment    50000 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5ZuZEZVxMMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1e595bd6-15b7-46a6-f0e5-a3160c0877ae"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPPkl1HmvfRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *\n",
        "from fastai.metrics import *\n",
        "from pytorch_transformers import RobertaTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqNIdBWowd3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a config object to store task specific information\n",
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "        \n",
        "config = Config(\n",
        "    testing=False,\n",
        "    seed = 2019,\n",
        "    roberta_model_name='roberta-base', # can also be exchnaged with roberta-large \n",
        "    max_lr=1e-5,\n",
        "    epochs=1,\n",
        "    use_fp16=False,\n",
        "    bs=4, \n",
        "    max_seq_len=256, \n",
        "    num_labels = 2,\n",
        "    hidden_dropout_prob=.05,\n",
        "    hidden_size=768, # 1024 for roberta-large\n",
        "    start_tok = \"<s>\",\n",
        "    end_tok = \"</s>\",\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTNaHzQhw6v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_cols = \"review\"\n",
        "label_cols = \"sentiment\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRJoLGbPxVjN",
        "colab_type": "text"
      },
      "source": [
        "SET UP TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM3MQ_jsxO2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastAiRobertaTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around RobertaTokenizer to be compatible with fastai\"\"\"\n",
        "    def __init__(self, tokenizer: RobertaTokenizer, max_seq_len: int=128, **kwargs): \n",
        "        self._pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len \n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self \n",
        "    def tokenizer(self, t:str) -> List[str]: \n",
        "        \"\"\"Adds Roberta bos and eos tokens and limits the maximum sequence length\"\"\" \n",
        "        return [config.start_tok] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [config.end_tok]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RorMbwm4xdRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f8a14079-931b-473e-be45-07135d399a7e"
      },
      "source": [
        "# create fastai tokenizer for roberta\n",
        "roberta_tok = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "fastai_tokenizer = Tokenizer(tok_func=FastAiRobertaTokenizer(roberta_tok, max_seq_len=config.max_seq_len), \n",
        "                             pre_rules=[], post_rules=[])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 898823/898823 [00:01<00:00, 701897.33B/s]\n",
            "100%|██████████| 456318/456318 [00:00<00:00, 533163.19B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26D-0IALxf9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create fastai vocabulary for roberta\n",
        "path = Path()\n",
        "roberta_tok.save_vocabulary(path)\n",
        "\n",
        "with open('vocab.json', 'r') as f:\n",
        "    roberta_vocab_dict = json.load(f)\n",
        "    \n",
        "fastai_roberta_vocab = Vocab(list(roberta_vocab_dict.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZU1l0bwxnCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting up pre-processors\n",
        "class RobertaTokenizeProcessor(TokenizeProcessor):\n",
        "    def __init__(self, tokenizer):\n",
        "         super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "class RobertaNumericalizeProcessor(NumericalizeProcessor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, vocab=fastai_roberta_vocab, **kwargs)\n",
        "\n",
        "\n",
        "def get_roberta_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
        "    \"\"\"\n",
        "    Constructing preprocessors for Roberta\n",
        "    We remove sos and eos tokens since we add that ourselves in the tokenizer.\n",
        "    We also use a custom vocabulary to match the numericalization with the original Roberta model.\n",
        "    \"\"\"\n",
        "    return [RobertaTokenizeProcessor(tokenizer=tokenizer), NumericalizeProcessor(vocab=vocab)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1c6kimRxwzC",
        "colab_type": "text"
      },
      "source": [
        "SET UP DATABUNCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSxsYnK0xsqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a Roberta specific DataBunch class\n",
        "class RobertaDataBunch(TextDataBunch):\n",
        "    \"Create a `TextDataBunch` suitable for training Roberta\"\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs:int=None, pad_idx=1,\n",
        "               pad_first=True, device:torch.device=None, no_check:bool=False, backwards:bool=False, \n",
        "               dl_tfms:Optional[Collection[Callable]]=None, **dl_kwargs) -> DataBunch:\n",
        "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
        "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
        "        val_bs = ifnone(val_bs, bs)\n",
        "        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
        "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)\n",
        "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
        "        dataloaders = [train_dl]\n",
        "        for ds in datasets[1:]:\n",
        "            lengths = [len(t) for t in ds.x.items]\n",
        "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
        "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
        "        return cls(*dataloaders, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z48Do8qzxyaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RobertaTextList(TextList):\n",
        "    _bunch = RobertaDataBunch\n",
        "    _label_cls = TextList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz8wQhOnx5Tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading the tokenizer and vocab processors\n",
        "processor = get_roberta_processor(tokenizer=fastai_tokenizer, vocab=fastai_roberta_vocab)\n",
        "\n",
        "# creating our databunch \n",
        "data = RobertaTextList.from_df(data, \".\", cols=feat_cols, processor=processor) \\\n",
        "    .split_by_rand_pct(seed=config.seed) \\\n",
        "    .label_from_df(cols=label_cols,label_cls=CategoryList) \\\n",
        "    .databunch(bs=config.bs, pad_first=False, pad_idx=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT2upgzgyPR4",
        "colab_type": "text"
      },
      "source": [
        "BUILDING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78O6ivheyBy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorch_transformers import RobertaModel\n",
        "\n",
        "# defining our model architecture \n",
        "class CustomRobertaModel(nn.Module):\n",
        "    def __init__(self,num_labels=2):\n",
        "        super(CustomRobertaModel,self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.roberta = RobertaModel.from_pretrained(config.roberta_model_name)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels) # defining final output layer\n",
        "        \n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _ , pooled_output = self.roberta(input_ids, token_type_ids, attention_mask) # \n",
        "        logits = self.classifier(pooled_output)        \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myTZ8DG5yYh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e63f3356-b114-42da-fec6-59684ce6da71"
      },
      "source": [
        "roberta_model = CustomRobertaModel(num_labels=config.num_labels)\n",
        "\n",
        "learn = Learner(data, roberta_model, metrics=[accuracy])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 473/473 [00:00<00:00, 118555.38B/s]\n",
            "100%|██████████| 501200538/501200538 [00:43<00:00, 11584418.04B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS7WaigGybm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "d4a971d7-66a5-49d9-e27c-be245fc3a2ae"
      },
      "source": [
        "learn.model.roberta.train() # setting roberta to train as it is in eval mode by default\n",
        "learn.fit_one_cycle(config.epochs, max_lr=config.max_lr)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.198077</td>\n",
              "      <td>0.154746</td>\n",
              "      <td>0.942600</td>\n",
              "      <td>39:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfXotOfaDU_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = learn.to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRHACQR1DpJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a06202b0-ebe0-4855-82e7-c4d3cfab973d"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDDzkOOzD2zM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "03452d19-9f6b-4154-dad7-0c760ca28030"
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy17KUQvECNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "d56d5844-53de-4f86-d7af-da2af785292f"
      },
      "source": [
        "learn.fit_one_cycle(2, 3e-05)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.221473</td>\n",
              "      <td>0.199842</td>\n",
              "      <td>0.924400</td>\n",
              "      <td>24:58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.177468</td>\n",
              "      <td>0.939900</td>\n",
              "      <td>24:57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DtvmBw7yzAt",
        "colab_type": "text"
      },
      "source": [
        "GETTING PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HARCjIP6yhbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    learn.model.roberta.eval()\n",
        "    preds = learn.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in data.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    ordered_preds = preds[reverse_sampler, :]\n",
        "    pred_values = np.argmax(ordered_preds, axis=1)\n",
        "    return ordered_preds, pred_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGD5YBUKy1YP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds, pred_values = get_preds_as_nparray(DatasetType.Valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-cpIxH90CKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17e68bea-8cc5-4663-9193-22878d17b6cb"
      },
      "source": [
        "# accuracy on valid\n",
        "(pred_values == data.valid_ds.y.items).mean()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9426"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtM1B-Y3gdRG",
        "colab_type": "text"
      },
      "source": [
        "Reference: \n",
        "https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vktb_4QK_y7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}