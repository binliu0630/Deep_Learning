{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fastai+Transformers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binliu0630/Deep_Learning/blob/master/Fastai%2BTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPYiMT_W5IzW",
        "colab_type": "text"
      },
      "source": [
        "## Get Started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8_w_l4o3n3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "b0286a7d-33b2-403b-a17d-b07035eba266"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n",
            "\r\u001b[K     |█                               | 10kB 26.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 28.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 33.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40kB 35.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51kB 37.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 61kB 39.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 71kB 39.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 81kB 40.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 92kB 40.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 112kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 122kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 133kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 143kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 153kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 163kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 174kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 184kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 194kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 204kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 215kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 225kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 235kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 245kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 256kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 266kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 276kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 286kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 296kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 307kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 317kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 327kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 337kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 348kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 358kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 368kB 41.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 48.1MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.27)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.27)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.27->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.27->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=4755975e18b38005792718f507a992056df3cc6f386083fec7e2a1b7b574aed3\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, regex, transformers\n",
            "Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzLZjdQl4Uz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "a837bd19-ebfe-493b-8b7b-aedcc030a8b0"
      },
      "source": [
        "import fastai\n",
        "import transformers\n",
        "print(f'fastai version: {fastai.__version__}')\n",
        "print(f'transformers version: {transformers. __version__}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "fastai version: 1.0.59\n",
            "transformers version: 2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl9AmI-b4fdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random\n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callback import *\n",
        "\n",
        "# transformer\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSuIToyD59ks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93187074-d1b1-410e-ba1e-aaa7137c0431"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYY6Agzi7z7N",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYmIsyEr7VSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"https://s3.amazonaws.com/tomk/h2o-world/megan/AmazonReviews.csv\"\n",
        "data = pd.read_csv(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45C0907D8UCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "7cb91f20-7935-4812-b85c-588c80b99800"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Score</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>Time</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B00141QYSQ</td>\n",
              "      <td>A1YS02UZZGRDCT</td>\n",
              "      <td>Do Not Buy</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>41471</td>\n",
              "      <td>Evan Eberhardt</td>\n",
              "      <td>2</td>\n",
              "      <td>1348358400</td>\n",
              "      <td>These are made in China (do not buy ANY pet fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B0089SPEO2</td>\n",
              "      <td>A3JOYNYL458QHP</td>\n",
              "      <td>Less lemon and less zing</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>28582</td>\n",
              "      <td>coleridge</td>\n",
              "      <td>0</td>\n",
              "      <td>1323907200</td>\n",
              "      <td>Everything is ok, except it just isn't as good...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ProductId  ...                                               Text\n",
              "0  B00141QYSQ  ...  These are made in China (do not buy ANY pet fo...\n",
              "1  B0089SPEO2  ...  Everything is ok, except it just isn't as good...\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTvqTd2u8Ypj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the binary label\n",
        "data['label'] = np.where(data['Score'] > 3, '1', '0')\n",
        "\n",
        "# change score into categorical so it can be the multiclass label\n",
        "data['Score'] = data['Score'].astype('category')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLV7zooI9Bv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "fddd6f4e-b054-4356-d17e-cf929ddb5b0a"
      },
      "source": [
        "data.sample()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Score</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>Time</th>\n",
              "      <th>Text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50921</th>\n",
              "      <td>B001UFFZ1I</td>\n",
              "      <td>A1L1RJE3R29CLI</td>\n",
              "      <td>Packed with Nutrition</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>434608</td>\n",
              "      <td>Skylar \"Health Nut\"</td>\n",
              "      <td>12</td>\n",
              "      <td>1256774400</td>\n",
              "      <td>This rice is good and very nutritious. It does...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        ProductId  ... label\n",
              "50921  B001UFFZ1I  ...     1\n",
              "\n",
              "[1 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qcaR02Z9WD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the data by timestamp\n",
        "timesplit = data['Time'].quantile(0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih5r1J2v9mwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f679d27-ca03-4943-84a2-622509bcabc9"
      },
      "source": [
        "train = data[data['Time'] < timesplit]\n",
        "test = data[data['Time'] >= timesplit]\n",
        "train.shape, test.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((79992, 11), (20008, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcw6FAxd9o13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J24EDqdy_k5T",
        "colab_type": "text"
      },
      "source": [
        "## FASTAI + TRANSFORMER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfH-1oNK-MQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLxLQ6Rf_9t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n",
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-base'\n",
        "\n",
        "model_type = 'bert'\n",
        "pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "model_type = 'distilbert'\n",
        "pretrained_model_name = 'distilbert-base-uncased-distilled-squad'#'distilbert-base-uncased'#'distilbert-base-uncased'\n",
        "\n",
        "# model_type = 'xlm'\n",
        "# pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "#model_type = 'xlnet'\n",
        "#pretrained_model_name = 'xlnet-base-cased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bx4EBkdALcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMOMJWyBAa8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4275edcc-a409-4b4d-dc97-73b4067d8cc3"
      },
      "source": [
        "# all the pretrained model for the specific model_class\n",
        "model_class.pretrained_model_archive_map"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'xlm-clm-ende-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-clm-ende-1024-pytorch_model.bin',\n",
              " 'xlm-clm-enfr-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-clm-enfr-1024-pytorch_model.bin',\n",
              " 'xlm-mlm-100-1280': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-100-1280-pytorch_model.bin',\n",
              " 'xlm-mlm-17-1280': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-17-1280-pytorch_model.bin',\n",
              " 'xlm-mlm-en-2048': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-en-2048-pytorch_model.bin',\n",
              " 'xlm-mlm-ende-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-ende-1024-pytorch_model.bin',\n",
              " 'xlm-mlm-enfr-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-enfr-1024-pytorch_model.bin',\n",
              " 'xlm-mlm-enro-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-enro-1024-pytorch_model.bin',\n",
              " 'xlm-mlm-tlm-xnli15-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-tlm-xnli15-1024-pytorch_model.bin',\n",
              " 'xlm-mlm-xnli15-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-xnli15-1024-pytorch_model.bin'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVoXYSPqAu3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_all(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I1mAUVqGxSi",
        "colab_type": "text"
      },
      "source": [
        "### 1 Setup FASTAI Databunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeK3w9iaHBzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8e5d5980-c945-4163-b8fd-4afa5c52f7a7"
      },
      "source": [
        "# load the pretrained tokenizer\n",
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1452741/1452741 [00:01<00:00, 1112496.20B/s]\n",
            "100%|██████████| 1008321/1008321 [00:01<00:00, 776455.21B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLzdH0lWM4y0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74900890-ef28-4ad2-e89c-8f52ff85bd05"
      },
      "source": [
        "transformer_tokenizer.max_len"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5ljV67gFDtI",
        "colab_type": "text"
      },
      "source": [
        "###### Create Custom FASTAI TOKENIER from pretrained transformer tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjnsSRo4Bbef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "        return [CLS] + tokens + [SEP]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_2fFui_EWQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wXeP_DVEfi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "3887aab3-9ea8-42e5-be52-6b336a1b17fa"
      },
      "source": [
        "tokenizer_class.pretrained_vocab_files_map"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'merges_file': {'xlm-clm-ende-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-ende-1024-merges.txt',\n",
              "  'xlm-clm-enfr-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-enfr-1024-merges.txt',\n",
              "  'xlm-mlm-100-1280': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-100-1280-merges.txt',\n",
              "  'xlm-mlm-17-1280': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-17-1280-merges.txt',\n",
              "  'xlm-mlm-en-2048': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-en-2048-merges.txt',\n",
              "  'xlm-mlm-ende-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-ende-1024-merges.txt',\n",
              "  'xlm-mlm-enfr-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-enfr-1024-merges.txt',\n",
              "  'xlm-mlm-enro-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-enro-1024-merges.txt',\n",
              "  'xlm-mlm-tlm-xnli15-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-tlm-xnli15-1024-merges.txt',\n",
              "  'xlm-mlm-xnli15-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-xnli15-1024-merges.txt'},\n",
              " 'vocab_file': {'xlm-clm-ende-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-clm-ende-1024-vocab.json',\n",
              "  'xlm-clm-enfr-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-clm-enfr-1024-vocab.json',\n",
              "  'xlm-mlm-100-1280': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-100-1280-vocab.json',\n",
              "  'xlm-mlm-17-1280': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-17-1280-vocab.json',\n",
              "  'xlm-mlm-en-2048': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-en-2048-vocab.json',\n",
              "  'xlm-mlm-ende-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-ende-1024-vocab.json',\n",
              "  'xlm-mlm-enfr-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-enfr-1024-vocab.json',\n",
              "  'xlm-mlm-enro-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-enro-1024-vocab.json',\n",
              "  'xlm-mlm-tlm-xnli15-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-tlm-xnli15-1024-vocab.json',\n",
              "  'xlm-mlm-xnli15-1024': 'https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-xnli15-1024-vocab.json'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra1uKAv1Fq3J",
        "colab_type": "text"
      },
      "source": [
        "###### Create Custom FASTAI Vocab from the pretrained transformer tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF64GKh_Ep7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLlu5bBuF82e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_vocab = TransformersVocab(tokenizer=transformer_tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYl02GssHLPo",
        "colab_type": "text"
      },
      "source": [
        "###### Create Custom FASTAI Processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duGkyBJYHWev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numericalize_processor = NumericalizeProcessor(vocab=fastai_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4hZJevuHyRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CowuQyVwJQtn",
        "colab_type": "text"
      },
      "source": [
        "###### Create Custom FASTAI Databunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY93k2TIKtPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7d8f4032-1b10-4f9a-800c-62bee22d1902"
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] token : </s>\n",
            "[SEP] token : </s>\n",
            "[PAD] token : <pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drsWa7kpIW6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtvAUGvdKOQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9fe72c08-a67f-4c35-f3a7-3211ec57d9a8"
      },
      "source": [
        "databunch = (TextList.from_df(train, cols='Text', processor=fastai_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'label')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWf9nJs-KOD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "3ba5a7e0-8dd4-454f-9979-9724e2b637a5"
      },
      "source": [
        "databunch.show_batch(10)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>&lt;&lt;/w&gt; span&lt;/w&gt; class&lt;/w&gt; =&lt;/w&gt; \"&lt;/w&gt; tiny&lt;/w&gt; \"&lt;/w&gt; &gt;&lt;/w&gt; length&lt;/w&gt; :&lt;/w&gt; :&lt;/w&gt; 4&lt;/w&gt; :&lt;/w&gt; 17&lt;/w&gt; mins&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; &lt;&lt;/w&gt; /&lt;/w&gt; span&lt;/w&gt; &gt;&lt;/w&gt; i&lt;/w&gt; talk&lt;/w&gt; in&lt;/w&gt; the&lt;/w&gt; video&lt;/w&gt; about&lt;/w&gt; how&lt;/w&gt; it&lt;/w&gt; is&lt;/w&gt; confusing&lt;/w&gt; when&lt;/w&gt; the&lt;/w&gt; product&lt;/w&gt; sent&lt;/w&gt; is&lt;/w&gt; somewhat&lt;/w&gt; different&lt;/w&gt; from&lt;/w&gt; the&lt;/w&gt; product&lt;/w&gt; that&lt;/w&gt; you&lt;/w&gt; see&lt;/w&gt; on&lt;/w&gt; the&lt;/w&gt; web&lt;/w&gt; .&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; i&lt;/w&gt; 'm&lt;/w&gt; disappointed&lt;/w&gt; that&lt;/w&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>this&lt;/w&gt; product&lt;/w&gt; is&lt;/w&gt; simply&lt;/w&gt; fabulous&lt;/w&gt; .&lt;/w&gt; i&lt;/w&gt; purchased&lt;/w&gt; it&lt;/w&gt; for&lt;/w&gt; my&lt;/w&gt; 7&lt;/w&gt; month&lt;/w&gt; old&lt;/w&gt; pit&lt;/w&gt; bull&lt;/w&gt; ,&lt;/w&gt; who&lt;/w&gt; is&lt;/w&gt; always&lt;/w&gt; into&lt;/w&gt; something&lt;/w&gt; and&lt;/w&gt; very&lt;/w&gt; highly&lt;/w&gt; food&lt;/w&gt; motivated&lt;/w&gt; .&lt;/w&gt; prior&lt;/w&gt; to&lt;/w&gt; the&lt;/w&gt; ever lasting&lt;/w&gt; treat&lt;/w&gt; ball&lt;/w&gt; her&lt;/w&gt; favorite&lt;/w&gt; toy&lt;/w&gt; was&lt;/w&gt; the&lt;/w&gt; chuck le&lt;/w&gt; ,&lt;/w&gt; made&lt;/w&gt; by&lt;/w&gt; premier&lt;/w&gt; .&lt;/w&gt; the&lt;/w&gt; advantage&lt;/w&gt; to&lt;/w&gt; the&lt;/w&gt; chuck le&lt;/w&gt; is&lt;/w&gt; that&lt;/w&gt; i&lt;/w&gt; could&lt;/w&gt; fill&lt;/w&gt; it&lt;/w&gt; with&lt;/w&gt; her&lt;/w&gt; food&lt;/w&gt; for&lt;/w&gt; a&lt;/w&gt; nutri tious&lt;/w&gt; but&lt;/w&gt; fun&lt;/w&gt; toy&lt;/w&gt; .&lt;/w&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>i&lt;/w&gt; bought&lt;/w&gt; this&lt;/w&gt; product&lt;/w&gt; around&lt;/w&gt; the&lt;/w&gt; beginning&lt;/w&gt; to&lt;/w&gt; middle&lt;/w&gt; of&lt;/w&gt; may&lt;/w&gt; 2011&lt;/w&gt; &amp;&lt;/w&gt; ,&lt;/w&gt; at&lt;/w&gt; that&lt;/w&gt; time&lt;/w&gt; ,&lt;/w&gt; it&lt;/w&gt; showed&lt;/w&gt; a&lt;/w&gt; picture&lt;/w&gt; of&lt;/w&gt; the&lt;/w&gt; box&lt;/w&gt; from&lt;/w&gt; the&lt;/w&gt; company&lt;/w&gt; cultures&lt;/w&gt; for&lt;/w&gt; health&lt;/w&gt; ll c&lt;/w&gt; .&lt;/w&gt; it&lt;/w&gt; also&lt;/w&gt; had&lt;/w&gt; (&lt;/w&gt; &amp;&lt;/w&gt; still&lt;/w&gt; has&lt;/w&gt; )&lt;/w&gt; their&lt;/w&gt; name&lt;/w&gt; on&lt;/w&gt; it&lt;/w&gt; as&lt;/w&gt; \"&lt;/w&gt; by&lt;/w&gt; cultures&lt;/w&gt; of&lt;/w&gt; health&lt;/w&gt; ll c&lt;/w&gt; \"&lt;/w&gt; but&lt;/w&gt; then&lt;/w&gt; further&lt;/w&gt; down&lt;/w&gt; is&lt;/w&gt; says&lt;/w&gt; \"&lt;/w&gt; ships&lt;/w&gt; from&lt;/w&gt; and&lt;/w&gt; sold&lt;/w&gt; by&lt;/w&gt; lifetime&lt;/w&gt; kef ir&lt;/w&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>i&lt;/w&gt; have&lt;/w&gt; many&lt;/w&gt; reviews&lt;/w&gt; for&lt;/w&gt; b arry&lt;/w&gt; farm&lt;/w&gt; products&lt;/w&gt; here&lt;/w&gt; on&lt;/w&gt; amaz on&lt;/w&gt; .&lt;/w&gt; maybe&lt;/w&gt; a&lt;/w&gt; dozen&lt;/w&gt; or&lt;/w&gt; so&lt;/w&gt; .&lt;/w&gt; if&lt;/w&gt; they&lt;/w&gt; are&lt;/w&gt; not&lt;/w&gt; the&lt;/w&gt; largest&lt;/w&gt; distributor&lt;/w&gt; of&lt;/w&gt; dried&lt;/w&gt; ve g gies&lt;/w&gt; ,&lt;/w&gt; spices&lt;/w&gt; ,&lt;/w&gt; herbs&lt;/w&gt; ,&lt;/w&gt; etc&lt;/w&gt; ,&lt;/w&gt; than&lt;/w&gt; they&lt;/w&gt; have&lt;/w&gt; to&lt;/w&gt; be&lt;/w&gt; very&lt;/w&gt; close&lt;/w&gt; .&lt;/w&gt; i&lt;/w&gt; became&lt;/w&gt; familiar&lt;/w&gt; with&lt;/w&gt; b arry&lt;/w&gt; farm&lt;/w&gt; products&lt;/w&gt; many&lt;/w&gt; years&lt;/w&gt; ago&lt;/w&gt; when&lt;/w&gt; i&lt;/w&gt; first&lt;/w&gt; started&lt;/w&gt; doing&lt;/w&gt; a&lt;/w&gt; lot&lt;/w&gt; of&lt;/w&gt; hiking&lt;/w&gt; .&lt;/w&gt; their&lt;/w&gt; fresh</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>i&lt;/w&gt; have&lt;/w&gt; been&lt;/w&gt; on&lt;/w&gt; something&lt;/w&gt; of&lt;/w&gt; honey&lt;/w&gt; j ag&lt;/w&gt; this&lt;/w&gt; year&lt;/w&gt; .&lt;/w&gt; it&lt;/w&gt; seems&lt;/w&gt; to&lt;/w&gt; find&lt;/w&gt; it&lt;/w&gt; 's&lt;/w&gt; way&lt;/w&gt; into&lt;/w&gt; everything&lt;/w&gt; around&lt;/w&gt; me&lt;/w&gt; from&lt;/w&gt; baked&lt;/w&gt; goods&lt;/w&gt; to&lt;/w&gt; bath&lt;/w&gt; products&lt;/w&gt; .&lt;/w&gt; honey&lt;/w&gt; is&lt;/w&gt; better&lt;/w&gt; for&lt;/w&gt; you&lt;/w&gt; than&lt;/w&gt; the&lt;/w&gt; vast&lt;/w&gt; majority&lt;/w&gt; what&lt;/w&gt; it&lt;/w&gt; there&lt;/w&gt; .&lt;/w&gt; (&lt;/w&gt; i&lt;/w&gt; discovered&lt;/w&gt; ,&lt;/w&gt; just&lt;/w&gt; a&lt;/w&gt; day&lt;/w&gt; or&lt;/w&gt; 2&lt;/w&gt; ago&lt;/w&gt; ,&lt;/w&gt; when&lt;/w&gt; per using&lt;/w&gt; &lt;&lt;/w&gt; a&lt;/w&gt; h re f&lt;/w&gt; =&lt;/w&gt; \"&lt;/w&gt; http&lt;/w&gt; :&lt;/w&gt; /&lt;/w&gt; /&lt;/w&gt; www. amaz</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>i&lt;/w&gt; believe&lt;/w&gt; that&lt;/w&gt; people&lt;/w&gt; need&lt;/w&gt; to&lt;/w&gt; be&lt;/w&gt; aware&lt;/w&gt; of&lt;/w&gt; the&lt;/w&gt; fact&lt;/w&gt; that&lt;/w&gt; the&lt;/w&gt; ki bble&lt;/w&gt; size&lt;/w&gt; of&lt;/w&gt; the&lt;/w&gt; adult&lt;/w&gt; oral&lt;/w&gt; care&lt;/w&gt; dry&lt;/w&gt; cat&lt;/w&gt; food&lt;/w&gt; is&lt;/w&gt; very&lt;/w&gt; large&lt;/w&gt; and&lt;/w&gt; presents&lt;/w&gt; a&lt;/w&gt; potential&lt;/w&gt; cho king&lt;/w&gt; hazard&lt;/w&gt; to&lt;/w&gt; their&lt;/w&gt; pets&lt;/w&gt; .&lt;/w&gt; i&lt;/w&gt; transi tioned&lt;/w&gt; my&lt;/w&gt; cat&lt;/w&gt; to&lt;/w&gt; this&lt;/w&gt; food&lt;/w&gt; from&lt;/w&gt; the&lt;/w&gt; science&lt;/w&gt; diet&lt;/w&gt; kit ten&lt;/w&gt; formula&lt;/w&gt; when&lt;/w&gt; he&lt;/w&gt; was&lt;/w&gt; about&lt;/w&gt; 15&lt;/w&gt; months&lt;/w&gt; old&lt;/w&gt; .&lt;/w&gt; from&lt;/w&gt; day&lt;/w&gt; one&lt;/w&gt; ,&lt;/w&gt; i&lt;/w&gt; thought&lt;/w&gt; that&lt;/w&gt; the&lt;/w&gt; ki</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>i&lt;/w&gt; decided&lt;/w&gt; to&lt;/w&gt; re- write&lt;/w&gt; my&lt;/w&gt; review&lt;/w&gt; in&lt;/w&gt; order&lt;/w&gt; to&lt;/w&gt; let&lt;/w&gt; you&lt;/w&gt; guys&lt;/w&gt; in&lt;/w&gt; on&lt;/w&gt; how&lt;/w&gt; my&lt;/w&gt; cat&lt;/w&gt; 's&lt;/w&gt; been&lt;/w&gt; doing&lt;/w&gt; on&lt;/w&gt; the&lt;/w&gt; war u va&lt;/w&gt; cat&lt;/w&gt; food&lt;/w&gt; .&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; we&lt;/w&gt; decided&lt;/w&gt; to&lt;/w&gt; try&lt;/w&gt; pretty&lt;/w&gt; much&lt;/w&gt; every&lt;/w&gt; flavor&lt;/w&gt; on&lt;/w&gt; here&lt;/w&gt; because&lt;/w&gt; i&lt;/w&gt; couldn&lt;/w&gt; 't&lt;/w&gt; find&lt;/w&gt; any&lt;/w&gt; really&lt;/w&gt; good&lt;/w&gt; specific&lt;/w&gt; reviews&lt;/w&gt; for&lt;/w&gt; anything&lt;/w&gt; other&lt;/w&gt; than&lt;/w&gt; one&lt;/w&gt; or&lt;/w&gt; two&lt;/w&gt; flavors&lt;/w&gt; ,&lt;/w&gt; here&lt;/w&gt; 's&lt;/w&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>i&lt;/w&gt; decided&lt;/w&gt; to&lt;/w&gt; switch&lt;/w&gt; from&lt;/w&gt; grocery&lt;/w&gt; store&lt;/w&gt; milk&lt;/w&gt; to&lt;/w&gt; sac o&lt;/w&gt; 's&lt;/w&gt; powder&lt;/w&gt; for&lt;/w&gt; mathem atical&lt;/w&gt; reasons&lt;/w&gt; .&lt;/w&gt; as&lt;/w&gt; a&lt;/w&gt; single&lt;/w&gt; lady&lt;/w&gt; who&lt;/w&gt; uses&lt;/w&gt; milk&lt;/w&gt; primarily&lt;/w&gt; for&lt;/w&gt; my&lt;/w&gt; tea&lt;/w&gt; ,&lt;/w&gt; i&lt;/w&gt; rarely&lt;/w&gt; finish&lt;/w&gt; a&lt;/w&gt; one- gallon&lt;/w&gt; bottle&lt;/w&gt; before&lt;/w&gt; it&lt;/w&gt; s ours&lt;/w&gt; (&lt;/w&gt; hate&lt;/w&gt; that&lt;/w&gt; race&lt;/w&gt; to&lt;/w&gt; use&lt;/w&gt; it&lt;/w&gt; all&lt;/w&gt; !&lt;/w&gt; )&lt;/w&gt; ,&lt;/w&gt; and&lt;/w&gt; buying&lt;/w&gt; half&lt;/w&gt; gallon&lt;/w&gt; containers&lt;/w&gt; absolutely&lt;/w&gt; bugs&lt;/w&gt; me&lt;/w&gt; ,&lt;/w&gt; as&lt;/w&gt; it&lt;/w&gt; costs&lt;/w&gt; five&lt;/w&gt; bucks&lt;/w&gt; for&lt;/w&gt; two&lt;/w&gt; (&lt;/w&gt; purchased&lt;/w&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>go&lt;/w&gt; to&lt;/w&gt; [&lt;/w&gt; ...&lt;/w&gt; ]&lt;/w&gt; .&lt;/w&gt; search&lt;/w&gt; for&lt;/w&gt; the&lt;/w&gt; video&lt;/w&gt; entitled&lt;/w&gt; :&lt;/w&gt; whole&lt;/w&gt; foods&lt;/w&gt; market&lt;/w&gt; \"&lt;/w&gt; organic&lt;/w&gt; \"&lt;/w&gt; food&lt;/w&gt; made&lt;/w&gt; in&lt;/w&gt; ch ina&lt;/w&gt; !&lt;/w&gt; !&lt;/w&gt; !&lt;/w&gt; !&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; according&lt;/w&gt; to&lt;/w&gt; my&lt;/w&gt; research&lt;/w&gt; ,&lt;/w&gt; ch ina&lt;/w&gt; is&lt;/w&gt; the&lt;/w&gt; major&lt;/w&gt; supplier&lt;/w&gt; of&lt;/w&gt; go ji&lt;/w&gt; berries&lt;/w&gt; .&lt;/w&gt; there&lt;/w&gt; 's&lt;/w&gt; been&lt;/w&gt; an&lt;/w&gt; unresolved&lt;/w&gt; growing&lt;/w&gt; concern&lt;/w&gt; about&lt;/w&gt; food&lt;/w&gt; ,&lt;/w&gt; any&lt;/w&gt; food&lt;/w&gt; produced&lt;/w&gt; in&lt;/w&gt; ch ina&lt;/w&gt; ,&lt;/w&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>i&lt;/w&gt; realize&lt;/w&gt; i&lt;/w&gt; am&lt;/w&gt; just&lt;/w&gt; adding&lt;/w&gt; my&lt;/w&gt; voice&lt;/w&gt; to&lt;/w&gt; the&lt;/w&gt; chorus&lt;/w&gt; of&lt;/w&gt; approval&lt;/w&gt; about&lt;/w&gt; til da&lt;/w&gt; bas mat i&lt;/w&gt; rice&lt;/w&gt; ,&lt;/w&gt; but&lt;/w&gt; i&lt;/w&gt; feel&lt;/w&gt; strongly&lt;/w&gt; enough&lt;/w&gt; to&lt;/w&gt; write&lt;/w&gt; a&lt;/w&gt; review&lt;/w&gt; anyway&lt;/w&gt; !&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; in&lt;/w&gt; a&lt;/w&gt; nut shell&lt;/w&gt; :&lt;/w&gt; &lt;&lt;/w&gt; b r&lt;/w&gt; /&lt;/w&gt; &gt;&lt;/w&gt; if&lt;/w&gt; you&lt;/w&gt; enjoy&lt;/w&gt; rice&lt;/w&gt; that&lt;/w&gt; is&lt;/w&gt; d rier&lt;/w&gt; in&lt;/w&gt; texture&lt;/w&gt; and&lt;/w&gt; has&lt;/w&gt; separate&lt;/w&gt; grains&lt;/w&gt; ,&lt;/w&gt; til da&lt;/w&gt; bas</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL9cyaXMMV6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1da556c9-3345-4e56-feea-0bebd97dc9b4"
      },
      "source": [
        "databunch.one_batch()[0].shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CBbrWy8Nbwx",
        "colab_type": "text"
      },
      "source": [
        "### 2 Setup FASTAI Learner "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1IReobzNy_r",
        "colab_type": "text"
      },
      "source": [
        "###### Create Custom Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEb-ujgEMV35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "36792ae6-2b08-4bd4-bd52-a016af3c7fd4"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-c3aa180c46d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatabunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: one_item() missing 1 required positional argument: 'item'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihOJYhPfMV1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-mKCcNlJH8I",
        "colab_type": "text"
      },
      "source": [
        "### Reference\n",
        "https://www.kaggle.com/maroberti/fastai-with-transformers-bert-roberta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN2eyUX1OLnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}