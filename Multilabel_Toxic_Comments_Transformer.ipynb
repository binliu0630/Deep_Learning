{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilabel_Toxic_Comments_Transformer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPtKX87YFuOkk/9DsUGp6ti",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37d06de7816c4920a2e78a06b622b5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_409985fc1892468d9283ef42067d377d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_55501c7699604da4ad6df8d717fc67ea",
              "IPY_MODEL_4081dfebf14247ab84e28c9bc9866512"
            ]
          }
        },
        "409985fc1892468d9283ef42067d377d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55501c7699604da4ad6df8d717fc67ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e77602634bb840c8a4815facedeb6a2e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffbaba7a73b24c37955e8c09358c782a"
          }
        },
        "4081dfebf14247ab84e28c9bc9866512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6b28092950e94b5f80742fbeb9c61e4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 593kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58a825ef3811450c8b53b5107b1506cd"
          }
        },
        "e77602634bb840c8a4815facedeb6a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffbaba7a73b24c37955e8c09358c782a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b28092950e94b5f80742fbeb9c61e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58a825ef3811450c8b53b5107b1506cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c0188c26a94401a812fa6ea2ecc2fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6904d484b7274468984844b70337ad65",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_821242ef0e034b0b91d5644e64644acc",
              "IPY_MODEL_44c22fd1182040dd8f9666944416d131"
            ]
          }
        },
        "6904d484b7274468984844b70337ad65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "821242ef0e034b0b91d5644e64644acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae411dc8392e4d64bfb52b66e8ae0da2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4487,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4487,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1459f4f2228e4d3eab7144d25941a56b"
          }
        },
        "44c22fd1182040dd8f9666944416d131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_891be7fcce25435a92d8ac03d34144cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4488/? [18:26&lt;00:00,  4.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_505eba549ebf40fc8e68efc8e32a94e4"
          }
        },
        "ae411dc8392e4d64bfb52b66e8ae0da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1459f4f2228e4d3eab7144d25941a56b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "891be7fcce25435a92d8ac03d34144cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "505eba549ebf40fc8e68efc8e32a94e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb94ac931ed045849136fa0d0d4c5704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c243b22528054ee6a4dc7db55baff623",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61054a2877a84db59a90d735e81caa5a",
              "IPY_MODEL_c4019dd4d6354654a0bbc95e1ecfedb7"
            ]
          }
        },
        "c243b22528054ee6a4dc7db55baff623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61054a2877a84db59a90d735e81caa5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fa99f9a885ff49d3b21cd95e0735d473",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 498,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 498,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb43bf67230245918c08ae3e475b82ff"
          }
        },
        "c4019dd4d6354654a0bbc95e1ecfedb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_baef0151010d444bb42308bcc7f690ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 499/? [06:01&lt;00:00,  1.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c4b34fc9d3f475ba8362bed08decd03"
          }
        },
        "fa99f9a885ff49d3b21cd95e0735d473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb43bf67230245918c08ae3e475b82ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baef0151010d444bb42308bcc7f690ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c4b34fc9d3f475ba8362bed08decd03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19a1fb83365a406185c0dd262297d116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_209d3e9dcece405bb706cf44acca157c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36e338e1905b4f45a441768d40b845e9",
              "IPY_MODEL_aa61f6af2bff4e3ca0cf8a7c26abc56c"
            ]
          }
        },
        "209d3e9dcece405bb706cf44acca157c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36e338e1905b4f45a441768d40b845e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5f80064d74a45a5a1802439a84e6235",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 4786,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c59c4bbdd924b7886fb53179ae24a9a"
          }
        },
        "aa61f6af2bff4e3ca0cf8a7c26abc56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdb2433a47d142f480e51ac62f480bb6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4786 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4031662ed59e44b3a0895e8fc231de33"
          }
        },
        "f5f80064d74a45a5a1802439a84e6235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c59c4bbdd924b7886fb53179ae24a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdb2433a47d142f480e51ac62f480bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4031662ed59e44b3a0895e8fc231de33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0177ca2c01ce4ced845287b27c4a7ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f7180d126f446f5af54648d4306559b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e951593fd1a94eea839a5d57135eb26a",
              "IPY_MODEL_078f093289244760aa21d653c0e2912b"
            ]
          }
        },
        "0f7180d126f446f5af54648d4306559b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e951593fd1a94eea839a5d57135eb26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7cf93c787da48c4b78315f773026f74",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afd9254826404261a422d378b64f8cc8"
          }
        },
        "078f093289244760aa21d653c0e2912b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab4a5aa66ffb4ffebf56d3c982594fe3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:18&lt;00:00, 24.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5eab2e73f3284d29b9ef5de489b275d6"
          }
        },
        "b7cf93c787da48c4b78315f773026f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afd9254826404261a422d378b64f8cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab4a5aa66ffb4ffebf56d3c982594fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5eab2e73f3284d29b9ef5de489b275d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7375eeb2159e48a99994d62502acdf64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fdde378057f4441489fddca3c555ca2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_95fa26b5f87b446e97e1f4792df5eea3",
              "IPY_MODEL_c2f1a8a7f1d44b0f905daf4844522e10"
            ]
          }
        },
        "fdde378057f4441489fddca3c555ca2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95fa26b5f87b446e97e1f4792df5eea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eab43361cd7e4a40a48e8eaf9f954c09",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_830abae9c1a446eca8fd92ee35ee421a"
          }
        },
        "c2f1a8a7f1d44b0f905daf4844522e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_792f4dad67f84de3a22d6e72b5cf8771",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 44.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f02a750a9d0491a91ca95b8e437eb37"
          }
        },
        "eab43361cd7e4a40a48e8eaf9f954c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "830abae9c1a446eca8fd92ee35ee421a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "792f4dad67f84de3a22d6e72b5cf8771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f02a750a9d0491a91ca95b8e437eb37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binliu0630/Deep_Learning/blob/master/Multilabel_Toxic_Comments_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vakLQvcJmw",
        "colab_type": "text"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0XFh2bFcJaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "10b86c9b-378a-4b0b-f34d-d1f5f528f7e0"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa0ehwKt06tt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "604c6b4a-2464-4fdf-c433-375a5564aa83"
      },
      "source": [
        "!ls -a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".  ..  .config\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6CM2k38cJW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c64f90a-4276-4660-ed3e-35ab699905b0"
      },
      "source": [
        "!rm -r ~/.kaggle # remove .kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/root/.kaggle': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1aq3vF42TMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXaaiIw3z6Y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORHRVXVAzZLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!touch ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JExBwuyAcJV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"binliu0630\",\"key\":\"8fbf745edbb9799f7f8f45f516701290\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp1wccrJcJSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stovugVYynOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad776e33-6388-448c-b96b-53a3e6cd7dc5"
      },
      "source": [
        "!ls ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoWyoIBTcJPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "717788b6-4b1d-41a8-c8f2-070931b5810f"
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxJiogO-cJM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o7FG6GhcJKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f5c386d9-a576-474b-92c4-6a62b10fe6ac"
      },
      "source": [
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge -p /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test_labels.csv.zip to /content\n",
            "\r  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 49.2MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 87% 23.0M/26.3M [00:00<00:00, 35.9MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 87.7MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 73% 17.0M/23.4M [00:01<00:00, 8.67MB/s]\n",
            "100% 23.4M/23.4M [00:01<00:00, 15.7MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 95.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFBV1tIRcJIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b9c42d88-4263-4134-e941-e457a3cf5c53"
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "\n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n",
            "\n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "\n",
            "Archive:  test_labels.csv.zip\n",
            "  inflating: test_labels.csv         \n",
            "\n",
            "4 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE6Oz45ecJFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "933e1855-85c7-486f-fe67-3cb9be32b5b5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t   test.csv\t    test_labels.csv.zip\n",
            "sample_submission.csv\t   test.csv.zip     train.csv\n",
            "sample_submission.csv.zip  test_labels.csv  train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-R4w_h3cJCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3e965233-b7d6-454e-a444-f88b4df50e80"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0brKmI8-dnxx",
        "colab_type": "text"
      },
      "source": [
        "# Get Started with Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCHWBdQCbiSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "22cbbea7-d13e-47ab-f22a-295372cf57de"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 16.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 33.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=3f9fb7cbb49ac5f8cc7209b02bcdfcb94cc9b26cb35e41ae413e6825d67d28cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsH0nq20bmno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dcbd70ea-5117-4dbc-91df-3a407b681c1e"
      },
      "source": [
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "print(f'tensorflow: {tf.__version__}')\n",
        "import torch\n",
        "print(f'torch:{torch.__version__}')\n",
        "from torch import nn\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow: 2.2.0\n",
            "torch:1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDAJpJy8d9hS",
        "colab_type": "text"
      },
      "source": [
        "### Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1vQrAcLebIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wpxwSwceeyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOPCmJPZe9xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test_labels = pd.read_csv('test_labels.csv')\n",
        "df_test_labels = df_test_labels.set_index('id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR1prZWFfFvL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bb7a370b-5038-4ff8-9bf2-8164af4e7015"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om2K9XwBfHE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMMPtv1jfypw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "37d06de7816c4920a2e78a06b622b5de",
            "409985fc1892468d9283ef42067d377d",
            "55501c7699604da4ad6df8d717fc67ea",
            "4081dfebf14247ab84e28c9bc9866512",
            "e77602634bb840c8a4815facedeb6a2e",
            "ffbaba7a73b24c37955e8c09358c782a",
            "6b28092950e94b5f80742fbeb9c61e4b",
            "58a825ef3811450c8b53b5107b1506cd"
          ]
        },
        "outputId": "bb668e6e-fbeb-4268-dd24-98a01ca0065c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37d06de7816c4920a2e78a06b622b5de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Nlt-IigY8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9N2V6RIhYFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token = tokenizer.batch_encode_plus(df_train['comment_text'].values, max_length=64, pad_to_max_length=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jtrz3zDiH8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a000b671-029b-4e75-e126-47e56b60fe6a"
      },
      "source": [
        "token.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-z5ePQui0GV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = token['input_ids']\n",
        "attention_mask = token['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnB4XXlAi82F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "labels = df_train[label_cols].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsBz4Y5ij0BV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,random_state=1234, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiYCUqvLkHtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_masks, validation_masks, _, _ = train_test_split(attention_mask, labels, random_state=1234, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX0WC0R4kWMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "889ab888-6dc3-4841-a6f2-2ae3a93931e7"
      },
      "source": [
        "train_size = len(train_inputs)\n",
        "print(f'train size: {train_size}')\n",
        "validation_size = len(validation_inputs)\n",
        "print(f'validation size: {validation_size}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train size: 143613\n",
            "validation size: 15958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0F7TSM5AYB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4Zb-PhW57Xy",
        "colab_type": "text"
      },
      "source": [
        "#### TF BERT MODEL\n",
        "\n",
        "https://www.kaggle.com/nkaenzig/bert-tensorflow-2-huggingface-transformers/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd3icYatkgeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prep Data\n",
        "def create_dataset(data_tuple, epochs=1, batch_size=32, buffer_size=10000, train=True):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(data_tuple)\n",
        "  if train:\n",
        "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
        "  dataset = dataset.repeat(epochs)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  if train:\n",
        "    dataset = dataset.prefetch(1)\n",
        "  return dataset "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUEJlurHmWpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = create_dataset((train_inputs, train_masks, train_labels), \n",
        "                               epochs=EPOCHS, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUL8uPvFmleT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_dataset = create_dataset((validation_inputs, validation_masks, validation_labels),\n",
        "                                    epochs=EPOCHS, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7mb_Ws4m6Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import TFBertModel\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "class BertMultiLabelClassifier(tf.keras.Model):\n",
        "  def __init__(self, bert: TFBertModel, num_classes: int):\n",
        "    super().__init__()\n",
        "    self.bert = bert\n",
        "    self.classifier = Dense(num_classes, activation='sigmoid')\n",
        "  @tf.function\n",
        "  def call(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None):\n",
        "    outputs = self.bert(input_ids, \n",
        "                       attention_mask=attention_mask,\n",
        "                       token_type_ids=token_type_ids,\n",
        "                       position_ids=position_ids,\n",
        "                       head_mask=head_mask)\n",
        "    cls_output = outputs[1]\n",
        "    cls_output = self.classifier(cls_output)\n",
        "    \n",
        "\n",
        "    return cls_output\n",
        "model = BertMultiLabelClassifier(TFBertModel.from_pretrained('bert-base-uncased'), len(label_cols))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmoRd56k4KKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from transformers import create_optimizer\n",
        "\n",
        "steps_per_epoch = train_size // BATCH_SIZE\n",
        "validation_steps = validation_size // BATCH_SIZE\n",
        "\n",
        "# | Loss Function\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "validation_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "# | Optimizer (with 1-cycle-policy)\n",
        "warmup_steps = steps_per_epoch // 3\n",
        "total_steps = steps_per_epoch * EPOCHS - warmup_steps\n",
        "optimizer = create_optimizer(init_lr=2e-5, num_train_steps=total_steps, num_warmup_steps=warmup_steps)\n",
        "\n",
        "# | Metrics\n",
        "train_auc_metrics = [tf.keras.metrics.AUC() for i in range(len(label_cols))]\n",
        "validation_auc_metrics = [tf.keras.metrics.AUC() for i in range(len(label_cols))]\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, token_ids, masks, labels):\n",
        "    labels = tf.dtypes.cast(labels, tf.float32)\n",
        "    print(labels.shape)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(token_ids, attention_mask=masks)\n",
        "        print(predictions.shape)\n",
        "        loss = loss_object(labels, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "\n",
        "    for i, auc in enumerate(train_auc_metrics):\n",
        "        auc.update_state(labels[:,i], predictions[:,i])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS07Sqsco8h4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999,
          "referenced_widgets": [
            "8c0188c26a94401a812fa6ea2ecc2fb7",
            "6904d484b7274468984844b70337ad65",
            "821242ef0e034b0b91d5644e64644acc",
            "44c22fd1182040dd8f9666944416d131",
            "ae411dc8392e4d64bfb52b66e8ae0da2",
            "1459f4f2228e4d3eab7144d25941a56b",
            "891be7fcce25435a92d8ac03d34144cd",
            "505eba549ebf40fc8e68efc8e32a94e4",
            "cb94ac931ed045849136fa0d0d4c5704",
            "c243b22528054ee6a4dc7db55baff623",
            "61054a2877a84db59a90d735e81caa5a",
            "c4019dd4d6354654a0bbc95e1ecfedb7",
            "fa99f9a885ff49d3b21cd95e0735d473",
            "fb43bf67230245918c08ae3e475b82ff",
            "baef0151010d444bb42308bcc7f690ee",
            "3c4b34fc9d3f475ba8362bed08decd03"
          ]
        },
        "outputId": "76df511b-428f-43a6-e8f5-272356fdb01f"
      },
      "source": [
        "import time\n",
        "from transformers import create_optimizer\n",
        "\n",
        "steps_per_epoch = train_size // BATCH_SIZE\n",
        "validation_steps = validation_size // BATCH_SIZE\n",
        "\n",
        "# | Loss Function\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "validation_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "# | Optimizer (with 1-cycle-policy)\n",
        "warmup_steps = steps_per_epoch // 3\n",
        "total_steps = steps_per_epoch * EPOCHS - warmup_steps\n",
        "optimizer = create_optimizer(init_lr=2e-5, num_train_steps=total_steps, num_warmup_steps=warmup_steps)\n",
        "\n",
        "# | Metrics\n",
        "train_auc_metrics = [tf.keras.metrics.AUC() for i in range(len(label_cols))]\n",
        "validation_auc_metrics = [tf.keras.metrics.AUC() for i in range(len(label_cols))]\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, token_ids, masks, labels):\n",
        "    labels = tf.dtypes.cast(labels, tf.float32)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(token_ids, attention_mask=masks)\n",
        "        loss = loss_object(labels, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "\n",
        "    for i, auc in enumerate(train_auc_metrics):\n",
        "        auc.update_state(labels[:,i], predictions[:,i])\n",
        "        \n",
        "@tf.function\n",
        "def validation_step(model, token_ids, masks, labels):\n",
        "    labels = tf.dtypes.cast(labels, tf.float32)\n",
        "\n",
        "    predictions = model(token_ids, attention_mask=masks, training=False)\n",
        "    v_loss = loss_object(labels, predictions)\n",
        "\n",
        "    validation_loss(v_loss)\n",
        "    for i, auc in enumerate(validation_auc_metrics):\n",
        "        auc.update_state(labels[:,i], predictions[:,i])\n",
        "                                             \n",
        "def train(model, train_dataset, val_dataset, train_steps_per_epoch, val_steps_per_epoch, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print('=' * 50, f\"EPOCH {epoch}\", '=' * 50)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        for i, (token_ids, masks, labels) in enumerate(tqdm(train_dataset, total=train_steps_per_epoch)):\n",
        "            train_step(model, token_ids, masks, labels)\n",
        "            if i % 1000 == 0:\n",
        "                print(f'\\nTrain Step: {i}, Loss: {train_loss.result()}')\n",
        "                for i, label_name in enumerate(label_cols):\n",
        "                    print(f\"{label_name} roc_auc {train_auc_metrics[i].result()}\")\n",
        "                    train_auc_metrics[i].reset_states()\n",
        "        \n",
        "        for i, (token_ids, masks, labels) in enumerate(tqdm(val_dataset, total=val_steps_per_epoch)):\n",
        "            validation_step(model, token_ids, masks, labels)\n",
        "\n",
        "        print(f'\\nEpoch {epoch+1}, Validation Loss: {validation_loss.result()}, Time: {time.time()-start}\\n')\n",
        "\n",
        "        for i, label_name in enumerate(label_cols):\n",
        "            print(f\"{label_name} roc_auc {validation_auc_metrics[i].result()}\")\n",
        "            validation_auc_metrics[i].reset_states()\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "        \n",
        "train(model, train_dataset, validation_dataset, train_steps_per_epoch=steps_per_epoch, val_steps_per_epoch=validation_steps, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================== EPOCH 0 ==================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c0188c26a94401a812fa6ea2ecc2fb7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4487.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Step: 0, Loss: 0.7295576333999634\n",
            "toxic roc_auc 0.5223214626312256\n",
            "severe_toxic roc_auc 0.0\n",
            "obscene roc_auc 0.8275862336158752\n",
            "threat roc_auc 0.0\n",
            "insult roc_auc 0.5223214030265808\n",
            "identity_hate roc_auc 0.5483871102333069\n",
            "\n",
            "Train Step: 1000, Loss: 0.1526714712381363\n",
            "toxic roc_auc 0.8820860981941223\n",
            "severe_toxic roc_auc 0.8512372970581055\n",
            "obscene roc_auc 0.9223113059997559\n",
            "threat roc_auc 0.7103817462921143\n",
            "insult roc_auc 0.887835681438446\n",
            "identity_hate roc_auc 0.8003348708152771\n",
            "\n",
            "Train Step: 2000, Loss: 0.09984458237886429\n",
            "toxic roc_auc 0.9755777716636658\n",
            "severe_toxic roc_auc 0.9859877228736877\n",
            "obscene roc_auc 0.9806215763092041\n",
            "threat roc_auc 0.9367233514785767\n",
            "insult roc_auc 0.9765495657920837\n",
            "identity_hate roc_auc 0.9652571082115173\n",
            "\n",
            "Train Step: 3000, Loss: 0.081039197742939\n",
            "toxic roc_auc 0.9786972403526306\n",
            "severe_toxic roc_auc 0.9908697009086609\n",
            "obscene roc_auc 0.981585681438446\n",
            "threat roc_auc 0.9529606699943542\n",
            "insult roc_auc 0.9800706505775452\n",
            "identity_hate roc_auc 0.9752938747406006\n",
            "\n",
            "Train Step: 4000, Loss: 0.07137174904346466\n",
            "toxic roc_auc 0.980316162109375\n",
            "severe_toxic roc_auc 0.9850447773933411\n",
            "obscene roc_auc 0.9881855249404907\n",
            "threat roc_auc 0.9773910045623779\n",
            "insult roc_auc 0.9842674732208252\n",
            "identity_hate roc_auc 0.9759039282798767\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb94ac931ed045849136fa0d0d4c5704",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=498.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch 1, Validation Loss: 0.04021574184298515, Time: 1107.8161141872406\n",
            "\n",
            "toxic roc_auc 0.981320321559906\n",
            "severe_toxic roc_auc 0.9918230772018433\n",
            "obscene roc_auc 0.9846734404563904\n",
            "threat roc_auc 0.989111602306366\n",
            "insult roc_auc 0.9816721677780151\n",
            "identity_hate roc_auc 0.9777508974075317\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apzRZ5r7y9pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_token = tokenizer.batch_encode_plus(df_test['comment_text'].values, max_length=64, pad_to_max_length=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAN32Qt92AE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd445984-8e6b-47f3-ff64-1d6531e621c3"
      },
      "source": [
        "test_token.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5MeV30sy7D5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_ids = test_token['input_ids']\n",
        "test_attention_mask = test_token['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2B_vU-z2gs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8d0e9f2c-bb62-4c18-a259-806f70234690"
      },
      "source": [
        "\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4  00017695ad8997eb          I don't anonymously edit articles at all."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCCPcq3Vy61m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_BATCH_SIZE = 32\n",
        "test_steps = len(df_test) // TEST_BATCH_SIZE\n",
        "\n",
        "test_dataset = create_dataset((test_input_ids, test_attention_mask), batch_size=TEST_BATCH_SIZE, train=False, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk8eeFpH3eMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "19a1fb83365a406185c0dd262297d116",
            "209d3e9dcece405bb706cf44acca157c",
            "36e338e1905b4f45a441768d40b845e9",
            "aa61f6af2bff4e3ca0cf8a7c26abc56c",
            "f5f80064d74a45a5a1802439a84e6235",
            "3c59c4bbdd924b7886fb53179ae24a9a",
            "cdb2433a47d142f480e51ac62f480bb6",
            "4031662ed59e44b3a0895e8fc231de33"
          ]
        },
        "outputId": "06b23985-82b7-4318-e7fb-f2c3c5275f38"
      },
      "source": [
        "preds = []\n",
        "for i, (token_ids, masks) in enumerate(tqdm(test_dataset, total=test_steps)):\n",
        "    sample_ids = df_test.iloc[i*TEST_BATCH_SIZE:(i+1)*TEST_BATCH_SIZE]['id']\n",
        "    #print(sample_ids)\n",
        "    predictions = model(token_ids, attention_mask=masks).numpy()\n",
        "    #print(predictions)\n",
        "    #pred_bools = [pl>0.5 for pl in predictions]\n",
        "    #print(pred_bools)\n",
        "    preds.append(predictions)\n",
        "    #df_test.loc[sample_ids, label_cols] = predictions\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19a1fb83365a406185c0dd262297d116",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4786.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWf6vV247C_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# expand the list of list \n",
        "pred_labels = [item for sublist in preds for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnNCkT8O5i4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "66192771-c1b9-4428-a341-81ad8add2c70"
      },
      "source": [
        "# apply a threshhold\n",
        "pred_labels = pd.DataFrame(pred_labels, columns=label_cols) >0.5\n",
        "pred_labels.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
              "0   True         False     True   False    True          False\n",
              "1  False         False    False   False   False          False\n",
              "2  False         False    False   False   False          False\n",
              "3  False         False    False   False   False          False\n",
              "4  False         False    False   False   False          False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUFNB_pXGNN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_labels['tags'] = pred_labels.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abRI-WD3HXLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2e0fdabd-f581-4591-d9fa-f2fc3b29fcc9"
      },
      "source": [
        "pred_labels['Tag_labes'] = pred_labels['tags'].apply(lambda x: [l for (l,v) in zip(label_cols,x) if v])\n",
        "\n",
        "pred_labels.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>tags</th>\n",
              "      <th>Tag_labes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>[True, False, True, False, True, False]</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[False, False, False, False, False, False]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[False, False, False, False, False, False]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[False, False, False, False, False, False]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[False, False, False, False, False, False]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   toxic  ...                 Tag_labes\n",
              "0   True  ...  [toxic, obscene, insult]\n",
              "1  False  ...                        []\n",
              "2  False  ...                        []\n",
              "3  False  ...                        []\n",
              "4  False  ...                        []\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDSPLcSSFQQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#another example of TF2: https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgbzhPwod17B",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch\n",
        "\n",
        "# more comprehensive example with custom class and AUC for each class\n",
        "https://github.com/lonePatient/Bert-Multi-Label-Text-Classification/tree/4d5b26f02112afc56086ff605c90efdd36366a30/pybert/train\n",
        "\n",
        "# more easier example with orginal sequence classification class and F1 scores\n",
        "https://colab.research.google.com/github/rap12391/transformers_multilabel_toxic/blob/master/toxic_multilabel.ipynb#scrollTo=NPvrL6OFSQvf\n",
        "\n",
        "\n",
        "#customer class with F1\n",
        "https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7i-Yuw5d0z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from transformers.modeling_bert import BertPreTrainedModel, BertModel\n",
        "\n",
        "class BertForMultiLable(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super(BertForMultiLable, self).__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None,head_mask=None):\n",
        "        outputs = self.bert(input_ids, token_type_ids=token_type_ids,attention_mask=attention_mask, head_mask=head_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "    def unfreeze(self,start_layer,end_layer):\n",
        "        def children(m):\n",
        "            return m if isinstance(m, (list, tuple)) else list(m.children())\n",
        "        def set_trainable_attr(m, b):\n",
        "            m.trainable = b\n",
        "            for p in m.parameters():\n",
        "                p.requires_grad = b\n",
        "        def apply_leaf(m, f):\n",
        "            c = children(m)\n",
        "            if isinstance(m, nn.Module):\n",
        "                f(m)\n",
        "            if len(c) > 0:\n",
        "                for l in c:\n",
        "                    apply_leaf(l, f)\n",
        "        def set_trainable(l, b):\n",
        "            apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
        "\n",
        "        # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
        "        set_trainable(self.bert, False)\n",
        "        for i in range(start_layer, end_layer+1):\n",
        "            set_trainable(self.bert.encoder.layer[i], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63g97fDUiGe5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "0177ca2c01ce4ced845287b27c4a7ea5",
            "0f7180d126f446f5af54648d4306559b",
            "e951593fd1a94eea839a5d57135eb26a",
            "078f093289244760aa21d653c0e2912b",
            "b7cf93c787da48c4b78315f773026f74",
            "afd9254826404261a422d378b64f8cc8",
            "ab4a5aa66ffb4ffebf56d3c982594fe3",
            "5eab2e73f3284d29b9ef5de489b275d6",
            "7375eeb2159e48a99994d62502acdf64",
            "fdde378057f4441489fddca3c555ca2d",
            "95fa26b5f87b446e97e1f4792df5eea3",
            "c2f1a8a7f1d44b0f905daf4844522e10",
            "eab43361cd7e4a40a48e8eaf9f954c09",
            "830abae9c1a446eca8fd92ee35ee421a",
            "792f4dad67f84de3a22d6e72b5cf8771",
            "6f02a750a9d0491a91ca95b8e437eb37"
          ]
        },
        "outputId": "577a2d73-2083-4d2c-97f3-d3ba214d9c2d"
      },
      "source": [
        "model = BertForMultiLable.from_pretrained('bert-base-uncased', num_labels=len(label_cols))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0177ca2c01ce4ced845287b27c4a7ea5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7375eeb2159e48a99994d62502acdf64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcgFlTxEiUUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXPGndIFzOrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel, BertPreTrainedModel, PretrainedConfig\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_inputs)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_inputs)\n",
        "\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZxYAy7W3xG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "LEARNING_RATE = 1e-05\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3uuMhylzOom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41b74452-4746-4534-9a03-deb729effe41"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "model = model.to(device)\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,(ids, masks, labels) in enumerate(train_dataloader, 0):\n",
        "      \n",
        "      ids = ids.to(device, dtype = torch.long)\n",
        "      #print(ids)\n",
        "      masks = masks.to(device, dtype = torch.long)\n",
        "      #print(masks)\n",
        "      #token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "      targets = labels.to(device, dtype = torch.float)\n",
        "      #print(targets)\n",
        "\n",
        "      outputs = model(ids, masks)\n",
        "      #print(outputs)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      if _%1000==0:\n",
        "        print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAgg1dhizOm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5cd0a585-045b-46f1-8e52-c28cde4d8787"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.06785805523395538\n",
            "Epoch: 0, Loss:  0.06045281141996384\n",
            "Epoch: 0, Loss:  0.02914099022746086\n",
            "Epoch: 0, Loss:  0.017635757103562355\n",
            "Epoch: 0, Loss:  0.005338038317859173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bBfvwvMzOkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PPVBsUNzOea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UKSZY2SzObu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK5T1z-nzOY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQTgaJlRzOV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWFWMDNmiuaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)\n",
        "\n",
        "#t_total = int(len(train_dataloader) / args.gradient_accumulation_steps * args.epochs)\n",
        "steps_per_epoch = train_size // BATCH_SIZE\n",
        "validation_steps = validation_size // BATCH_SIZE\n",
        "warmup_steps = steps_per_epoch // 3\n",
        "total_steps = steps_per_epoch * EPOCHS - warmup_steps\n",
        "#warmup_steps = int(t_total * args.warmup_proportion)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
        "                                                num_training_steps=total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZeWrIblrHOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "5a935d2c-caf4-4619-ce89-accf9a1929e4"
      },
      "source": [
        "id2label = {i: label for i, label in enumerate(label_cols)}\n",
        "trainer = Trainer(model=model,criterion=BCEWithLogLoss(),optimizer=optimizer,\n",
        "                      scheduler=scheduler,early_stopping=None,\n",
        "                  #training_monitor=train_monitor,\n",
        "                     # model_checkpoint=model_checkpoint,\n",
        "                      batch_metrics=[AccuracyThresh(thresh=0.5)],\n",
        "                      epoch_metrics=[AUC(average='micro', task_type='binary'),\n",
        "                                     MultiLabelReport(id2label=id2label)])\n",
        "#trainer.train(train_data=train_dataloader, valid_data=valid_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-c782c4f07b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0mbatch_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAccuracyThresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       epoch_metrics=[AUC(average='micro', task_type='binary'),\n\u001b[0;32m----> 8\u001b[0;31m                                      MultiLabelReport(id2label=id2label)])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#trainer.train(train_data=train_dataloader, valid_data=valid_dataloader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-c4f34740a129>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, criterion, optimizer, scheduler, early_stopping, epoch_metrics, batch_metrics, verbose, training_monitor, model_checkpoint)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR2yDPuVrHIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddvZv8U-rHBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56TNgUUKrGu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "# from ..callback.progressbar import ProgressBar\n",
        "# from ..common.tools import model_device\n",
        "# from ..common.tools import summary\n",
        "# from ..common.tools import seed_everything\n",
        "# from ..common.tools import AverageMeter\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(self,model,criterion,optimizer,scheduler,early_stopping,epoch_metrics,\n",
        "                 batch_metrics,verbose = 1,training_monitor = None,model_checkpoint = None\n",
        "                 ):\n",
        "        # self.args = args\n",
        "        # self.model = model\n",
        "        self.logger =logger\n",
        "        self.verbose = verbose\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.early_stopping = early_stopping\n",
        "        self.epoch_metrics = epoch_metrics\n",
        "        self.batch_metrics = batch_metrics\n",
        "        self.model_checkpoint = model_checkpoint\n",
        "        self.training_monitor = training_monitor\n",
        "        self.start_epoch = 1\n",
        "        self.global_step = 0\n",
        "        self.model, self.device = model_device(n_gpu = args.n_gpu, model=self.model)\n",
        "        if args.fp16:\n",
        "            try:\n",
        "                from apex import amp\n",
        "            except ImportError:\n",
        "                raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        if args.resume_path:\n",
        "            self.logger.info(f\"\\nLoading checkpoint: {args.resume_path}\")\n",
        "            resume_dict = torch.load(args.resume_path / 'checkpoint_info.bin')\n",
        "            best = resume_dict['best']\n",
        "            self.start_epoch = resume_dict['epoch']\n",
        "            if self.model_checkpoint:\n",
        "                self.model_checkpoint.best = best\n",
        "            self.logger.info(f\"\\nCheckpoint '{args.resume_path}' and epoch {self.start_epoch} loaded\")\n",
        "\n",
        "    def epoch_reset(self):\n",
        "        self.outputs = []\n",
        "        self.targets = []\n",
        "        self.result = {}\n",
        "        for metric in self.epoch_metrics:\n",
        "            metric.reset()\n",
        "\n",
        "    def batch_reset(self):\n",
        "        self.info = {}\n",
        "        for metric in self.batch_metrics:\n",
        "            metric.reset()\n",
        "\n",
        "    def save_info(self,epoch,best):\n",
        "        model_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
        "        state = {\"model\":model_save,\n",
        "                 'epoch':epoch,\n",
        "                 'best':best}\n",
        "        return state\n",
        "\n",
        "    def valid_epoch(self,data):\n",
        "        pbar = ProgressBar(n_total=len(data),desc=\"Evaluating\")\n",
        "        self.epoch_reset()\n",
        "        for step, batch in enumerate(data):\n",
        "            self.model.eval()\n",
        "            batch = tuple(t.to(self.device) for t in batch)\n",
        "            with torch.no_grad():\n",
        "                input_ids, input_mask, segment_ids, label_ids = batch\n",
        "                logits = self.model(input_ids, segment_ids,input_mask)\n",
        "            self.outputs.append(logits.cpu().detach())\n",
        "            self.targets.append(label_ids.cpu().detach())\n",
        "            pbar(step=step)\n",
        "        self.outputs = torch.cat(self.outputs, dim = 0).cpu().detach()\n",
        "        self.targets = torch.cat(self.targets, dim = 0).cpu().detach()\n",
        "        loss = self.criterion(target = self.targets, output=self.outputs)\n",
        "        self.result['valid_loss'] = loss.item()\n",
        "        print(\"------------- valid result --------------\")\n",
        "        if self.epoch_metrics:\n",
        "            for metric in self.epoch_metrics:\n",
        "                metric(logits=self.outputs, target=self.targets)\n",
        "                value = metric.value()\n",
        "                if value:\n",
        "                    self.result[f'valid_{metric.name()}'] = value\n",
        "        if 'cuda' in str(self.device):\n",
        "            torch.cuda.empty_cache()\n",
        "        return self.result\n",
        "\n",
        "    def train_epoch(self,data):\n",
        "        pbar = ProgressBar(n_total = len(data),desc='Training')\n",
        "        tr_loss = AverageMeter()\n",
        "        self.epoch_reset()\n",
        "        for step,  batch in enumerate(data):\n",
        "            self.batch_reset()\n",
        "            self.model.train()\n",
        "            batch = tuple(t.to(self.device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids = batch\n",
        "            logits = self.model(input_ids, segment_ids,input_mask)\n",
        "            loss = self.criterion(output=logits,target=label_ids)\n",
        "            if len(self.args.n_gpu) >= 2:\n",
        "                loss = loss.mean()\n",
        "            if self.args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / self.args.gradient_accumulation_steps\n",
        "            if self.args.fp16:\n",
        "                with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "                clip_grad_norm_(amp.master_params(self.optimizer), self.args.grad_clip)\n",
        "            else:\n",
        "                loss.backward()\n",
        "                clip_grad_norm_(self.model.parameters(), self.args.grad_clip)\n",
        "            if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
        "                self.scheduler.step()\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "                self.global_step += 1\n",
        "            if self.batch_metrics:\n",
        "                for metric in self.batch_metrics:\n",
        "                    metric(logits = logits,target = label_ids)\n",
        "                    self.info[metric.name()] = metric.value()\n",
        "            self.info['loss'] = loss.item()\n",
        "            tr_loss.update(loss.item(),n = 1)\n",
        "            if self.verbose >= 1:\n",
        "                pbar(step= step,info = self.info)\n",
        "            self.outputs.append(logits.cpu().detach())\n",
        "            self.targets.append(label_ids.cpu().detach())\n",
        "        print(\"\\n------------- train result --------------\")\n",
        "        # epoch metric\n",
        "        self.outputs = torch.cat(self.outputs, dim =0).cpu().detach()\n",
        "        self.targets = torch.cat(self.targets, dim =0).cpu().detach()\n",
        "        self.result['loss'] = tr_loss.avg\n",
        "        if self.epoch_metrics:\n",
        "            for metric in self.epoch_metrics:\n",
        "                metric(logits=self.outputs, target=self.targets)\n",
        "                value = metric.value()\n",
        "                if value:\n",
        "                    self.result[f'{metric.name()}'] = value\n",
        "        if \"cuda\" in str(self.device):\n",
        "            torch.cuda.empty_cache()\n",
        "        return self.result\n",
        "\n",
        "    def train(self,train_data,valid_data):\n",
        "#         print(\"model summary info: \")\n",
        "#         for step, (input_ids, input_mask, segment_ids, label_ids) in enumerate(train_data):\n",
        "#             input_ids = input_ids.to(self.device)\n",
        "#             input_mask = input_mask.to(self.device)\n",
        "#             segment_ids = segment_ids.to(self.device)\n",
        "#             summary(self.model,*(input_ids, segment_ids,input_mask),show_input=True)\n",
        "#             break\n",
        "        # ***************************************************************\n",
        "        self.model.zero_grad()\n",
        "        seed_everything(self.args.seed)  # Added here for reproductibility (even between python 2 a\n",
        "        for epoch in range(self.start_epoch,self.start_epoch+self.args.epochs):\n",
        "            self.logger.info(f\"Epoch {epoch}/{self.args.epochs}\")\n",
        "            train_log = self.train_epoch(train_data)\n",
        "            valid_log = self.valid_epoch(valid_data)\n",
        "\n",
        "            logs = dict(train_log,**valid_log)\n",
        "            show_info = f'\\nEpoch: {epoch} - ' + \"-\".join([f' {key}: {value:.4f} ' for key,value in logs.items()])\n",
        "            self.logger.info(show_info)\n",
        "\n",
        "            # save\n",
        "            if self.training_monitor:\n",
        "                self.training_monitor.epoch_step(logs) \n",
        "\n",
        "            # save model\n",
        "            if self.model_checkpoint:\n",
        "                state = self.save_info(epoch,best=logs[self.model_checkpoint.monitor])\n",
        "                self.model_checkpoint.bert_epoch_step(current=logs[self.model_checkpoint.monitor],state = state)\n",
        "\n",
        "            # early_stopping\n",
        "            if self.early_stopping:\n",
        "                self.early_stopping.epoch_step(epoch=epoch, current=logs[self.early_stopping.monitor])\n",
        "                if self.early_stopping.stop_training:\n",
        "                    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5QjuoMetSe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "def print_config(config):\n",
        "    info = \"Running with the following configs:\\n\"\n",
        "    for k, v in config.items():\n",
        "        info += f\"\\t{k} : {str(v)}\\n\"\n",
        "    print(\"\\n\" + info + \"\\n\")\n",
        "    return\n",
        "\n",
        "def init_logger(log_file=None, log_file_level=logging.NOTSET):\n",
        "    '''\n",
        "    Example:\n",
        "        >>> init_logger(log_file)\n",
        "        >>> logger.info(\"abc'\")\n",
        "    '''\n",
        "    if isinstance(log_file,Path):\n",
        "        log_file = str(log_file)\n",
        "    log_format = logging.Formatter(fmt='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                                   datefmt='%m/%d/%Y %H:%M:%S')\n",
        "\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(logging.INFO)\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setFormatter(log_format)\n",
        "    logger.handlers = [console_handler]\n",
        "    if log_file and log_file != '':\n",
        "        file_handler = logging.FileHandler(log_file)\n",
        "        file_handler.setLevel(log_file_level)\n",
        "        # file_handler.setFormatter(log_format)\n",
        "        logger.addHandler(file_handler)\n",
        "    return logger\n",
        "\n",
        "def seed_everything(seed=1029):\n",
        "    '''\n",
        "    设置整个开发环境的seed\n",
        "    :param seed:\n",
        "    :param device:\n",
        "    :return:\n",
        "    '''\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # some cudnn methods can be random even after fixing the seed\n",
        "    # unless you tell it to be deterministic\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def prepare_device(use_gpu):\n",
        "    \"\"\"\n",
        "    setup GPU device if available, move model into configured device\n",
        "    # 如果n_gpu_use为数字，则使用range生成list\n",
        "    # 如果输入的是一个list，则默认使用list[0]作为controller\n",
        "    Example:\n",
        "        use_gpu = '' : cpu\n",
        "        use_gpu = '0': cuda:0\n",
        "        use_gpu = '0,1' : cuda:0 and cuda:1\n",
        "     \"\"\"\n",
        "    n_gpu_use = [int(x) for x in use_gpu.split(\",\")]\n",
        "    if not use_gpu:\n",
        "        device_type = 'cpu'\n",
        "    else:\n",
        "        device_type = f\"cuda:{n_gpu_use[0]}\"\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    if len(n_gpu_use) > 0 and n_gpu == 0:\n",
        "        logger.warning(\"Warning: There\\'s no GPU available on this machine, training will be performed on CPU.\")\n",
        "        device_type = 'cpu'\n",
        "    if len(n_gpu_use) > n_gpu:\n",
        "        msg = f\"Warning: The number of GPU\\'s configured to use is {n_gpu}, but only {n_gpu} are available on this machine.\"\n",
        "        logger.warning(msg)\n",
        "        n_gpu_use = range(n_gpu)\n",
        "    device = torch.device(device_type)\n",
        "    list_ids = n_gpu_use\n",
        "    return device, list_ids\n",
        "\n",
        "\n",
        "def model_device(n_gpu, model):\n",
        "    '''\n",
        "    :param n_gpu:\n",
        "    :param model:\n",
        "    :return:\n",
        "    '''\n",
        "    device, device_ids = prepare_device(n_gpu)\n",
        "    if len(device_ids) > 1:\n",
        "        logger.info(f\"current {len(device_ids)} GPUs\")\n",
        "        model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
        "    if len(device_ids) == 1:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = str(device_ids[0])\n",
        "    model = model.to(device)\n",
        "    return model, device\n",
        "\n",
        "def restore_checkpoint(resume_path, model=None):\n",
        "    '''\n",
        "    加载模型\n",
        "    :param resume_path:\n",
        "    :param model:\n",
        "    :param optimizer:\n",
        "    :return:\n",
        "    注意： 如果是加载Bert模型的话，需要调整，不能使用该模式\n",
        "    可以使用模块自带的Bert_model.from_pretrained(state_dict = your save state_dict)\n",
        "    '''\n",
        "    if isinstance(resume_path, Path):\n",
        "        resume_path = str(resume_path)\n",
        "    checkpoint = torch.load(resume_path)\n",
        "    best = checkpoint['best']\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    states = checkpoint['state_dict']\n",
        "    if isinstance(model, nn.DataParallel):\n",
        "        model.module.load_state_dict(states)\n",
        "    else:\n",
        "        model.load_state_dict(states)\n",
        "    return [model,best,start_epoch]\n",
        "\n",
        "def save_pickle(data, file_path):\n",
        "    '''\n",
        "    保存成pickle文件\n",
        "    :param data:\n",
        "    :param file_name:\n",
        "    :param pickle_path:\n",
        "    :return:\n",
        "    '''\n",
        "    if isinstance(file_path, Path):\n",
        "        file_path = str(file_path)\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "\n",
        "def load_pickle(input_file):\n",
        "    '''\n",
        "    读取pickle文件\n",
        "    :param pickle_path:\n",
        "    :param file_name:\n",
        "    :return:\n",
        "    '''\n",
        "    with open(str(input_file), 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "def save_json(data, file_path):\n",
        "    '''\n",
        "    保存成json文件\n",
        "    :param data:\n",
        "    :param json_path:\n",
        "    :param file_name:\n",
        "    :return:\n",
        "    '''\n",
        "    if not isinstance(file_path, Path):\n",
        "        file_path = Path(file_path)\n",
        "    # if isinstance(data,dict):\n",
        "    #     data = json.dumps(data)\n",
        "    with open(str(file_path), 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "\n",
        "def load_json(file_path):\n",
        "    '''\n",
        "    加载json文件\n",
        "    :param json_path:\n",
        "    :param file_name:\n",
        "    :return:\n",
        "    '''\n",
        "    if not isinstance(file_path, Path):\n",
        "        file_path = Path(file_path)\n",
        "    with open(str(file_path), 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "def json_to_text(file_path,data):\n",
        "    '''\n",
        "    chinese\n",
        "    将json list写入text文件中\n",
        "    :param file_path:\n",
        "    :param data:\n",
        "    :return:\n",
        "    '''\n",
        "    if not isinstance(file_path, Path):\n",
        "        file_path = Path(file_path)\n",
        "    with open(str(file_path), 'w') as fw:\n",
        "        for line in data:\n",
        "            line = json.dumps(line, ensure_ascii=False)\n",
        "            fw.write(line + '\\n')\n",
        "\n",
        "def save_model(model, model_path):\n",
        "    \"\"\" 存储不含有显卡信息的state_dict或model\n",
        "    :param model:\n",
        "    :param model_name:\n",
        "    :param only_param:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if isinstance(model_path, Path):\n",
        "        model_path = str(model_path)\n",
        "    if isinstance(model, nn.DataParallel):\n",
        "        model = model.module\n",
        "    state_dict = model.state_dict()\n",
        "    for key in state_dict:\n",
        "        state_dict[key] = state_dict[key].cpu()\n",
        "    torch.save(state_dict, model_path)\n",
        "\n",
        "def load_model(model, model_path):\n",
        "    '''\n",
        "    加载模型\n",
        "    :param model:\n",
        "    :param model_name:\n",
        "    :param model_path:\n",
        "    :param only_param:\n",
        "    :return:\n",
        "    '''\n",
        "    if isinstance(model_path, Path):\n",
        "        model_path = str(model_path)\n",
        "    logging.info(f\"loading model from {str(model_path)} .\")\n",
        "    states = torch.load(model_path)\n",
        "    state = states['state_dict']\n",
        "    if isinstance(model, nn.DataParallel):\n",
        "        model.module.load_state_dict(state)\n",
        "    else:\n",
        "        model.load_state_dict(state)\n",
        "    return model\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    '''\n",
        "    computes and stores the average and current value\n",
        "    Example:\n",
        "        >>> loss = AverageMeter()\n",
        "        >>> for step,batch in enumerate(train_data):\n",
        "        >>>     pred = self.model(batch)\n",
        "        >>>     raw_loss = self.metrics(pred,target)\n",
        "        >>>     loss.update(raw_loss.item(),n = 1)\n",
        "        >>> cur_loss = loss.avg\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def summary(model, *inputs, batch_size=-1, show_input=True):\n",
        "    '''\n",
        "    打印模型结构信息\n",
        "    :param model:\n",
        "    :param inputs:\n",
        "    :param batch_size:\n",
        "    :param show_input:\n",
        "    :return:\n",
        "    Example:\n",
        "        >>> print(\"model summary info: \")\n",
        "        >>> for step,batch in enumerate(train_data):\n",
        "        >>>     summary(self.model,*batch,show_input=True)\n",
        "        >>>     break\n",
        "    '''\n",
        "\n",
        "    def register_hook(module):\n",
        "        def hook(module, input, output=None):\n",
        "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
        "            module_idx = len(summary)\n",
        "\n",
        "            m_key = f\"{class_name}-{module_idx + 1}\"\n",
        "            summary[m_key] = OrderedDict()\n",
        "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
        "            summary[m_key][\"input_shape\"][0] = batch_size\n",
        "\n",
        "            if show_input is False and output is not None:\n",
        "                if isinstance(output, (list, tuple)):\n",
        "                    for out in output:\n",
        "                        if isinstance(out, torch.Tensor):\n",
        "                            summary[m_key][\"output_shape\"] = [\n",
        "                                [-1] + list(out.size())[1:]\n",
        "                            ][0]\n",
        "                        else:\n",
        "                            summary[m_key][\"output_shape\"] = [\n",
        "                                [-1] + list(out[0].size())[1:]\n",
        "                            ][0]\n",
        "                else:\n",
        "                    summary[m_key][\"output_shape\"] = list(output.size())\n",
        "                    summary[m_key][\"output_shape\"][0] = batch_size\n",
        "\n",
        "            params = 0\n",
        "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
        "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
        "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
        "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
        "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
        "            summary[m_key][\"nb_params\"] = params\n",
        "\n",
        "        if (not isinstance(module, nn.Sequential) and not isinstance(module, nn.ModuleList) and not (module == model)):\n",
        "            if show_input is True:\n",
        "                hooks.append(module.register_forward_pre_hook(hook))\n",
        "            else:\n",
        "                hooks.append(module.register_forward_hook(hook))\n",
        "\n",
        "    # create properties\n",
        "    summary = OrderedDict()\n",
        "    hooks = []\n",
        "\n",
        "    # register hook\n",
        "    model.apply(register_hook)\n",
        "    model(*inputs)\n",
        "\n",
        "    # remove these hooks\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    if show_input is True:\n",
        "        line_new = f\"{'Layer (type)':>25}  {'Input Shape':>25} {'Param #':>15}\"\n",
        "    else:\n",
        "        line_new = f\"{'Layer (type)':>25}  {'Output Shape':>25} {'Param #':>15}\"\n",
        "    print(line_new)\n",
        "    print(\"=======================================================================\")\n",
        "\n",
        "    total_params = 0\n",
        "    total_output = 0\n",
        "    trainable_params = 0\n",
        "    for layer in summary:\n",
        "        # input_shape, output_shape, trainable, nb_params\n",
        "        if show_input is True:\n",
        "            line_new = \"{:>25}  {:>25} {:>15}\".format(\n",
        "                layer,\n",
        "                str(summary[layer][\"input_shape\"]),\n",
        "                \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
        "            )\n",
        "        else:\n",
        "            line_new = \"{:>25}  {:>25} {:>15}\".format(\n",
        "                layer,\n",
        "                str(summary[layer][\"output_shape\"]),\n",
        "                \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
        "            )\n",
        "\n",
        "        total_params += summary[layer][\"nb_params\"]\n",
        "        if show_input is True:\n",
        "            total_output += np.prod(summary[layer][\"input_shape\"])\n",
        "        else:\n",
        "            total_output += np.prod(summary[layer][\"output_shape\"])\n",
        "        if \"trainable\" in summary[layer]:\n",
        "            if summary[layer][\"trainable\"] == True:\n",
        "                trainable_params += summary[layer][\"nb_params\"]\n",
        "\n",
        "        print(line_new)\n",
        "\n",
        "    print(\"=======================================================================\")\n",
        "    print(f\"Total params: {total_params:0,}\")\n",
        "    print(f\"Trainable params: {trainable_params:0,}\")\n",
        "    print(f\"Non-trainable params: {(total_params - trainable_params):0,}\")\n",
        "    print(\"-----------------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5bzHbIqjA_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "\n",
        "\n",
        "__call__ = ['CrossEntropy','BCEWithLogLoss']\n",
        "\n",
        "class CrossEntropy(object):\n",
        "    def __init__(self):\n",
        "        self.loss_f = CrossEntropyLoss()\n",
        "\n",
        "    def __call__(self, output, target):\n",
        "        loss = self.loss_f(input=output, target=target)\n",
        "        return loss\n",
        "\n",
        "class BCEWithLogLoss(object):\n",
        "    def __init__(self):\n",
        "        self.loss_fn = BCEWithLogitsLoss()\n",
        "\n",
        "    def __call__(self,output,target):\n",
        "        output = output.float()\n",
        "        target = target.float()\n",
        "        loss = self.loss_fn(input = output,target = target)\n",
        "        return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qGoQj-od0xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r\"\"\"Functional interface\"\"\"\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "__call__ = ['Accuracy','AUC','F1Score','EntityScore','ClassReport','MultiLabelReport','AccuracyThresh']\n",
        "\n",
        "class Metric:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, outputs, target):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def reset(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def value(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def name(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Accuracy(Metric):\n",
        "    '''\n",
        "    计算准确度\n",
        "    可以使用topK参数设定计算K准确度\n",
        "    Examples:\n",
        "        >>> metric = Accuracy(**)\n",
        "        >>> for epoch in range(epochs):\n",
        "        >>>     metric.reset()\n",
        "        >>>     for batch in batchs:\n",
        "        >>>         logits = model()\n",
        "        >>>         metric(logits,target)\n",
        "        >>>         print(metric.name(),metric.value())\n",
        "    '''\n",
        "    def __init__(self,topK):\n",
        "        super(Accuracy,self).__init__()\n",
        "        self.topK = topK\n",
        "        self.reset()\n",
        "\n",
        "    def __call__(self, logits, target):\n",
        "        _, pred = logits.topk(self.topK, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        self.correct_k = correct[:self.topK].view(-1).float().sum(0)\n",
        "        self.total = target.size(0)\n",
        "\n",
        "    def reset(self):\n",
        "        self.correct_k = 0\n",
        "        self.total = 0\n",
        "\n",
        "    def value(self):\n",
        "        return float(self.correct_k)  / self.total\n",
        "\n",
        "    def name(self):\n",
        "        return 'accuracy'\n",
        "\n",
        "\n",
        "class AccuracyThresh(Metric):\n",
        "    '''\n",
        "    计算准确度\n",
        "    可以使用topK参数设定计算K准确度\n",
        "    Example:\n",
        "        >>> metric = AccuracyThresh(**)\n",
        "        >>> for epoch in range(epochs):\n",
        "        >>>     metric.reset()\n",
        "        >>>     for batch in batchs:\n",
        "        >>>         logits = model()\n",
        "        >>>         metric(logits,target)\n",
        "        >>>         print(metric.name(),metric.value())\n",
        "    '''\n",
        "    def __init__(self,thresh = 0.5):\n",
        "        super(AccuracyThresh,self).__init__()\n",
        "        self.thresh = thresh\n",
        "        self.reset()\n",
        "\n",
        "    def __call__(self, logits, target):\n",
        "        self.y_pred = logits.sigmoid()\n",
        "        self.y_true = target\n",
        "\n",
        "    def reset(self):\n",
        "        self.correct_k = 0\n",
        "        self.total = 0\n",
        "\n",
        "    def value(self):\n",
        "        data_size = self.y_pred.size(0)\n",
        "        acc = np.mean(((self.y_pred>self.thresh)==self.y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
        "        return acc / data_size\n",
        "\n",
        "    def name(self):\n",
        "        return 'accuracy'\n",
        "\n",
        "\n",
        "class AUC(Metric):\n",
        "    '''\n",
        "    AUC score\n",
        "    micro:\n",
        "            Calculate metrics globally by considering each element of the label\n",
        "            indicator matrix as a label.\n",
        "    macro:\n",
        "            Calculate metrics for each label, and find their unweighted\n",
        "            mean.  This does not take label imbalance into account.\n",
        "    weighted:\n",
        "            Calculate metrics for each label, and find their average, weighted\n",
        "            by support (the number of true instances for each label).\n",
        "    samples:\n",
        "            Calculate metrics for each instance, and find their average.\n",
        "    Example:\n",
        "        >>> metric = AUC(**)\n",
        "        >>> for epoch in range(epochs):\n",
        "        >>>     metric.reset()\n",
        "        >>>     for batch in batchs:\n",
        "        >>>         logits = model()\n",
        "        >>>         metric(logits,target)\n",
        "        >>>         print(metric.name(),metric.value())\n",
        "    '''\n",
        "\n",
        "    def __init__(self,task_type = 'binary',average = 'binary'):\n",
        "        super(AUC, self).__init__()\n",
        "\n",
        "        assert task_type in ['binary','multiclass']\n",
        "        assert average in ['binary','micro', 'macro', 'samples', 'weighted']\n",
        "\n",
        "        self.task_type = task_type\n",
        "        self.average = average\n",
        "\n",
        "    def __call__(self,logits,target):\n",
        "        '''\n",
        "        计算整个结果\n",
        "        '''\n",
        "        if self.task_type == 'binary':\n",
        "            self.y_prob = logits.sigmoid().data.cpu().numpy()\n",
        "        else:\n",
        "            self.y_prob = logits.softmax(-1).data.cpu().detach().numpy()\n",
        "        self.y_true = target.cpu().numpy()\n",
        "\n",
        "    def reset(self):\n",
        "        self.y_prob = 0\n",
        "        self.y_true = 0\n",
        "\n",
        "    def value(self):\n",
        "        '''\n",
        "        计算指标得分\n",
        "        '''\n",
        "        auc = roc_auc_score(y_score=self.y_prob, y_true=self.y_true, average=self.average)\n",
        "        return auc\n",
        "\n",
        "    def name(self):\n",
        "        return 'auc'\n",
        "\n",
        "class F1Score(Metric):\n",
        "    '''\n",
        "    F1 Score\n",
        "    binary:\n",
        "            Only report results for the class specified by ``pos_label``.\n",
        "            This is applicable only if targets (``y_{true,pred}``) are binary.\n",
        "    micro:\n",
        "            Calculate metrics globally by considering each element of the label\n",
        "            indicator matrix as a label.\n",
        "    macro:\n",
        "            Calculate metrics for each label, and find their unweighted\n",
        "            mean.  This does not take label imbalance into account.\n",
        "    weighted:\n",
        "            Calculate metrics for each label, and find their average, weighted\n",
        "            by support (the number of true instances for each label).\n",
        "    samples:\n",
        "            Calculate metrics for each instance, and find their average.\n",
        "    Example:\n",
        "        >>> metric = F1Score(**)\n",
        "        >>> for epoch in range(epochs):\n",
        "        >>>     metric.reset()\n",
        "        >>>     for batch in batchs:\n",
        "        >>>         logits = model()\n",
        "        >>>         metric(logits,target)\n",
        "        >>>         print(metric.name(),metric.value())\n",
        "    '''\n",
        "    def __init__(self,thresh = 0.5, normalizate = True,task_type = 'binary',average = 'binary',search_thresh = False):\n",
        "        super(F1Score).__init__()\n",
        "        assert task_type in ['binary','multiclass']\n",
        "        assert average in ['binary','micro', 'macro', 'samples', 'weighted']\n",
        "\n",
        "        self.thresh = thresh\n",
        "        self.task_type = task_type\n",
        "        self.normalizate  = normalizate\n",
        "        self.search_thresh = search_thresh\n",
        "        self.average = average\n",
        "\n",
        "    def thresh_search(self,y_prob):\n",
        "        '''\n",
        "        对于f1评分的指标，一般我们需要对阈值进行调整，一般不会使用默认的0.5值，因此\n",
        "        这里我们队Thresh进行优化\n",
        "        :return:\n",
        "        '''\n",
        "        best_threshold = 0\n",
        "        best_score = 0\n",
        "        for threshold in tqdm([i * 0.01 for i in range(100)], disable=True):\n",
        "            self.y_pred = y_prob > threshold\n",
        "            score = self.value()\n",
        "            if score > best_score:\n",
        "                best_threshold = threshold\n",
        "                best_score = score\n",
        "        return best_threshold,best_score\n",
        "\n",
        "    def __call__(self,logits,target):\n",
        "        '''\n",
        "        计算整个结果\n",
        "        :return:\n",
        "        '''\n",
        "        self.y_true = target.cpu().numpy()\n",
        "        if self.normalizate and self.task_type == 'binary':\n",
        "            y_prob = logits.sigmoid().data.cpu().numpy()\n",
        "        elif self.normalizate and self.task_type == 'multiclass':\n",
        "            y_prob = logits.softmax(-1).data.cpu().detach().numpy()\n",
        "        else:\n",
        "            y_prob = logits.cpu().detach().numpy()\n",
        "\n",
        "        if self.task_type == 'binary':\n",
        "            if self.thresh and self.search_thresh == False:\n",
        "                self.y_pred = (y_prob > self.thresh ).astype(int)\n",
        "                self.value()\n",
        "            else:\n",
        "                thresh,f1 = self.thresh_search(y_prob = y_prob)\n",
        "                print(f\"Best thresh: {thresh:.4f} - F1 Score: {f1:.4f}\")\n",
        "\n",
        "        if self.task_type == 'multiclass':\n",
        "            self.y_pred = np.argmax(y_prob, 1)\n",
        "\n",
        "    def reset(self):\n",
        "        self.y_pred = 0\n",
        "        self.y_true = 0\n",
        "\n",
        "    def value(self):\n",
        "        '''\n",
        "         计算指标得分\n",
        "         '''\n",
        "        f1 = f1_score(y_true=self.y_true, y_pred=self.y_pred, average=self.average)\n",
        "        return f1\n",
        "\n",
        "    def name(self):\n",
        "        return 'f1'\n",
        "\n",
        "class ClassReport(Metric):\n",
        "    '''\n",
        "    class report\n",
        "    '''\n",
        "    def __init__(self,target_names = None):\n",
        "        super(ClassReport).__init__()\n",
        "        self.target_names = target_names\n",
        "\n",
        "    def reset(self):\n",
        "        self.y_pred = 0\n",
        "        self.y_true = 0\n",
        "\n",
        "    def value(self):\n",
        "        '''\n",
        "        计算指标得分\n",
        "        '''\n",
        "        score = classification_report(y_true = self.y_true,\n",
        "                                      y_pred = self.y_pred,\n",
        "                                      target_names=self.target_names)\n",
        "        print(f\"\\n\\n classification report: {score}\")\n",
        "\n",
        "    def __call__(self,logits,target):\n",
        "        _, y_pred = torch.max(logits.data, 1)\n",
        "        self.y_pred = y_pred.cpu().numpy()\n",
        "        self.y_true = target.cpu().numpy()\n",
        "\n",
        "    def name(self):\n",
        "        return \"class_report\"\n",
        "\n",
        "class MultiLabelReport(Metric):\n",
        "    '''\n",
        "    multi label report\n",
        "    '''\n",
        "    def __init__(self,id2label = None):\n",
        "        super(MultiLabelReport).__init__()\n",
        "        self.id2label = id2label\n",
        "\n",
        "    def reset(self):\n",
        "        self.y_prob = 0\n",
        "        self.y_true = 0\n",
        "\n",
        "    def __call__(self,logits,target):\n",
        "\n",
        "        self.y_prob = logits.sigmoid().data.cpu().detach().numpy()\n",
        "        self.y_true = target.cpu().numpy()\n",
        "\n",
        "    def value(self):\n",
        "        '''\n",
        "        计算指标得分\n",
        "        '''\n",
        "        for i, label in self.id2label.items():\n",
        "            auc = roc_auc_score(y_score=self.y_prob[:, i], y_true=self.y_true[:, i])\n",
        "            print(f\"label:{label} - auc: {auc:.4f}\")\n",
        "\n",
        "    def name(self):\n",
        "        return \"multilabel_report\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of0ToiSYd0vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DckAWavdd0sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqamsPPbd0qW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTeCwkP0d0nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVnY4xJOd0lH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abM18v-id0ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_7sBTgMd0f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51HEta0wd0dU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ievhEljZ40Jm",
        "colab_type": "text"
      },
      "source": [
        "#### Pytorch BERT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxtpbuuAAOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel, BertPreTrainedModel, PretrainedConfig\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6VbSuS346t3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel, BertPreTrainedModel, PretrainedConfig\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_inputs)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_inputs)\n",
        "\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MffX2Tbs46of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_inputs)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja6Eky9S46kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_inputs)\n",
        "\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUq2rswj46Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=6):\n",
        "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "        #self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        pooled_out = output[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            return loss\n",
        "        else:\n",
        "            return logits\n",
        "        \n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHZGirlLyARJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForMultiLabelSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_cols))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJv4IEA5Kec0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = len(label_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHHrWyJdyANc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVivlc7cBezS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# setting custom optimization parameters. You may implement a scheduler here as well.\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)\n",
        "# optimizer = AdamW(model.parameters(),lr=2e-5)  # Default optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3RcdxnNBewP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "b41ed076-7f65-46da-bc27-763408e4742e"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0 #running loss\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # # Forward pass for multiclass classification\n",
        "    # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    # loss = outputs[0]\n",
        "    # logits = outputs[1]\n",
        "\n",
        "    # Forward pass for multilabel classification\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    # loss_func = BCELoss() \n",
        "    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "  # Predict\n",
        "  for i, batch in enumerate(validation_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    with torch.no_grad():\n",
        "      # Forward pass\n",
        "      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  threshold = 0.50\n",
        "  pred_bools = [pl>threshold for pl in pred_labels]\n",
        "  true_bools = [tl==1 for tl in true_labels]\n",
        "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
        "\n",
        "  print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-1d2e0937e78d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Update parameters and take a step using the computed gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b52o_Ll-Belg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5604413-dfaa-4765-8fc3-954bf8f4f8ef"
      },
      "source": [
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "import pickle\n",
        "from transformers import *\n",
        "from tqdm import tqdm, trange\n",
        "from ast import literal_eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzHqgBFPDW8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdHH9V3JDW3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVB38dd8DW1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXy2b8yPDWzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAHDRWqDWyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAp3jQUEDWt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLdBwVY5DWsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNAhLWUnDWou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch mordel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE0sXB4IKiAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "import pickle\n",
        "from transformers import *\n",
        "from tqdm import tqdm, trange\n",
        "from ast import literal_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPKfEmyEMUBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cea270e-1a31-4b06-a555-88bc401469f0"
      },
      "source": [
        "df = df_train\n",
        "cols = df.columns\n",
        "label_cols = list(cols[2:])\n",
        "num_labels = len(label_cols)\n",
        "print('Label columns: ', label_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label columns:  ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65uTf9gAMfX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2e0d1bbd-6c26-4368-92d3-1c742939b719"
      },
      "source": [
        "df['one_hot_labels'] = list(df[label_cols].values)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...      one_hot_labels\n",
              "0  0000997932d777bf  ...  [0, 0, 0, 0, 0, 0]\n",
              "1  000103f0d9cfb60f  ...  [0, 0, 0, 0, 0, 0]\n",
              "2  000113f07ec002fd  ...  [0, 0, 0, 0, 0, 0]\n",
              "3  0001b41b1c6bb37e  ...  [0, 0, 0, 0, 0, 0]\n",
              "4  0001d958c54c6e35  ...  [0, 0, 0, 0, 0, 0]\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmfpjtOyMlnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = list(df.one_hot_labels.values)\n",
        "comments = list(df.comment_text.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyYx_sg0Mn_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0de12f28-cc0c-448c-a640-8dc8f5c22d95"
      },
      "source": [
        "# Identifying indices of 'one_hot_labels' entries that only occur once - this will allow us to stratify split our training data later\n",
        "label_counts = df.one_hot_labels.astype(str).value_counts()\n",
        "one_freq = label_counts[label_counts==1].keys()\n",
        "one_freq_idxs = sorted(list(df[df.one_hot_labels.astype(str).isin(one_freq)].index), reverse=True)\n",
        "print('df label indices with only one instance: ', one_freq_idxs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df label indices with only one instance:  [134459, 107881]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT9zDvo4MqvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0958811f-9fe4-4def-b34b-13d7c369fbe2"
      },
      "source": [
        "max_length = 100\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer\n",
        "encodings = tokenizer.batch_encode_plus(comments,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n",
        "print('tokenizer outputs: ', encodings.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTEyLzfMMzDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = encodings['input_ids'] # tokenized and encoded sentences\n",
        "token_type_ids = encodings['token_type_ids'] # token type ids\n",
        "attention_masks = encodings['attention_mask'] # attention masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pml2Woq2M1zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gathering single instance inputs to force into the training set after stratified split\n",
        "one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n",
        "one_freq_token_types = [token_type_ids.pop(i) for i in one_freq_idxs]\n",
        "one_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\n",
        "one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNIu2r8OM4lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids,attention_masks,\n",
        "                                                            random_state=2020, test_size=0.10, stratify = labels)\n",
        "\n",
        "# Add one frequency data to train data\n",
        "train_inputs.extend(one_freq_input_ids)\n",
        "train_labels.extend(one_freq_labels)\n",
        "train_masks.extend(one_freq_attention_masks)\n",
        "train_token_types.extend(one_freq_token_types)\n",
        "\n",
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "train_token_types = torch.tensor(train_token_types)\n",
        "\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "validation_token_types = torch.tensor(validation_token_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiNR4PoCNEKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kMV_IeBNItI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0ec1e5e-45f7-4b83-c93e-8bfcff6aea75"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYBFtuniNO5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting custom optimization parameters. You may implement a scheduler here as well.\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)\n",
        "# optimizer = AdamW(model.parameters(),lr=2e-5)  # Default optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UJB0oxON5Lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "645d57af-15cb-4694-cbac-0645f1c5c661"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 1\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0 #running loss\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # # Forward pass for multiclass classification\n",
        "    # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    # loss = outputs[0]\n",
        "    # logits = outputs[1]\n",
        "\n",
        "    # Forward pass for multilabel classification\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    # loss_func = BCELoss() \n",
        "    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "  # Predict\n",
        "  for i, batch in enumerate(validation_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    with torch.no_grad():\n",
        "      # Forward pass\n",
        "      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  threshold = 0.50\n",
        "  pred_bools = [pl>threshold for pl in pred_labels]\n",
        "  true_bools = [tl==1 for tl in true_labels]\n",
        "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
        "\n",
        "  print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.05055477690936208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch: 100%|██████████| 1/1 [1:17:51<00:00, 4671.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  78.0175621372228\n",
            "Flat Validation Accuracy:  92.76179733032525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zAYYE2pN6Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}