{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_with_Fastai_for_Tabular_with_text.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binliu0630/Deep_Learning/blob/master/Classification_with_Fastai_for_Tabular_with_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uodQ2B44gZHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWYP15JoggUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZY2MTC1gvhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6eda5f6a-e49e-417f-f338-9977e7c6c039"
      },
      "source": [
        "from fastai.tabular import *\n",
        "from fastai.text import *\n",
        "from fastai.text.data import _join_texts\n",
        "\n",
        "print(f'fastai version: {__version__}')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version: 1.0.59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBebJoH9h6hh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10093556-c94c-442c-c0a1-b0c3c9317c37"
      },
      "source": [
        "# device = torch.cuda.current_device()\n",
        "# print(device)\n",
        "# torch.cuda.set_device(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzOgQ9cwkV2b",
        "colab_type": "text"
      },
      "source": [
        "Custom DatablockAPI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baW2HL-PkVVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MixedTabularLine(TabularLine):\n",
        "    \"Item's that include both tabular data(`conts` and `cats`) and textual data (numericalized `ids`)\"\n",
        "    \n",
        "    def __init__(self, cats, conts, cat_classes, col_names, txt_ids, txt_cols, txt_string):\n",
        "        # tabular\n",
        "        super().__init__(cats, conts, cat_classes, col_names)\n",
        "\n",
        "        # add the text bits\n",
        "        self.text_ids = txt_ids\n",
        "        self.text_cols = txt_cols\n",
        "        self.text = txt_string\n",
        "        \n",
        "        # append numericalted text data to your input (represents your X values that are fed into your model)\n",
        "        # self.data = [tensor(cats), tensor(conts), tensor(txt_ids)]\n",
        "        self.data += [ np.array(txt_ids, dtype=np.int64) ]\n",
        "        self.obj = self.data\n",
        "        \n",
        "    def __str__(self):\n",
        "        res = super().__str__() + f'Text: {self.text}'\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS0zeV6EkiKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MixedTabularProcessor(TabularProcessor):\n",
        "    \n",
        "    def __init__(self, ds:ItemList=None, procs=None, \n",
        "                 tokenizer:Tokenizer=None, chunksize:int=10000,\n",
        "                 vocab:Vocab=None, max_vocab:int=60000, min_freq:int=2):\n",
        "        #pdb.set_trace()\n",
        "        super().__init__(ds, procs)\n",
        "    \n",
        "        self.tokenizer, self.chunksize = ifnone(tokenizer, Tokenizer()), chunksize\n",
        "        \n",
        "        vocab = ifnone(vocab, ds.vocab if ds is not None else None)\n",
        "        self.vocab, self.max_vocab, self.min_freq = vocab, max_vocab, min_freq\n",
        "        \n",
        "    # process a single item in a dataset\n",
        "    # NOTE: THIS IS METHOD HAS NOT BEEN TESTED AT THIS POINT (WILL COVER IN A FUTURE ARTICLE)\n",
        "    def process_one(self, item):\n",
        "        # process tabular data (copied form tabular.data)\n",
        "        df = pd.DataFrame([item, item])\n",
        "        for proc in self.procs: proc(df, test=True)\n",
        "            \n",
        "        if len(self.cat_names) != 0:\n",
        "            codes = np.stack([c.cat.codes.values for n,c in df[self.cat_names].items()], 1).astype(np.int64) + 1\n",
        "        else: \n",
        "            codes = [[]]\n",
        "            \n",
        "        if len(self.cont_names) != 0:\n",
        "            conts = np.stack([c.astype('float32').values for n,c in df[self.cont_names].items()], 1)\n",
        "        else: \n",
        "            conts = [[]]\n",
        "            \n",
        "        classes = None\n",
        "        col_names = list(df[self.cat_names].columns.values) + list(df[self.cont_names].columns.values)\n",
        "        \n",
        "        # process textual data\n",
        "        if len(self.text_cols) != 0:\n",
        "            txt = _join_texts(df[self.text_cols].values, (len(self.text_cols) > 1))\n",
        "            txt_toks = self.tokenizer._process_all_1(txt)[0]\n",
        "            text_ids = np.array(self.vocab.numericalize(txt_toks), dtype=np.int64)\n",
        "        else:\n",
        "            txt_toks, text_ids = None, [[]]\n",
        "            \n",
        "        # return ItemBase\n",
        "        return MixedTabularLine(codes[0], conts[0], classes, col_names, text_ids, self.txt_cols, txt_toks)\n",
        "    \n",
        "    # processes the entire dataset\n",
        "    def process(self, ds):\n",
        "        #pdb.set_trace()\n",
        "        # process tabular data and then set \"preprocessed=False\" since we still have text data possibly\n",
        "        super().process(ds)\n",
        "        ds.preprocessed = False\n",
        "        \n",
        "        # process text data from column(s) containing text\n",
        "        if len(ds.text_cols) != 0:\n",
        "            texts = _join_texts(ds.inner_df[ds.text_cols].values, (len(ds.text_cols) > 1))\n",
        "\n",
        "            # tokenize (set = .text)\n",
        "            tokens = []\n",
        "            for i in progress_bar(range(0, len(ds), self.chunksize), leave=False):\n",
        "                tokens += self.tokenizer.process_all(texts[i:i+self.chunksize])\n",
        "            ds.text = tokens\n",
        "\n",
        "            # set/build vocab\n",
        "            if self.vocab is None: self.vocab = Vocab.create(ds.text, self.max_vocab, self.min_freq)\n",
        "            ds.vocab = self.vocab\n",
        "            ds.text_ids = [ np.array(self.vocab.numericalize(toks), dtype=np.int64) for toks in ds.text ]\n",
        "        else:\n",
        "            ds.text, ds.vocab, ds.text_ids = None, None, []\n",
        "            \n",
        "        ds.preprocessed = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKn8NZ9ukiIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# similar to the \"fasta.text.data.pad_collate\" except that it is designed to work with MixedTabularLine items,\n",
        "# where the final thing in an item is the numericalized text ids.\n",
        "# we need a collate function to ensure a square matrix with the text ids, which will be of variable length.\n",
        "def mixed_tabular_pad_collate(samples:BatchSamples, \n",
        "                              pad_idx:int=1, pad_first:bool=True) -> Tuple[LongTensor, LongTensor]:\n",
        "    \"Function that collect samples and adds padding.\"\n",
        "\n",
        "    samples = to_data(samples)\n",
        "    max_len = max([len(s[0][-1]) for s in samples])\n",
        "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
        "   \n",
        "    for i,s in enumerate(samples):\n",
        "        if pad_first: \n",
        "            res[i,-len(s[0][-1]):] = LongTensor(s[0][-1])\n",
        "        else:         \n",
        "            res[i,:len(s[0][-1]):] = LongTensor(s[0][-1])\n",
        "            \n",
        "        # replace the text_ids array (the last thing in the inputs) with the padded tensor matrix\n",
        "        s[0][-1] = res[i]\n",
        "             \n",
        "    # 10/31/2019 (wtg) - keeping the old code so you can see the difference ...\n",
        "    # for the inputs, return a list containing 3 elements: a list of cats, a list of conts, and a list of text_ids\n",
        "    # return [x for x in zip(*[s[0] for s in samples])], tensor([s[1] for s in samples])\n",
        "\n",
        "    cats = torch.cat([ s[0][0].unsqueeze(0) for s in samples ], 0)\n",
        "    conts = torch.cat([ s[0][1].unsqueeze(0) for s in samples ], 0)\n",
        "    texts = torch.cat([ s[0][2].unsqueeze(0) for s in samples ], 0)\n",
        "    return [cats, conts, texts], tensor([ s[1] for s in samples ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAtmrmhNkiF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# each \"ds\" is of type LabelList(Dataset)\n",
        "class MixedTabularDataBunch(DataBunch):\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs=64, \n",
        "               pad_idx=1, pad_first=True, no_check:bool=False, **kwargs) -> DataBunch:\n",
        "        \n",
        "        # only thing we're doing here is setting the collate_fn = to our new \"pad_collate\" method above\n",
        "        collate_fn = partial(mixed_tabular_pad_collate, pad_idx=pad_idx, pad_first=pad_first)\n",
        "        \n",
        "        kwargs['collate_fn'] = collate_fn\n",
        "        kwargs['num_workers'] = 1\n",
        "        return super().create(train_ds, valid_ds, test_ds, path=path, bs=bs, no_check=no_check, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p77ckrLkiDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MixedTabularList(TabularList):\n",
        "    \"A custom `ItemList` that merges tabular data along with textual data\"\n",
        "    \n",
        "    _item_cls = MixedTabularLine\n",
        "    _processor = MixedTabularProcessor\n",
        "    _bunch = MixedTabularDataBunch\n",
        "    \n",
        "    def __init__(self, items:Iterator, cat_names:OptStrList=None, cont_names:OptStrList=None, \n",
        "                 text_cols=None, vocab:Vocab=None, pad_idx:int=1, \n",
        "                 procs=None, **kwargs) -> 'MixedTabularList':\n",
        "        #pdb.set_trace()\n",
        "        super().__init__(items, cat_names, cont_names, procs, **kwargs)\n",
        "        \n",
        "        self.cols = [] if cat_names == None else cat_names.copy()\n",
        "        if cont_names: self.cols += cont_names.copy()\n",
        "        if txt_cols: self.cols += text_cols.copy()\n",
        "        \n",
        "        self.text_cols, self.vocab, self.pad_idx = text_cols, vocab, pad_idx\n",
        "        \n",
        "        # add any ItemList state into \"copy_new\" that needs to be copied each time \"new()\" is called; \n",
        "        # your ItemList acts as a prototype for training, validation, and/or test ItemList instances that\n",
        "        # are created via ItemList.new()\n",
        "        self.copy_new += ['text_cols', 'vocab', 'pad_idx']\n",
        "        \n",
        "        self.preprocessed = False\n",
        "        \n",
        "    # defines how to construct an ItemBase from the data in the ItemList.items array\n",
        "    def get(self, i):\n",
        "        if not self.preprocessed: \n",
        "            return self.inner_df.iloc[i][self.cols] if hasattr(self, 'inner_df') else self.items[i]\n",
        "        \n",
        "        codes = [] if self.codes is None else self.codes[i]\n",
        "        conts = [] if self.conts is None else self.conts[i]\n",
        "        text_ids = [] if self.text_ids is None else self.text_ids[i]\n",
        "        text_string = None if self.text_ids is None else self.vocab.textify(self.text_ids[i])\n",
        "        \n",
        "        return self._item_cls(codes, conts, self.classes, self.col_names, text_ids, self.text_cols, text_string)\n",
        "    \n",
        "    # this is the method that is called in data.show_batch(), learn.predict() or learn.show_results() \n",
        "    # to transform a pytorch tensor back in an ItemBase. \n",
        "    # in a way, it does the opposite of calling ItemBase.data. It should take a tensor t and return \n",
        "    # the same king of thing as the get method.\n",
        "    def reconstruct(self, t:Tensor):\n",
        "        return self._item_cls(t[0], t[1], self.classes, self.col_names, \n",
        "                              t[2], self.text_cols, self.vocab.textify(t[2]))\n",
        "    \n",
        "    # tells fastai how to display a custom ItemBase when data.show_batch() is called\n",
        "    def show_xys(self, xs, ys) -> None:\n",
        "        \"Show the `xs` (inputs) and `ys` (targets).\"\n",
        "        from IPython.display import display, HTML\n",
        "        \n",
        "        # show tabular\n",
        "        display(HTML('TABULAR:<br>'))\n",
        "        super().show_xys(xs, ys)\n",
        "        \n",
        "        # show text\n",
        "        items = [['text_data', 'target']]\n",
        "        for i, (x,y) in enumerate(zip(xs,ys)):\n",
        "            res = []\n",
        "            res += [' '.join([ f'{tok}({self.vocab.stoi[tok]})' \n",
        "                              for tok in x.text.split() if (not self.vocab.stoi[tok] == self.pad_idx) ])]\n",
        "                \n",
        "            res += [str(y)]\n",
        "            items.append(res)\n",
        "            \n",
        "        col_widths = [90, 1]\n",
        "        \n",
        "        display(HTML('TEXT:<br>'))\n",
        "        display(HTML(text2html_table(items)))\n",
        "        \n",
        "    # tells fastai how to display a custom ItemBase when learn.show_results() is called\n",
        "    def show_xyzs(self, xs, ys, zs):\n",
        "        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions).\"\n",
        "        from IPython.display import display, HTML\n",
        "        \n",
        "        # show tabular\n",
        "        super().show_xyzs(xs, ys, zs)\n",
        "        \n",
        "        # show text\n",
        "        items = [['text_data','target', 'prediction']]\n",
        "        for i, (x,y,z) in enumerate(zip(xs,ys,zs)):\n",
        "            res = []\n",
        "            res += [' '.join([ f'{tok}({self.vocab.stoi[tok]})'\n",
        "                              for tok in x.text.split() if (not self.vocab.stoi[tok] == self.pad_idx) ])]\n",
        "                \n",
        "            res += [str(y),str(z)]\n",
        "            items.append(res)\n",
        "            \n",
        "        col_widths = [90, 1, 1]\n",
        "        display(HTML('<br>' + text2html_table(items)))\n",
        "    \n",
        "        \n",
        "    @classmethod\n",
        "    def from_df(cls, df:DataFrame, cat_names:OptStrList=None, cont_names:OptStrList=None, \n",
        "                text_cols=None, vocab=None, procs=None, **kwargs) -> 'ItemList':\n",
        "        \n",
        "        return cls(items=range(len(df)), cat_names=cat_names, cont_names=cont_names, \n",
        "                   text_cols=text_cols, vocab=vocab, procs=procs, inner_df=df, **kwargs)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp23dcq0kiBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aICZMB9zkh-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxbiPQH3kh8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCQsXhLUkh1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9FA4TxGgHPD",
        "colab_type": "text"
      },
      "source": [
        "**Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C00DfNRTgDHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"https://s3.amazonaws.com/tomk/h2o-world/megan/AmazonReviews.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFcn2u-NgR5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "cee0aa43-0439-40cc-8b08-2f12bfe62ac8"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Score</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>Time</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B00141QYSQ</td>\n",
              "      <td>A1YS02UZZGRDCT</td>\n",
              "      <td>Do Not Buy</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>41471</td>\n",
              "      <td>Evan Eberhardt</td>\n",
              "      <td>2</td>\n",
              "      <td>1348358400</td>\n",
              "      <td>These are made in China (do not buy ANY pet food from China).  Dogswell has been using propylene glycol to soften their treats (what are they thinkng?).  Do not purchase or support this company in any way until they clean up their act.  And for whatever reason Amazon doesn't allow returns of this item, so I had to toss mine out.  Bad business all around on this one.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B0089SPEO2</td>\n",
              "      <td>A3JOYNYL458QHP</td>\n",
              "      <td>Less lemon and less zing</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>28582</td>\n",
              "      <td>coleridge</td>\n",
              "      <td>0</td>\n",
              "      <td>1323907200</td>\n",
              "      <td>Everything is ok, except it just isn't as good as it is in the bags.  Just considerably more bland -- less lemon and less zing.  Boring.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B001PMCDK2</td>\n",
              "      <td>A14TTMM0Z03Y2W</td>\n",
              "      <td>my cat goes crazy for these!</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>389965</td>\n",
              "      <td>Lindsay S. Bradford</td>\n",
              "      <td>0</td>\n",
              "      <td>1310601600</td>\n",
              "      <td>Best cat treat ever. There isn't anything comparable to the love my cat has for these treats, he snubs away any other kind now.&lt;br /&gt;I know he likes to manipulate me with his cattiness but these treats are my way of manipulating him to come sit on my lap and have some chill time. :)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B002Q8JOSI</td>\n",
              "      <td>A17UQD2RSSQH5X</td>\n",
              "      <td>My dogs tell me these treats are YUMMY</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>212536</td>\n",
              "      <td>in the dark</td>\n",
              "      <td>1</td>\n",
              "      <td>1316131200</td>\n",
              "      <td>My two Corgis were thoroughly spoiled by my late husband (I spent a year and a half dieting them down a combined total of 25 pounds!)&lt;br /&gt;&lt;br /&gt;They are accustomed to the finest of fare, and they absolutely love the Wellness brand of treats.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00176G870</td>\n",
              "      <td>A2F2MZW8EOGH5J</td>\n",
              "      <td>Yummy to the tummy</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>115971</td>\n",
              "      <td>daemoncycler \"When you arrive at a fork in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>1334793600</td>\n",
              "      <td>We used to have drive down to the specialty pet food store for this product.  So glad we discovered Amazon.  As far as I can tell it is no more expensive &amp; in some cases less - Prime membership is awesome.  Loving Pets treats are some of the best according to my dog.  They do not develop that nasty smell like some dog treats do.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ProductId          UserId                                 Summary  Score  \\\n",
              "0  B00141QYSQ  A1YS02UZZGRDCT  Do Not Buy                              1       \n",
              "1  B0089SPEO2  A3JOYNYL458QHP  Less lemon and less zing                3       \n",
              "2  B001PMCDK2  A14TTMM0Z03Y2W  my cat goes crazy for these!            5       \n",
              "3  B002Q8JOSI  A17UQD2RSSQH5X  My dogs tell me these treats are YUMMY  5       \n",
              "4  B00176G870  A2F2MZW8EOGH5J  Yummy to the tummy                      5       \n",
              "\n",
              "   HelpfulnessDenominator      Id  \\\n",
              "0  2                       41471    \n",
              "1  0                       28582    \n",
              "2  0                       389965   \n",
              "3  1                       212536   \n",
              "4  0                       115971   \n",
              "\n",
              "                                        ProfileName  HelpfulnessNumerator  \\\n",
              "0  Evan Eberhardt                                    2                      \n",
              "1  coleridge                                         0                      \n",
              "2  Lindsay S. Bradford                               0                      \n",
              "3  in the dark                                       1                      \n",
              "4  daemoncycler \"When you arrive at a fork in th...  0                      \n",
              "\n",
              "         Time  \\\n",
              "0  1348358400   \n",
              "1  1323907200   \n",
              "2  1310601600   \n",
              "3  1316131200   \n",
              "4  1334793600   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                               Text  \n",
              "0  These are made in China (do not buy ANY pet food from China).  Dogswell has been using propylene glycol to soften their treats (what are they thinkng?).  Do not purchase or support this company in any way until they clean up their act.  And for whatever reason Amazon doesn't allow returns of this item, so I had to toss mine out.  Bad business all around on this one.  \n",
              "1  Everything is ok, except it just isn't as good as it is in the bags.  Just considerably more bland -- less lemon and less zing.  Boring.                                                                                                                                                                                                                                          \n",
              "2  Best cat treat ever. There isn't anything comparable to the love my cat has for these treats, he snubs away any other kind now.<br />I know he likes to manipulate me with his cattiness but these treats are my way of manipulating him to come sit on my lap and have some chill time. :)                                                                                       \n",
              "3  My two Corgis were thoroughly spoiled by my late husband (I spent a year and a half dieting them down a combined total of 25 pounds!)<br /><br />They are accustomed to the finest of fare, and they absolutely love the Wellness brand of treats.                                                                                                                                \n",
              "4  We used to have drive down to the specialty pet food store for this product.  So glad we discovered Amazon.  As far as I can tell it is no more expensive & in some cases less - Prime membership is awesome.  Loving Pets treats are some of the best according to my dog.  They do not develop that nasty smell like some dog treats do.                                        "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLfS8yYVipYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "140dc3c3-b512-4ff8-e3c2-9089e1ec7b4b"
      },
      "source": [
        "data.describe().T"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Score</th>\n",
              "      <td>100000.0</td>\n",
              "      <td>4.186090e+00</td>\n",
              "      <td>1.309541e+00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <td>100000.0</td>\n",
              "      <td>2.236560e+00</td>\n",
              "      <td>8.805400e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>8.780000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <td>100000.0</td>\n",
              "      <td>2.846200e+05</td>\n",
              "      <td>1.641594e+05</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.422378e+05</td>\n",
              "      <td>2.856740e+05</td>\n",
              "      <td>4.263818e+05</td>\n",
              "      <td>5.684360e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <td>100000.0</td>\n",
              "      <td>1.745550e+00</td>\n",
              "      <td>8.171451e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>8.660000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <td>100000.0</td>\n",
              "      <td>1.296172e+09</td>\n",
              "      <td>4.810743e+07</td>\n",
              "      <td>940809600.0</td>\n",
              "      <td>1.271203e+09</td>\n",
              "      <td>1.311120e+09</td>\n",
              "      <td>1.332720e+09</td>\n",
              "      <td>1.351210e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           count          mean  ...           75%           max\n",
              "Score                   100000.0  4.186090e+00  ...  5.000000e+00  5.000000e+00\n",
              "HelpfulnessDenominator  100000.0  2.236560e+00  ...  2.000000e+00  8.780000e+02\n",
              "Id                      100000.0  2.846200e+05  ...  4.263818e+05  5.684360e+05\n",
              "HelpfulnessNumerator    100000.0  1.745550e+00  ...  2.000000e+00  8.660000e+02\n",
              "Time                    100000.0  1.296172e+09  ...  1.332720e+09  1.351210e+09\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxokNaUHlXSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d2d731b9-45ef-4deb-bccf-9c2f6382f2d1"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ProductId', 'UserId', 'Summary', 'Score', 'HelpfulnessDenominator',\n",
              "       'Id', 'ProfileName', 'HelpfulnessNumerator', 'Time', 'Text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp2uC5tzixsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_cols = ['ProductId', 'UserId', 'Id', 'ProfileName']\n",
        "cont_cols = ['HelpfulnessDenominator', 'HelpfulnessNumerator']\n",
        "txt_cols = ['Summary','Text']\n",
        "dep_var = ['Score']\n",
        "\n",
        "procs = [FillMissing, Categorify, Normalize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMUohhMJmJqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "il = MixedTabularList.from_df(data, cat_cols, cont_cols, txt_cols, vocab=None, procs=procs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa0U1LcimktZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "45352eed-59f5-4a6d-da2f-9b152b644432"
      },
      "source": [
        "il.get(0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProductId                                                        B00141QYSQ\n",
              "UserId                                                       A1YS02UZZGRDCT\n",
              "Id                                                                    41471\n",
              "ProfileName                                                  Evan Eberhardt\n",
              "HelpfulnessDenominator                                                    2\n",
              "HelpfulnessNumerator                                                      2\n",
              "Summary                                                          Do Not Buy\n",
              "Text                      These are made in China (do not buy ANY pet fo...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4S9DxiLm3s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ils = il.split_by_rand_pct(valid_pct=0.2, seed=1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYaoAKZ_nNAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88ef6abc-233b-4493-ead7-852101011a56"
      },
      "source": [
        "len(ils.train), len(ils.valid)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 20000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ulPx-JgnUNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll = ils.label_from_df(dep_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaU2Nk40nfjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee178c24-974a-4dc4-fca2-2c93f54a91a8"
      },
      "source": [
        "type(ll), type(ll.train), len(ll.lists)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(fastai.data_block.LabelLists, fastai.data_block.LabelList, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st_gInn6oF8p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "28862b76-5eba-4790-b1aa-8a70761381a3"
      },
      "source": [
        "ll.train"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelList (80000 items)\n",
              "x: MixedTabularList\n",
              "ProductId B0089SPEO2; UserId A3JOYNYL458QHP; Id 28582; ProfileName coleridge; HelpfulnessDenominator -0.2631; HelpfulnessNumerator -0.2219; Text: xxbos xxfld 1 xxmaj less lemon and less zing xxfld 2 xxmaj everything is ok , except it just is n't as good as it is in the bags . xxmaj just considerably more bland -- less lemon and less zing . xxmaj boring .,ProductId B001PMCDK2; UserId A14TTMM0Z03Y2W; Id 389965; ProfileName Lindsay S. Bradford; HelpfulnessDenominator -0.2631; HelpfulnessNumerator -0.2219; Text: xxbos xxfld 1 my cat goes crazy for these ! xxfld 2 xxmaj best cat treat ever . xxmaj there is n't anything comparable to the love my cat has for these treats , he snubs away any other kind now . \n",
              "  i know he likes to manipulate me with his xxunk but these treats are my way of manipulating him to come sit on my lap and have some chill time . :),ProductId B002Q8JOSI; UserId A17UQD2RSSQH5X; Id 212536; ProfileName in the dark; HelpfulnessDenominator -0.1452; HelpfulnessNumerator -0.0943; Text: xxbos xxfld 1 xxmaj my dogs tell me these treats are xxup yummy xxfld 2 xxmaj my two xxmaj corgis were thoroughly spoiled by my late husband ( i spent a year and a half dieting them down a combined total of 25 pounds ! ) \n",
              " \n",
              "  xxmaj they are accustomed to the finest of fare , and they absolutely love the xxmaj wellness brand of treats .,ProductId B001CHFUGY; UserId A2M8VROSDPU4JT; Id 434484; ProfileName Officefan \"Officefankt\"; HelpfulnessDenominator -0.1452; HelpfulnessNumerator -0.0943; Text: xxbos xxfld 1 xxmaj very good coffee xxfld 2 i really liked this coffee , it was just as good as everyone claimed it was . xxmaj strong , bold and flavorful ! i would recommend !,ProductId B0041CIR62; UserId A16I6WJUEBJ1C3; Id 138997; ProfileName doctorsirena \"doctorsirena\"; HelpfulnessDenominator -0.1452; HelpfulnessNumerator -0.0943; Text: xxbos xxfld 1 okay but not as healthy as it appears xxfld 2 i am always looking for healthier , whole grain versions of foods i enjoy . xxmaj unfortunately , these xxmaj peacock brand noodles are yet another food masquerading as healthy . xxmaj the product title in big letters on the front says \" xxmaj brown xxmaj rice xxmaj vermicelli \" , making the consumer think \" this is made with brown rice , so it should be a healthy choice \" . xxmaj but the first indication that it is not is when looking at the fiber content on the nutrition facts - only 0.6 g per 2 oz serving . xxmaj then onto the ingredients list to see why so low ... contains brown rice , sago starch and water . xxmaj the sago starch comes from palms and must not have much ( if any ) fiber . \n",
              " \n",
              "  xxmaj the xxmaj annie xxmaj chun 's xxmaj maifun xxmaj brown xxmaj rice xxmaj noodles ( sold on xxmaj amazon and in my local healthy grocer ) has become one of my staples and is my frame of reference when comparing to the xxmaj peacock brand . xxmaj the xxmaj annie xxmaj chun 's product is made with 100 % whole grain , with ingredients brown rice flour and water . xxmaj per 2 oz serving , it has 4 g fiber and pretty much the same calories and other nutrients as the xxmaj peacock brand . \n",
              " \n",
              "  xxmaj if you do try this xxmaj peacock brand noodles and have not used rice noodles before , you will need to seek guidance elsewhere on preparation . xxmaj as others have pointed out , the xxmaj peacock package gives almost no directions on how to prepare the product , aside from a brief mention in the recipes ( in the header text it does say that they are \" easy - to - cook \" but does not say how ) . xxmaj it also contains a very strange recipe for rice noodles : xxmaj xxunk xxmaj olio style - this is an xxmaj italian recipe for noodles with olive oil / garlic / sprinkled with grated cheese that i think would not be very tasty . xxmaj the second recipe appears to be for a soup with veggie strips . xxmaj neither recipe gives amounts or much direction . xxmaj in comparison , the xxmaj annie xxmaj chun 's package gives clear , specific directions on rice noodle preparation and two recipes . \n",
              " \n",
              "  i use rice noodles = maifun = rice sticks = sometimes called vermicelli for making the xxmaj vietnamese salad \" bun tofu \" , to serve with stir - fried veggies or in lettuce rolls . xxmaj they can also be used in spring rolls / egg rolls . xxmaj when cooking with thin rice noodles , be careful not to xxunk / overcook / xxunk or they tend to disintegrate . xxmaj asian rice noodle vermicelli ( maifun ) are not the same as xxmaj italian vermicelli and are not readily interchangeable . xxmaj if making an xxmaj italian recipe , the best results would be expected from xxmaj italian pasta and not maifun . \n",
              " \n",
              "  a few final notes ... xxmaj both xxmaj peacock and xxmaj annie xxmaj chun 's brown rice noodles are gluten free . xxmaj the xxmaj peacock is made in xxmaj singapore and the xxmaj annie xxmaj chun 's in xxmaj thailand . xxmaj the xxmaj peacock noodles do taste fine ( kind of bland ) , but so do the xxmaj annie xxmaj chun 's . xxmaj at this time , they are both approximately the same price . xxmaj peacock come in an plastic bag with some noodle xxunk upon shipping ; xxmaj annie xxmaj chun 's are perfect upon removal from their cellophane bag in a box . xxmaj overall , i highly recommend the xxmaj annie xxmaj chun 's xxmaj maifun as a healthier option over the xxmaj peacock brand . xxmaj on a related note , the xxmaj annie xxmaj chun 's soba and brown rice pad thai noodles are also excellent . \n",
              " \n",
              "  xxmaj rating for this product : 2.5 stars rounded down to 2 stars .\n",
              "y: CategoryList\n",
              "3,5,5,5,2\n",
              "Path: ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhdO1GbpoJGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "dbf6155f-50eb-4832-d6b2-5d668b02d8c7"
      },
      "source": [
        "ll.train.x[0], ll.train.y[0], ll.train.x.codes[0], ll.train.x.cat_names, ll.train.x.text_ids[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(MixedTabularLine ProductId B0089SPEO2; UserId A3JOYNYL458QHP; Id 28582; ProfileName coleridge; HelpfulnessDenominator -0.2631; HelpfulnessNumerator -0.2219; Text: xxbos xxfld 1 xxmaj less lemon and less zing xxfld 2 xxmaj everything is ok , except it just is n't as good as it is in the bags . xxmaj just considerably more bland -- less lemon and less zing . xxmaj boring .,\n",
              " Category 3,\n",
              " array([27527, 40148,  4101, 47130]),\n",
              " ['ProductId', 'UserId', 'Id', 'ProfileName'],\n",
              " array([   2,    4,   21,    5,  214,  561,   13,  214, 3298,    4,   20,    5,  507,   18,  498,   11,  966,   15,\n",
              "          58,   18,   37,   38,   43,   38,   15,   18,   24,   10,  254,    9,    5,   58, 3619,   69,  871,  228,\n",
              "         214,  561,   13,  214, 3298,    9,    5, 2509,    9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPqf_SCIofy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb2d6235-7de1-429c-89a1-787ead114593"
      },
      "source": [
        "len(ll.train.x.vocab.itos), len(ll.valid.x.vocab.itos)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33672, 33672)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukL6r73apF9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd2a3f7c-a9e5-48eb-cb49-3c465bf188b9"
      },
      "source": [
        "data_bunch = ll.databunch(bs=32)\n",
        "b = data_bunch.one_batch()\n",
        "\n",
        "len(b), len(b[0]), len(b[0][0]), len(b[0][1]), len(b[0][1]), b[1].shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3, 32, 32, 32, torch.Size([32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3VrMMZUpszL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8605dd12-588a-4454-c761-66533080b824"
      },
      "source": [
        "b"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor([[ 9526, 34221, 48746,    41],\n",
              "          [ 1558, 53032, 60835, 38694],\n",
              "          [12482, 47017, 73692, 43448],\n",
              "          [ 7961, 51682, 29427, 40177],\n",
              "          [14947, 23539, 15585, 23329],\n",
              "          [ 1662, 31652, 73078, 44983],\n",
              "          [ 3471, 46042, 38739, 42210],\n",
              "          [ 5653, 46113, 59485, 23926],\n",
              "          [12280, 32680, 52335, 27032],\n",
              "          [ 2735,  2080, 28633, 27587],\n",
              "          [ 8890, 52095, 17450, 35049],\n",
              "          [ 4079, 30979, 10060,  5888],\n",
              "          [11964,  5674, 70483, 28117],\n",
              "          [10318, 38273, 21286, 51996],\n",
              "          [14114, 26687, 50778, 45122],\n",
              "          [  830, 59127, 33834, 25461],\n",
              "          [26646,  8974, 13821, 37184],\n",
              "          [ 2936,  4043, 72491,  6435],\n",
              "          [16489, 30586, 26330, 52794],\n",
              "          [10017, 50819,  3447,  3681],\n",
              "          [20701, 30699, 31235, 33090],\n",
              "          [25995, 18146, 12386, 32234],\n",
              "          [ 8163, 49631, 42994,  1336],\n",
              "          [21413, 32815, 59720,  1509],\n",
              "          [10022,  3779,  8309, 46150],\n",
              "          [14132, 33346, 73163, 17313],\n",
              "          [14306, 18168, 51864,  5792],\n",
              "          [25602,  6484,  5454, 17444],\n",
              "          [18579, 22957, 66562, 30636],\n",
              "          [ 5675, 29494, 33238, 54027],\n",
              "          [24153, 58362, 66485, 52900],\n",
              "          [14961, 29636, 71103,  2112]]), tensor([[-0.0273, -0.0943],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.1452, -0.0943],\n",
              "          [-0.2631, -0.2219],\n",
              "          [ 0.3264,  0.1609],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.0273,  0.0333],\n",
              "          [-0.1452, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.1452, -0.0943],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [ 0.0906,  0.1609],\n",
              "          [ 0.0906,  0.1609],\n",
              "          [ 0.0906, -0.2219],\n",
              "          [ 1.0338,  0.0333],\n",
              "          [-0.1452, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [ 0.3264,  0.4160],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.0273,  0.0333],\n",
              "          [-0.2631, -0.2219],\n",
              "          [-0.2631, -0.2219],\n",
              "          [ 0.0906,  0.1609],\n",
              "          [-0.0273,  0.0333]]), tensor([[    1,     1,     1,  ...,    17,    84,     9],\n",
              "          [    1,     1,     1,  ...,    85,  3636,     9],\n",
              "          [    1,     1,     1,  ...,   321,   488,     9],\n",
              "          ...,\n",
              "          [    1,     1,     1,  ...,   163,    47,     9],\n",
              "          [    1,     1,     1,  ...,    86, 26504,    23],\n",
              "          [    1,     1,     1,  ...,    16,  5616,     9]])],\n",
              " tensor([4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 3, 4, 4, 1, 0, 4, 4, 4,\n",
              "         3, 4, 0, 4, 4, 3, 4, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sutLabFAp4ce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "6259fb49-74fc-4721-8ac1-acf4ace4b5bc"
      },
      "source": [
        "data_bunch.show_batch()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "TABULAR:<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>B000G82L62</td>\n",
              "      <td>A1WS5M1IQLU14L</td>\n",
              "      <td>64579</td>\n",
              "      <td>Anika M. O.</td>\n",
              "      <td>-0.1452</td>\n",
              "      <td>-0.0943</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>B0026LKJTS</td>\n",
              "      <td>A17WER66R17JEF</td>\n",
              "      <td>339771</td>\n",
              "      <td>Larry Finley</td>\n",
              "      <td>-0.1452</td>\n",
              "      <td>-0.0943</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>B0007ZLRUU</td>\n",
              "      <td>A1IFOESRHYQ4AH</td>\n",
              "      <td>10044</td>\n",
              "      <td>A. Bradley-Verett \"Amanda Verett\"</td>\n",
              "      <td>0.3264</td>\n",
              "      <td>0.4160</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>B00004RBDU</td>\n",
              "      <td>A2AJMN9EDT94B3</td>\n",
              "      <td>343426</td>\n",
              "      <td>Gouverneur Girl</td>\n",
              "      <td>-0.2631</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>B0030VJ9UI</td>\n",
              "      <td>A1P6C8KO9IU4OI</td>\n",
              "      <td>238687</td>\n",
              "      <td>gloriarecycles</td>\n",
              "      <td>-0.1452</td>\n",
              "      <td>-0.0943</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "TEXT:<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text_data</th>      <th>target</th>    </tr>\n",
              "  </thead>\n",
              "  <tbody>  <tbody>    <tr>      <td>xxbos(2) xxfld(4) 1(21) love(65) this(19) rice(324) !(23) xxfld(4) 2(20) really(85) good(43) quality(188) grains(1005) !(23) easy(227) to(16) prepare(1323) and(13) i(12) feel(319) that(26) my(25) every(198) meal(439) is(18) definitely(257) elevated(8483) with(30) this(19) as(38) a(14) my(25) carbs(1002) !(23) and(13) what(95) 's(36) best(82) is(18) you(28) can(67) get(81) it(15) for(22) much(91) cheaper(453) because(104) of(17) amazon(101) subscribe(684) &amp;(176) save(432) !(23)</td>      <td>5</td>    </tr>    <tr>      <td>xxbos(2) xxfld(4) 1(21) xxmaj(5) for(22) xxmaj(5) the(10) xxmaj(5) cat(179) xxfld(4) 2(20) xxmaj(5) my(25) cat(179) has(74) never(194) turned(969) up(84) his(240) nose(1528) at(53) this(19) product(54) .(9) xxmaj(5) he(111) always(207) has(74) his(240) choice(538) at(53) meal(439) time(100) and(13) he(111) eats(848) both(277) the(10) chicken(260) and(13) this(19) product(54) without(203) fail(4085) .(9)</td>      <td>5</td>    </tr>    <tr>      <td>xxbos(2) xxfld(4) 1(21) xxmaj(5) the(10) best(82) coffee(51) ever(187) xxfld(4) 2(20) xxmaj(5) there(94) is(18) a(14) reason(577) they(35) serve(929) this(19) coffee(51) at(53) the(10) xxmaj(5) white(435) xxmaj(5) house(446) .(9) xxmaj(5) its(217) the(10) smoothest(4896) ,(11) best(82) coffee(51) ever(187) produced(1780) .(9) xxmaj(5) low(294) acid(888) ,(11) smooth(399) in(24) the(10) mouth(513) ,(11) and(13) it(15) has(74) the(10) most(167) intoxicating(9528) aroma(627) .(9) xxmaj(5) worth(307) the(10) price(99) .(9)</td>      <td>5</td>    </tr>    <tr>      <td>xxbos(2) xxfld(4) 1(21) xxmaj(5) flea(6691) xxmaj(5) trap(2599) xxmaj(5) refill(3316) pads(9772) xxfld(4) 2(20) xxmaj(5) these(44) are(33) awesome(427) .(9) i(12) only(90) wish(444) that(26) there(94) were(102) more(69) in(24) the(10) package(288) than(78) 3(184) .(9) xxmaj(5) maybe(420) a(14) 6(304) pack(252) or(56) more(69) for(22) the(10) same(212) amount(351) or(56) a(14) few(202) dollars(1332) more(69) !(23) !(23) !(23)</td>      <td>5</td>    </tr>    <tr>      <td>xxbos(2) xxfld(4) 1(21) xxmaj(5) good(43) xxmaj(5) snacks(583) xxfld(4) 2(20) xxmaj(5) my(25) 10(380) month(494) old(216) baby(414) loves(165) these(44) .(9) xxmaj(5) she(115) can(67) pick(823) them(47) up(84) and(13) eat(126) them(47) .(9) i(12) tasted(308) one(57) myself(490) and(13) they(35) dissolve(1922) in(24) your(92) mouth(513) and(13) they(35) are(33) not(29) too(87) sweet(140) ,(11) just(58) enough(223) sweetness(797) .(9) i(12) love(65) that(26) they(35) are(33) organic(200) and(13) do(59) n't(37) have(31) anything(321) artificial(551) .(9)</td>      <td>5</td>    </tr>  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVo5gH6-rMAa",
        "colab_type": "text"
      },
      "source": [
        "**LM Fine Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySOvbFt0qf6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm_df = pd.DataFrame(pd.concat([data[txt_cols]], axis=0))\n",
        "lm_df[txt_cols].fillna('None', inplace=True)\n",
        "lm_df[txt_cols].fillna('NaN', inplace=True)\n",
        "lm_df.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rv2cuUEsDn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "120c28cf-075d-4c49-fc0e-ebb21193b020"
      },
      "source": [
        "lm_df[lm_df['Summary'].isna()]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Summary, Text]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2yZMQLpru1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = (TextList.from_df(lm_df.head(5000), '.', cols=txt_cols) # use top 5000 as example\n",
        "            .split_by_rand_pct()\n",
        "            .label_for_lm()\n",
        "            .databunch())\n",
        "\n",
        "data_lm.save('data_lm_export.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6_0J-6GtKK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data('.', file='data_lm_export.pkl')\n",
        "\n",
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y017MjjEtmRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "73aa69c2-970a-4533-ea2f-e04555ea94b4"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.267663</td>\n",
              "      <td>3.902570</td>\n",
              "      <td>0.266127</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYbjAGJZttvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('lm_ft_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPIGR-jMunUp",
        "colab_type": "text"
      },
      "source": [
        "MixedTabluar Databunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW-DNFIyua8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "procs = [FillMissing, Categorify, Normalize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy5KQSnKu76T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_cls = (MixedTabularList.from_df(data, cat_cols, cont_cols, txt_cols, vocab=data_lm.train_ds.vocab, procs=procs)\n",
        "            .split_by_rand_pct(valid_pct=0.2, seed=1234)\n",
        "            .label_from_df(dep_var)\n",
        "            .databunch(bs=32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVbQv2IavvWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "ecb8e737-2c30-4622-90f1-5e26284f8fd4"
      },
      "source": [
        "data_cls.show_batch()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "TABULAR:<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>B001AC8JL4</td>\n",
              "      <td>A3NLSOWM1IHN35</td>\n",
              "      <td>274389</td>\n",
              "      <td>James Crawford \"n\"</td>\n",
              "      <td>-0.1452</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>B0011MTYF8</td>\n",
              "      <td>AQ4BZY7SKEAGV</td>\n",
              "      <td>45416</td>\n",
              "      <td>Jessica</td>\n",
              "      <td>-0.2631</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>B001EQ4ICA</td>\n",
              "      <td>A1OW05IFB843RN</td>\n",
              "      <td>221698</td>\n",
              "      <td>audchild \"Donna\"</td>\n",
              "      <td>-0.2631</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>B001HY7R5O</td>\n",
              "      <td>A1ZT5QIXBC4UOV</td>\n",
              "      <td>469802</td>\n",
              "      <td>Bigdoglover</td>\n",
              "      <td>-0.2631</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>B005ZBZLT4</td>\n",
              "      <td>A2P26Q03X2SZ0P</td>\n",
              "      <td>83313</td>\n",
              "      <td>smylescheduler \"diamond@kennett.net\"</td>\n",
              "      <td>0.0906</td>\n",
              "      <td>0.0333</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "TEXT:<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text_data</th>      <th>target</th>    </tr>\n",
              "  </thead>\n",
              "  <tbody>  <tbody>    <tr>      <td>xxbos(2) xxfld(4) 1(182) toxic(3518) waste(705) xxfld(4) 2(138) when(68) i(11) put(263) the(10) toxic(3518) waste(705) in(22) my(23) mouth(547) i(11) xxunk(0) about(88) how(213) every(210) one(54) in(22) my(23) school(1274) was(30) saying(1065) toxic(3518) waste(705) was(30) more(72) sour(756) then(154) war(3840) heads(2982) as(37) i(11) put(263) it(15) in(22) my(23) mouth(547) it(15) xxunk(0) seem(482) like(38) it(15) was(30) more(72) sour(756) then(154) war(3840) heads(2982) then(154) i(11) xxunk(0) for(20) 7(555) xxunk(0) after(118) i(11) was(30) done(674) with(28) the(10) toxic(3518) waste(705) a(14) xxunk(0) to(16) have(29) a(14) xxunk(0) was(30) xxunk(0) me(69)</td>      <td>5</td>    </tr>    <tr>      <td>xxbos(2) xxfld(4) 1(182) xxmaj(5) snow(3959) xxmaj(5) xxunk(0) xxmaj(5) time(94) !(21) xxfld(4) 2(138) i(11) ordered(230) this(19) for(20) my(23) kid(1019) 's(35) home(336) snow(3959) xxunk(0) machine(589) .(9) xxmaj(5) got(198) the(10) product(49) a(14) few(203) days(344) before(191) it(15) was(30) xxunk(0) to(16) arrive(1971) .(9) xxmaj(5) kids(400) were(90) so(39) excited(980) .(9) xxmaj(5) perfect(186) blend(326) of(17) different(227) flavors(171) .(9) xxmaj(5) everyone(485) is(18) enjoying(1584) snow(3959) xxunk(0) this(19) summer(920) !(21)</td>      <td>5</td>    </tr>    <tr>      <td>xxbos(2) xxfld(4) 1(182) xxmaj(5) love(63) this(19) stuff(159) !(21) xxfld(4) 2(138) i(11) 've(103) been(107) drinking(418) xxmaj(5) xxunk(0) xxmaj(5) instant(801) xxmaj(5) breakfast(373) since(155) the(10) xxunk(0) 's(35) .(9) xxmaj(5) it(15) 's(35) an(92) awesome(459) ,(12) quick(567) ,(12) nutritionally(5115) balanced(1382) meal(528) replacement(1585) .(9) i(11) purchased(304) this(19) product(49) in(22) bulk(792) for(20) my(23) food(74) storage(1721) pantry(1402) ,(12) along(668) with(28) xxmaj(5) xxunk(0) whole(259) milk(290) powder(423) .(9) xxmaj(5) in(22) an(92) emergency(3919) ,(12) this(19) is(18) the(10) kind(369) of(17) stuff(159) that(24) 's(35) light(390) enough(224) to(16) carry(793) ,(12) and(13) nutrient(4471) xxunk(0) enough(224) to(16) make(120) a(14) big(239) difference(534) in(22) your(102) family(356) 's(35) xxunk(0) xxunk(0) .(9)</td>      <td>5</td>    </tr>    <tr>      <td>xxbos(2) xxfld(4) 1(182) xxmaj(5) finally(619) the(10) right(223) dog(100) food(74) for(20) my(23) xxmaj(5) st(4577) xxmaj(5) xxunk(0) 's(35) xxfld(4) 2(138) xxmaj(5) it(15) has(70) taken(1221) us(359) a(14) bit(178) of(17) trial(3302) and(13) error(4259) but(25) finally(619) we(67) have(29) found(147) the(10) right(223) dog(100) food(74) for(20) our(125) two(164) xxmaj(5) st.(2748) xxmaj(5) xxunk(0) .(9) xxmaj(5) it(15) is(18) one(54) they(32) like(38) ,(12) it(15) is(18) xxunk(0) for(20) large(360) xxunk(0) ,(12) it(15) fills(3416) them(45) up(83) and(13) because(104) of(17) the(10) high(217) quality(204) there(89) is(18) less(193) xxunk(0) in(22) the(10) xxunk(0) .(9) xxmaj(5) the(10) price(96) is(18) high(217) but(25) it(15) seems(362) to(16) be(46) higher(1127) for(20) this(19) food(74) everywhere(1300) .(9) xxmaj(5) however(260) ,(12) with(28) xxmaj(5) amazon(98) xxmaj(5) prime(1306) i(11) just(57) order(167) it(15) up(83) and(13) it(15) is(18) delivered(808) right(223) to(16) my(23) xxunk(0) every(210) other(78) week(467) .(9) xxmaj(5) no(79) more(72) xxunk(0) the(10) bag(134) into(184) my(23) car(1541) ,(12) out(77) of(17) my(23) car(1541) ,(12) etc(500) .(9) xxmaj(5) amazon(98) and(13) xxmaj(5) wellness(720) rock(2109) !(21)</td>      <td>5</td>    </tr>    <tr>      <td>xxbos(2) xxfld(4) 1(182) enjoy(261) this(19) brand(209) of(17) coffee(50) xxfld(4) 2(138) i(11) am(112) pleased(679) with(28) this(19) brand(209) of(17) coffee(50) ,(12) great(42) flavor(60) and(13) no(79) waste(705) with(28) the(10) great(42) design(2437) .(9) xxmaj(5) will(76) be(46) one(54) of(17) my(23) favorite(161) blends(1039) now(117) .(9)</td>      <td>5</td>    </tr>  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdDcz4qIwY5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.callbacks import hook_output\n",
        "from fastai.text.learner import RNNTrainer, masked_concat_pool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6G0sEKmw5XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TabularTextNN(nn.Module):\n",
        "    def __init__(self, data, tab_layers, tab_args={}, text_args={}):\n",
        "        super().__init__()\n",
        "        \n",
        "        tab_learner = tabular_learner(data, tab_layers, **tab_args)\n",
        "        tab_learner.model.layers = tab_learner.model.layers[:-1]\n",
        "        self.tabular_model = tab_learner.model\n",
        "\n",
        "        text_class_learner = text_classifier_learner(data, AWD_LSTM, **text_args)\n",
        "        text_class_learner.load_encoder('lm_ft_enc')\n",
        "        self.text_enc_model = list(text_class_learner.model.children())[0]\n",
        "        \n",
        "        self.bn_concat = nn.BatchNorm1d(400*3+100)\n",
        "        \n",
        "        self.lin = nn.Linear(400*3+100, 50)\n",
        "        self.final_lin = nn.Linear(50, data.c)\n",
        "        \n",
        "    def forward(self, x_cat:Tensor, x_cont:Tensor, text_input:Tuple[Tensor,Tensor]) -> Tensor:\n",
        "        # grab the tabular results minus the last layer\n",
        "        tab_res = self.tabular_model.forward(x_cat, x_cont)\n",
        "\n",
        "        # grab the results of the encoder\n",
        "        raw_outputs, outputs, mask = self.text_enc_model(text_input)\n",
        "        text_final_rnn_output = masked_concat_pool(outputs, mask) #outputs[-1][:,-1] # => (bs, 400*3)\n",
        "  \n",
        "        # do the concat pooling trick with the tabular and text encoder results\n",
        "        x = torch.cat([tab_res, text_final_rnn_output], dim=1)\n",
        "        x = self.bn_concat(x)\n",
        "        \n",
        "        # run the final results though a couple of linears\n",
        "        x = self.final_lin(F.relu(self.lin(x)))\n",
        "        \n",
        "        # return the goods\n",
        "        return x, raw_outputs, outputs\n",
        "    \n",
        "    def reset(self):\n",
        "        self.text_enc_model.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j5WxVfuw537",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tab_layers = [200, 100]\n",
        "tabular_args = {\n",
        "    'metrics': accuracy, \n",
        "    'ps': [.05, .03], \n",
        "    'emb_drop': 0.3, \n",
        "    #'y_range': [1, 5.1]\n",
        "}\n",
        "\n",
        "\n",
        "bptt = 70\n",
        "emb_size = 400\n",
        "n_hidden = 1150\n",
        "n_layers = 3\n",
        "\n",
        "max_seq = 70*20\n",
        "drop_mult = 0.5\n",
        "\n",
        "text_args = {\n",
        "    'bptt': bptt, \n",
        "    'drop_mult': drop_mult,\n",
        "    'max_len': max_seq\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGzJdlQjw-eP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TabularTextNN(data_cls, tab_layers, tabular_args, text_args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Rc7Q_ExDyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b654f609-bed1-4427-8f3b-b79ceaf97bcb"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "560"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avHM4_gyxNdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = None; gc.collect()\n",
        "learn = Learner(data_cls, model, metrics=[accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHoYsdk3xQAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.callbacks.append(RNNTrainer(learn, bptt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BD2V-48xTi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "c490b4b9-4490-4250-9497-5bb64e8da39f"
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIpxQQIiLSKQWEiIh06v8D1o5zJdEGsBoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3sxtWaSxVuF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "28f4b536-c0f1-4d1a-fbcf-7d627a8c13e5"
      },
      "source": [
        "\n",
        "learn.fit_one_cycle(1, 1e-2, wd=1e-1, pct_start=0.2, moms=(0.8, 0.7))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.884298</td>\n",
              "      <td>0.829151</td>\n",
              "      <td>0.687550</td>\n",
              "      <td>39:19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mKzOPF9xtSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbf68435-7b6e-4ff5-ec14-226023ccb0d2"
      },
      "source": [
        "gc.garbage"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx-4BleNBmBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2146c5c2-a246-453f-d6fd-0bbbfe5a63e9"
      },
      "source": [
        "learn;\n",
        "gc.collect()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU9RsvRmBpWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cdac3a7-10ff-4d48-93a1-d437e8ee4cb0"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDiW_sYYB0ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://medium.com/@wgilliam/finding-data-block-nirvana-a-journey-through-the-fastai-data-block-api-part-2-9b23ea5d83ee"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Unbjek2H5ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}